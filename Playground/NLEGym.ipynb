{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8851253-48f7-40ef-bc50-9e8c9c2dbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import gym\n",
    "import nle\n",
    "import numpy as np\n",
    "import random\n",
    "from gym import envs\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81b0c628-c6e0-4d80-84d8-f6e8d7663068",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('NetHack-v0', max_episode_steps=100000)\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7f264325-1289-4e41-9605-de3597d92d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg Acts: 1\tPos Acts: 0.0008\tNeu Acts: 0.9992\n",
      "\n",
      "Total Value: 6112.0\tReward Rate: 0.0061\n"
     ]
    }
   ],
   "source": [
    "value = 0\n",
    "neg_acts = 0\n",
    "pos_acts = 0\n",
    "neu_acts = 0\n",
    "RUNS = 1000000\n",
    "for i in range(RUNS):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if reward < 0.0:\n",
    "        neg_acts += 1\n",
    "    elif reward > 0.0:\n",
    "        pos_acts += 1\n",
    "    else:\n",
    "        neu_acts += 1\n",
    "    value += reward\n",
    "    if done:\n",
    "        env.reset()\n",
    "print(f'Neg Acts: {neg_acts/RUNS:.4f}\\tPos Acts: {pos_acts/RUNS:.4f}\\tNeu Acts: {neu_acts/RUNS:.4f}\\n')\n",
    "print(f'Total Value: {value}\\tReward Rate: {value/RUNS:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32757ace-6d8d-47ef-a219-db94975ee726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algo(model, env):\n",
    "    value = 0\n",
    "    neg_acts = 0\n",
    "    pos_acts = 0\n",
    "    neu_acts = 0\n",
    "    RUNS = 1000000\n",
    "    obs = env.reset()\n",
    "    for i in range(RUNS):\n",
    "        action = model.sample(obs)\n",
    "        new_obs, reward, done, info = env.step(action)\n",
    "        model.update(obs, new_obs, reward, action)\n",
    "        if reward < 0.0:\n",
    "            neg_acts += 1\n",
    "        elif reward > 0.0:\n",
    "            pos_acts += 1\n",
    "        else:\n",
    "            neu_acts += 1\n",
    "        value += reward\n",
    "        if done:\n",
    "            new_obs = env.reset()\n",
    "        obs = new_obs\n",
    "    print(f'Neg Acts: {neg_acts/RUNS:.4f}\\tPos Acts: {pos_acts/RUNS:.4f}\\tNeu Acts: {neu_acts/RUNS:.4f}\\n')\n",
    "    print(f'Total Value: {value}\\tReward Rate: {value/RUNS:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0f1e327e-a1c1-4ed8-95dd-ca33f5c9a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpModel():\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "    \n",
    "    def sample(self, obs):\n",
    "        return self.env.action_space.sample()\n",
    "    \n",
    "    def update(self, obs, new_obs, reward, action):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e905b588-347b-4506-b0f3-9d1289b6a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg Acts: 0.0000\tPos Acts: 0.0008\tNeu Acts: 0.9992\n",
      "\n",
      "Total Value: 5547.0\tReward Rate: 0.0055\n"
     ]
    }
   ],
   "source": [
    "goon = SimpModel(env)\n",
    "test_algo(goon, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c47eaf5-5f3b-4b03-b122-172ed599f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextSimp():\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.p_reward_dist = np.ones(env.action_space.n)\n",
    "    \n",
    "    def sample(self, obs):\n",
    "        indexes = list(range(self.p_reward_dist.shape[0]))\n",
    "        return np.random.choice(indexes, p=self.p_reward_dist/np.sum(self.p_reward_dist))\n",
    "    \n",
    "    def update(self, obs, new_obs, reward, action):\n",
    "        if reward > 0:\n",
    "            self.p_reward_dist[action] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37d656c8-53f5-48e7-9eab-80d416163c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg Acts: 0.0000\tPos Acts: 0.0029\tNeu Acts: 0.9971\n",
      "\n",
      "Total Value: 21913.0\tReward Rate: 0.0219\n"
     ]
    }
   ],
   "source": [
    "boon = NextSimp(env)\n",
    "test_algo(boon, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5442d-1a71-4b59-99c2-e36c0b0559a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
