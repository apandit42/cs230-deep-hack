{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c3152b05-ea41-48d6-ae39-8f31a47d7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import Statements: From PyTorch RL Tutorial\n",
    "\"\"\"\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nle\n",
    "import gym\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b06a338b-15e3-4a3e-a51b-eeebf72355dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glyphs': array([[2359, 2359, 2359, ..., 2359, 2359, 2359],\n",
       "        [2359, 2359, 2359, ..., 2359, 2359, 2359],\n",
       "        [2359, 2359, 2359, ..., 2359, 2359, 2359],\n",
       "        ...,\n",
       "        [2359, 2359, 2359, ..., 2359, 2359, 2359],\n",
       "        [2359, 2359, 2359, ..., 2359, 2359, 2359],\n",
       "        [2359, 2359, 2359, ..., 2359, 2359, 2359]], dtype=int16),\n",
       " 'chars': array([[32, 32, 32, ..., 32, 32, 32],\n",
       "        [32, 32, 32, ..., 32, 32, 32],\n",
       "        [32, 32, 32, ..., 32, 32, 32],\n",
       "        ...,\n",
       "        [32, 32, 32, ..., 32, 32, 32],\n",
       "        [32, 32, 32, ..., 32, 32, 32],\n",
       "        [32, 32, 32, ..., 32, 32, 32]], dtype=uint8),\n",
       " 'colors': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'specials': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'blstats': array([75, 10, 15, 15, 18, 12, 12, 11,  8,  0, 11, 11,  1,  0,  2,  2,  7,\n",
       "         0,  1,  0,  1,  1,  0,  0,  1,  0]),\n",
       " 'message': array([ 66, 101,  32,  99,  97, 114, 101, 102, 117, 108,  33,  32,  32,\n",
       "         78, 101, 119,  32, 109, 111, 111, 110,  32, 116, 111, 110, 105,\n",
       "        103, 104, 116,  46,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8),\n",
       " 'inv_glyphs': array([1937, 1925, 2019, 2185, 2103, 2098, 2163, 2145, 5976, 5976, 5976,\n",
       "        5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976,\n",
       "        5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976,\n",
       "        5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976,\n",
       "        5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976, 5976],\n",
       "       dtype=int16),\n",
       " 'inv_strs': array([[ 97,  32,  98, ...,   0,   0,   0],\n",
       "        [ 57,  32,  43, ...,   0,   0,   0],\n",
       "        [ 97, 110,  32, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]], dtype=uint8),\n",
       " 'inv_letters': array([ 97,  98,  99, 100, 101, 102, 103, 104,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0], dtype=uint8),\n",
       " 'inv_oclasses': array([ 2,  2,  3,  8,  6,  6,  7,  7, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18], dtype=uint8),\n",
       " 'tty_chars': array([[ 66, 101,  32, ...,  32,  32,  32],\n",
       "        [ 32,  32,  32, ...,  32,  32,  32],\n",
       "        [ 32,  32,  32, ...,  32,  32,  32],\n",
       "        ...,\n",
       "        [ 32,  32,  32, ...,  32,  32,  32],\n",
       "        [ 65, 103, 101, ...,  32,  32,  32],\n",
       "        [ 68, 108, 118, ...,  32,  32,  32]], dtype=uint8),\n",
       " 'tty_colors': array([[7, 7, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [7, 7, 7, ..., 0, 0, 0],\n",
       "        [7, 7, 7, ..., 0, 0, 0]], dtype=int8),\n",
       " 'tty_cursor': array([11, 75], dtype=uint8),\n",
       " 'misc': array([0, 0, 0], dtype=int32)}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('NetHackChallenge-v0', savedir=None)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d64abc40-d788-4e11-82a3-a9ed484d5215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transition Class (represents change from one state to a another)\n",
    "StateTransition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "# Replay Memory Class (represents a memory of an experience, or state transition)\n",
    "class ReplayMemory():\n",
    "    def __init__(self, max_memory):\n",
    "        self.memory = []\n",
    "        self.max_memory = max_memory\n",
    "    \n",
    "    def push(self, newExperience):\n",
    "        if len(self.memory) >= self.max_memory:\n",
    "            self.memory.pop(0)\n",
    "        self.memory.append(newExperience)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d86cfce-7013-4876-9048-3682f4383e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.joe = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(), # 21 * 79 * 16\n",
    "            nn.MaxPool2d(3, padding=(0,1)), # 7 * 27 * 16\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding='same'),# 7 * 27 * 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, padding=(1,0)), # 3 * 9 * 64\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*9*64, 3*64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3*64, 113),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.joe(x.float())\n",
    "        return logits\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fad4af8e-cbf3-449f-98f1-10b37fe0add3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 21, 79])\n"
     ]
    }
   ],
   "source": [
    "x = np.load('l.txt.npy')\n",
    "x = torch.Tensor(x)[None,:,:,:]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "103c2869-efd2-4be5-97d1-9d84acb6e1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8304e-01,  1.0052e-02, -5.7900e-01, -2.9673e-01, -5.6491e-02,\n",
       "          2.1603e-01, -3.4159e-01, -1.8731e-01, -3.0812e-01,  1.1164e-01,\n",
       "         -5.2045e-01,  1.8728e-01,  8.7429e-03,  4.8387e-04,  2.5057e-01,\n",
       "          2.5009e-01, -1.3320e-01,  8.6689e-01,  3.7173e-01, -3.8553e-01,\n",
       "          3.6755e-01,  3.2878e-01, -3.0470e-01, -1.1364e-01,  7.6163e-02,\n",
       "         -1.2119e-01,  8.9848e-02, -2.7088e-01,  1.8923e-01,  2.3233e-01,\n",
       "         -3.2015e-01,  3.9316e-02,  2.3188e-01, -4.3725e-01,  3.8906e-01,\n",
       "          2.4832e-02,  4.1420e-01, -4.1497e-01, -1.0266e-01, -5.2499e-01,\n",
       "          1.3781e-01, -2.5641e-02,  1.5768e-01, -2.5781e-01, -2.7788e-01,\n",
       "          2.2917e-01,  8.4392e-02, -2.7387e-01, -1.3557e-01,  2.2888e-01,\n",
       "         -3.0993e-01, -4.7942e-01,  1.7450e-02, -5.8284e-01, -1.9728e-01,\n",
       "         -4.6851e-01,  1.0893e-01, -1.1585e-01, -1.9302e-01,  1.6277e-01,\n",
       "          3.6498e-01, -2.0792e-01, -1.4542e-01,  1.6003e-01,  4.4351e-01,\n",
       "          9.1785e-02,  2.2712e-01,  6.0230e-02,  5.9241e-01,  3.9681e-01,\n",
       "         -5.7851e-03,  1.6787e-01,  2.9251e-01,  6.8396e-02,  2.1292e-01,\n",
       "          2.4060e-01, -2.2475e-02,  1.9857e-01,  3.5922e-01, -6.2550e-02,\n",
       "         -9.3313e-02, -3.2536e-01, -1.1505e-01,  2.8369e-01,  3.9439e-01,\n",
       "         -4.2234e-01,  3.4255e-01, -4.9306e-01,  1.0881e-01, -5.7616e-01,\n",
       "         -2.0943e-01, -2.8898e-01, -2.8283e-02, -2.3627e-01, -3.8050e-01,\n",
       "          2.7460e-01,  1.4837e-01, -4.7705e-02, -8.1186e-02,  1.4099e-02,\n",
       "          1.1030e-01, -9.9232e-02, -2.2313e-01,  7.4484e-01, -1.5064e-01,\n",
       "          6.3937e-01, -1.9397e-01,  2.6047e-01,  8.6587e-02, -1.3839e-01,\n",
       "          5.1409e-01,  9.9075e-02, -4.6779e-02]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bink = DQNetwork()\n",
    "bink.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3ca06b4e-d88d-4337-b7c0-206af1aed284",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "steps_done = 0\n",
    "episode_durations = []\n",
    "episode_rewards = []\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "83cea590-47b5-4877-8221-2da09dd176c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQNetwork().to(device)\n",
    "target_net = DQNetwork().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b286d76a-a79f-41a5-ad74-aed2db2f37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a280b923-e49c-4c31-91ff-a6a4289fabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4893b7d4-05cf-40d6-a194-4574f163eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = StateTransition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0ce7c3ad-ab9d-4d04-82b4-03e3c916761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "\n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m2\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;37mK\u001b[0;37mi\u001b[0;37ml\u001b[0;37ml\u001b[0;37me\u001b[0;37md\u001b[0;30m \u001b[0;37mb\u001b[0;37my\u001b[0;30m \u001b[0;37ma\u001b[0;30m \u001b[0;37mk\u001b[0;37mo\u001b[0;37mb\u001b[0;37mo\u001b[0;37ml\u001b[0;37md\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m-\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m5\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m2\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m2\n",
      "\u001b[0;37m4\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mP\u001b[0;37mr\u001b[0;37mi\u001b[0;37m-\u001b[0;37mE\u001b[0;37ml\u001b[0;37mf\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mC\u001b[0;37mh\u001b[0;37ma\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m8\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m3\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m3\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m8\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mV\u001b[0;37ma\u001b[0;37ml\n",
      "\u001b[0;37m-\u001b[0;37mD\u001b[0;37mw\u001b[0;37ma\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mL\u001b[0;37ma\u001b[0;37mw\u001b[0;30m \u001b[0;37me\u001b[0;37ms\u001b[0;37mc\u001b[0;37ma\u001b[0;37mp\u001b[0;37me\u001b[0;37md\u001b[0;30m \u001b[0;37mt\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37md\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;37m[\u001b[0;37mm\u001b[0;37ma\u001b[0;37mx\u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m]\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m8\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m8\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m4\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mA\u001b[0;37mr\u001b[0;37mc\u001b[0;37m-\u001b[0;37mG\u001b[0;37mn\u001b[0;37mo\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mN\u001b[0;37me\u001b[0;37mu\u001b[0;30m \n",
      "\u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m2\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m2\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m5\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mB\u001b[0;37ma\u001b[0;37mr\u001b[0;37m-\u001b[0;37mH\u001b[0;37mu\u001b[0;37mm\u001b[0;37m-\u001b[0;37mM\u001b[0;37ma\u001b[0;37ml\u001b[0;37m-\u001b[0;37mC\u001b[0;37mh\u001b[0;37ma\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \n",
      "\u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m6\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m6\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m0\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mP\u001b[0;37mr\u001b[0;37mi\u001b[0;37m-\u001b[0;37mH\u001b[0;37mu\u001b[0;37mm\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mN\u001b[0;37me\u001b[0;37mu\u001b[0;30m \u001b[0;37md\u001b[0;37mi\u001b[0;37me\u001b[0;37md\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \n",
      "\u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;37mK\u001b[0;37mi\u001b[0;37ml\u001b[0;37ml\u001b[0;37me\u001b[0;37md\u001b[0;30m \u001b[0;37mb\u001b[0;37my\u001b[0;30m \u001b[0;37ma\u001b[0;30m \u001b[0;37mk\u001b[0;37mo\u001b[0;37mb\u001b[0;37mo\u001b[0;37ml\u001b[0;37md\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m-\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m4\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def concat_state(state):\n",
    "    state = np.stack((state['glyphs'], state['chars'], state['colors'], state['specials']))\n",
    "    state = torch.tensor(np.expand_dims(state, axis=0), device=device)\n",
    "    return state\n",
    "\n",
    "\n",
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    state = concat_state(obs)\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        obs, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        # Keep track of current state and previous states \n",
    "        last_state = state\n",
    "        state = concat_state(obs)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(StateTransition(last_state, action, state, reward))\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2c4a8571-aacc-45e4-a0c5-bc8bbf358ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165571"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(episode_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8edfcdb5-8edd-4e3c-b6e3-b58add25ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = [x.reward for x in memory.memory]\n",
    "max(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dd39b-f1b4-437c-b1ae-67646435f955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
