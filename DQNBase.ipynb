{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3152b05-ea41-48d6-ae39-8f31a47d7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import Statements: From PyTorch RL Tutorial\n",
    "\"\"\"\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nle\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "env = gym.make('NetHackChallenge-v0', savedir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e3036ff0-7543-4bea-b0f6-072f82046c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This model stores each individual experience replay.\n",
    "\"\"\"\n",
    "class Experience():\n",
    "    def __init__(self, state, action, next_state, reward):\n",
    "        self.state - state\n",
    "        self.action = action\n",
    "        self.next_state = next_state\n",
    "        self.reward = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7ed681f1-946b-43d7-8501-5cf8559333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "StateTransition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a812f967-c70f-44ff-b1ff-5039839ba27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This model stores replays of memories as a whole. It also holds the full set, and manages removing old memories.\n",
    "\"\"\"\n",
    "class ReplayMemory():\n",
    "    def __init__(self, max_memory):\n",
    "        self.memory = []\n",
    "        self.max_memory = max_memory\n",
    "    \n",
    "    def push(self, newExp):\n",
    "        if len(self.memory) >= self.max_memory:\n",
    "            self.memory.pop(0)\n",
    "        self.memory.append(newExp)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d86cfce-7013-4876-9048-3682f4383e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DQN implementation, with convolutional layers, max pooling implemented.\n",
    "\"\"\"\n",
    "class DQNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQNetwork, self).__init__()\n",
    "        self.joe = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(), # 21 * 79 * 16\n",
    "            nn.MaxPool2d(3, padding=(0,1)), # 7 * 27 * 16\n",
    "            nn.Conv2d(16, 64, kernel_size=3, padding='same'),# 7 * 27 * 64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, padding=(1,0)), # 3 * 9 * 64\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*9*64, 3*64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3*64, 113),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.joe(x.float())\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fad4af8e-cbf3-449f-98f1-10b37fe0add3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 21, 79])\n"
     ]
    }
   ],
   "source": [
    "x = np.load('l.txt.npy')\n",
    "x = torch.Tensor(x)[None,:,:,:]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "103c2869-efd2-4be5-97d1-9d84acb6e1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5820, -0.0145, -0.1973, -0.1992,  0.2478, -0.0486, -0.3093, -0.5386,\n",
       "         -0.3617,  0.3553, -0.1044,  0.0896,  0.3319,  0.0839,  0.3118, -0.1289,\n",
       "          0.6876, -0.3061,  0.2591, -0.1896, -0.2452, -0.3310,  0.4667, -0.0732,\n",
       "          0.0860,  0.2486,  0.4494, -0.1109, -0.2731, -0.3920, -0.3173,  0.1012,\n",
       "         -0.3699,  0.3519, -0.5330,  0.1259,  0.2164,  0.1370,  0.0064,  0.1190,\n",
       "         -0.4528,  0.3458,  0.1344, -0.0987,  0.1707, -0.2028, -0.1253,  0.2144,\n",
       "         -0.1029,  0.3621, -0.2257,  0.3409,  0.3094,  0.2402, -0.4096,  0.4916,\n",
       "          0.4554,  0.2320, -0.2696,  0.0756,  0.1477, -0.0558, -0.1738,  0.0380,\n",
       "          0.3713, -0.7179, -0.0909, -0.0165, -0.0039,  0.2123, -0.2760, -0.0745,\n",
       "          0.1062, -0.7338, -0.1024, -0.3925,  0.4214, -0.5662,  0.0836, -0.1241,\n",
       "         -0.2492, -0.0139,  0.1420,  0.1919,  0.1639, -0.0694,  0.1629,  0.0275,\n",
       "          0.1929, -0.1990,  0.0890,  0.3104,  0.0475, -0.4032,  0.3717,  0.0449,\n",
       "          0.1330,  0.3433, -0.2100, -0.3346,  0.0809, -0.3081,  0.1304, -0.0708,\n",
       "          0.0313, -0.3098,  0.0753, -0.3943,  0.1577, -0.1646, -0.4376,  0.3681,\n",
       "          0.4656]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bink = DQNetwork()\n",
    "bink.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ca06b4e-d88d-4337-b7c0-206af1aed284",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "steps_done = 0\n",
    "episode_durations = []\n",
    "n_actions = env.action_space.n\n",
    "# All of the batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "83cea590-47b5-4877-8221-2da09dd176c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQNetwork().to(device)\n",
    "target_net = DQNetwork().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b286d76a-a79f-41a5-ad74-aed2db2f37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4893b7d4-05cf-40d6-a194-4574f163eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(iter_num):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = StateTransition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    if iter_num % 100 == 0:\n",
    "        print('Iteration number ' + str(iter_num) + ' loss: ' + str(loss.item()))\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ce7c3ad-ab9d-4d04-82b4-03e3c916761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Number: 0\n",
      "Iteration number 0 loss: 6.063097953796387\n",
      "Iteration number 100 loss: 5.312196731567383\n",
      "Iteration number 200 loss: 5.266094207763672\n",
      "Iteration number 300 loss: 4.826352119445801\n",
      "Iteration number 400 loss: 5.324923515319824\n",
      "Iteration number 500 loss: 5.1598029136657715\n",
      "Iteration number 600 loss: 4.959875583648682\n",
      "Iteration number 700 loss: 5.1431427001953125\n",
      "Iteration number 800 loss: 5.475369930267334\n",
      "Iteration number 900 loss: 5.263668537139893\n",
      "Iteration number 1000 loss: 5.570958614349365\n",
      "Iteration number 1100 loss: 4.899526596069336\n",
      "Iteration number 1200 loss: 4.876068592071533\n",
      "Iteration number 1300 loss: 4.815316200256348\n",
      "Iteration number 1400 loss: 4.18011474609375\n",
      "Iteration number 1500 loss: 5.1479597091674805\n",
      "Iteration number 1600 loss: 5.231861114501953\n",
      "Iteration number 1700 loss: 5.413294792175293\n",
      "Iteration number 1800 loss: 5.127189636230469\n",
      "Iteration number 1900 loss: 4.941763877868652\n",
      "Iteration number 2000 loss: 4.384138107299805\n",
      "Iteration number 2100 loss: 4.927384376525879\n",
      "Iteration number 2200 loss: 5.10919713973999\n",
      "Iteration number 2300 loss: 4.544266223907471\n",
      "Iteration number 2400 loss: 4.693434715270996\n",
      "Iteration number 2500 loss: 4.9939422607421875\n",
      "Iteration number 2600 loss: 4.28806734085083\n",
      "Iteration number 2700 loss: 5.115417003631592\n",
      "Iteration number 2800 loss: 5.19580602645874\n",
      "Iteration number 2900 loss: 5.008608341217041\n",
      "Iteration number 3000 loss: 4.588536262512207\n",
      "Iteration number 3100 loss: 5.006666660308838\n",
      "Iteration number 3200 loss: 4.79035758972168\n",
      "Iteration number 3300 loss: 4.992922782897949\n",
      "Iteration number 3400 loss: 5.23337459564209\n",
      "Iteration number 3500 loss: 4.76837158203125\n",
      "Iteration number 3600 loss: 4.8191022872924805\n",
      "Iteration number 3700 loss: 4.8591461181640625\n",
      "Iteration number 3800 loss: 4.455713748931885\n",
      "Iteration number 3900 loss: 4.912102222442627\n",
      "Iteration number 4000 loss: 4.523871421813965\n",
      "Iteration number 4100 loss: 5.111042022705078\n",
      "Iteration number 4200 loss: 4.407190799713135\n",
      "Iteration number 4300 loss: 4.6222686767578125\n",
      "Iteration number 4400 loss: 4.540738582611084\n",
      "Iteration number 4500 loss: 5.361352920532227\n",
      "Iteration number 4600 loss: 4.458252906799316\n",
      "Iteration number 4700 loss: 5.037332534790039\n",
      "Iteration number 4800 loss: 4.805472373962402\n",
      "Iteration number 4900 loss: 4.293991565704346\n",
      "Iteration number 5000 loss: 4.581597328186035\n",
      "Iteration number 5100 loss: 4.198244094848633\n",
      "Iteration number 5200 loss: 4.386966228485107\n",
      "Iteration number 5300 loss: 5.140908718109131\n",
      "Iteration number 5400 loss: 4.359687805175781\n",
      "Iteration number 5500 loss: 4.713439464569092\n",
      "Iteration number 5600 loss: 4.422030448913574\n",
      "Iteration number 5700 loss: 4.847017288208008\n",
      "Iteration number 5800 loss: 4.221773147583008\n",
      "Iteration number 5900 loss: 4.876473426818848\n",
      "Iteration number 6000 loss: 4.120296478271484\n",
      "Iteration number 6100 loss: 4.03264045715332\n",
      "Iteration number 6200 loss: 3.9013915061950684\n",
      "Iteration number 6300 loss: 4.009123802185059\n",
      "Iteration number 6400 loss: 4.668182373046875\n",
      "Iteration number 6500 loss: 5.225872993469238\n",
      "Iteration number 6600 loss: 4.473191738128662\n",
      "Iteration number 6700 loss: 4.858104705810547\n",
      "Iteration number 6800 loss: 4.747164726257324\n",
      "Iteration number 6900 loss: 4.201568603515625\n",
      "Iteration number 7000 loss: 4.26410436630249\n",
      "Iteration number 7100 loss: 5.100022315979004\n",
      "Iteration number 7200 loss: 5.059239864349365\n",
      "Iteration number 7300 loss: 4.045450210571289\n",
      "Iteration number 7400 loss: 4.735687255859375\n",
      "Iteration number 7500 loss: 4.987771034240723\n",
      "Iteration number 7600 loss: 4.442971706390381\n",
      "Iteration number 7700 loss: 4.308655261993408\n",
      "Iteration number 7800 loss: 4.485835075378418\n",
      "Iteration number 7900 loss: 4.640231609344482\n",
      "Iteration number 8000 loss: 4.395308494567871\n",
      "Iteration number 8100 loss: 4.815537929534912\n",
      "Iteration number 8200 loss: 4.459857940673828\n",
      "Iteration number 8300 loss: 4.501885414123535\n",
      "Iteration number 8400 loss: 4.983985424041748\n",
      "Iteration number 8500 loss: 4.278594970703125\n",
      "Iteration number 8600 loss: 4.727802276611328\n",
      "Iteration number 8700 loss: 4.38942813873291\n",
      "Iteration number 8800 loss: 5.027022838592529\n",
      "Iteration number 8900 loss: 4.804959297180176\n",
      "Iteration number 9000 loss: 4.899463653564453\n",
      "Iteration number 9100 loss: 4.677371025085449\n",
      "Iteration number 9200 loss: 4.291707992553711\n",
      "Iteration number 9300 loss: 4.57747745513916\n",
      "Iteration number 9400 loss: 4.488766670227051\n",
      "Iteration number 9500 loss: 4.855718612670898\n",
      "Iteration number 9600 loss: 4.664656639099121\n",
      "Iteration number 9700 loss: 4.5276336669921875\n",
      "Iteration number 9800 loss: 4.870335578918457\n",
      "Iteration number 9900 loss: 4.540011405944824\n",
      "Iteration number 10000 loss: 4.413348197937012\n",
      "Iteration number 10100 loss: 4.772674083709717\n",
      "Iteration number 10200 loss: 4.813429832458496\n",
      "Iteration number 10300 loss: 4.996635437011719\n",
      "Iteration number 10400 loss: 4.353508949279785\n",
      "Iteration number 10500 loss: 4.450425148010254\n",
      "Iteration number 10600 loss: 4.572017192840576\n",
      "Iteration number 10700 loss: 4.494804382324219\n",
      "Iteration number 10800 loss: 4.832267761230469\n",
      "Iteration number 10900 loss: 4.455127239227295\n",
      "Iteration number 11000 loss: 4.198571681976318\n",
      "Iteration number 11100 loss: 4.654030799865723\n",
      "Iteration number 11200 loss: 4.265851974487305\n",
      "Iteration number 11300 loss: 4.132838249206543\n",
      "Iteration number 11400 loss: 4.555966377258301\n",
      "Iteration number 11500 loss: 4.33854341506958\n",
      "Iteration number 11600 loss: 4.638643264770508\n",
      "Iteration number 11700 loss: 4.660921573638916\n",
      "Iteration number 11800 loss: 4.34773588180542\n",
      "Iteration number 11900 loss: 4.100973606109619\n",
      "Iteration number 12000 loss: 4.359800338745117\n",
      "Iteration number 12100 loss: 4.608888149261475\n",
      "Iteration number 12200 loss: 4.54862117767334\n",
      "Iteration number 12300 loss: 4.491495132446289\n",
      "Iteration number 12400 loss: 4.3656744956970215\n",
      "Iteration number 12500 loss: 4.453423976898193\n",
      "Iteration number 12600 loss: 4.537663459777832\n",
      "Iteration number 12700 loss: 4.781511306762695\n",
      "Iteration number 12800 loss: 4.372840881347656\n",
      "Iteration number 12900 loss: 5.047296524047852\n",
      "Iteration number 13000 loss: 4.011071681976318\n",
      "Iteration number 13100 loss: 4.324594497680664\n",
      "Iteration number 13200 loss: 4.618926525115967\n",
      "Iteration number 13300 loss: 4.634988784790039\n",
      "Iteration number 13400 loss: 4.162720680236816\n",
      "Iteration number 13500 loss: 3.804905652999878\n",
      "Iteration number 13600 loss: 4.6833600997924805\n",
      "Iteration number 13700 loss: 4.336758136749268\n",
      "Iteration number 13800 loss: 4.341185569763184\n",
      "Iteration number 13900 loss: 4.764897346496582\n",
      "Iteration number 14000 loss: 4.514708042144775\n",
      "Iteration number 14100 loss: 4.702441215515137\n",
      "Iteration number 14200 loss: 4.656055450439453\n",
      "Iteration number 14300 loss: 4.604795932769775\n",
      "Iteration number 14400 loss: 4.2550811767578125\n",
      "Iteration number 14500 loss: 4.535223960876465\n",
      "Iteration number 14600 loss: 4.381093978881836\n",
      "Iteration number 14700 loss: 4.5981879234313965\n",
      "Iteration number 14800 loss: 4.225797653198242\n",
      "Iteration number 14900 loss: 3.966275215148926\n",
      "Iteration number 15000 loss: 4.270423889160156\n",
      "Iteration number 15100 loss: 4.849001884460449\n",
      "Iteration number 15200 loss: 4.654446125030518\n",
      "Iteration number 15300 loss: 4.87213134765625\n",
      "Iteration number 15400 loss: 4.312761306762695\n",
      "Iteration number 15500 loss: 5.1391377449035645\n",
      "Iteration number 15600 loss: 4.69706392288208\n",
      "Iteration number 15700 loss: 4.661599159240723\n",
      "Iteration number 15800 loss: 4.713066101074219\n",
      "Episode Number: 1\n",
      "Iteration number 0 loss: 2.925581216812134\n",
      "Iteration number 100 loss: 4.8892412185668945\n",
      "Iteration number 200 loss: 4.720792770385742\n",
      "Iteration number 300 loss: 4.645622253417969\n",
      "Iteration number 400 loss: 4.826572895050049\n",
      "Iteration number 500 loss: 4.403861999511719\n",
      "Iteration number 600 loss: 4.427852630615234\n",
      "Iteration number 700 loss: 4.773670673370361\n",
      "Iteration number 800 loss: 5.4069318771362305\n",
      "Iteration number 900 loss: 4.935268402099609\n",
      "Iteration number 1000 loss: 4.649036407470703\n",
      "Iteration number 1100 loss: 4.356722831726074\n",
      "Iteration number 1200 loss: 4.395438194274902\n",
      "Iteration number 1300 loss: 5.000799179077148\n",
      "Iteration number 1400 loss: 4.588070869445801\n",
      "Iteration number 1500 loss: 4.740935802459717\n",
      "Iteration number 1600 loss: 4.652195453643799\n",
      "Iteration number 1700 loss: 4.999300003051758\n",
      "Iteration number 1800 loss: 4.2325286865234375\n",
      "Iteration number 1900 loss: 4.282197952270508\n",
      "Iteration number 2000 loss: 4.359228610992432\n",
      "Iteration number 2100 loss: 4.74109411239624\n",
      "Iteration number 2200 loss: 5.082409381866455\n",
      "Iteration number 2300 loss: 5.0994157791137695\n",
      "Iteration number 2400 loss: 5.069060325622559\n",
      "Iteration number 2500 loss: 4.049290657043457\n",
      "Iteration number 2600 loss: 4.5831098556518555\n",
      "Iteration number 2700 loss: 4.796069145202637\n",
      "Iteration number 2800 loss: 4.452798843383789\n",
      "Iteration number 2900 loss: 4.004805088043213\n",
      "Iteration number 3000 loss: 4.548094749450684\n",
      "Iteration number 3100 loss: 4.662894248962402\n",
      "Iteration number 3200 loss: 4.545604705810547\n",
      "Iteration number 3300 loss: 5.114846229553223\n",
      "Iteration number 3400 loss: 4.633028984069824\n",
      "Iteration number 3500 loss: 4.226184844970703\n",
      "Iteration number 3600 loss: 5.0593719482421875\n",
      "Iteration number 3700 loss: 4.629393100738525\n",
      "Iteration number 3800 loss: 4.838454723358154\n",
      "Iteration number 3900 loss: 5.2389326095581055\n",
      "Iteration number 4000 loss: 4.368745803833008\n",
      "Iteration number 4100 loss: 5.162039279937744\n",
      "Iteration number 4200 loss: 4.736987113952637\n",
      "Iteration number 4300 loss: 4.580986022949219\n",
      "Iteration number 4400 loss: 4.333026885986328\n",
      "Iteration number 4500 loss: 4.592608451843262\n",
      "Iteration number 4600 loss: 4.748682975769043\n",
      "Iteration number 4700 loss: 4.615644931793213\n",
      "Iteration number 4800 loss: 4.945827484130859\n",
      "Iteration number 4900 loss: 3.9688987731933594\n",
      "Iteration number 5000 loss: 4.762963771820068\n",
      "Iteration number 5100 loss: 4.800978183746338\n",
      "Iteration number 5200 loss: 5.152888298034668\n",
      "Iteration number 5300 loss: 4.585667133331299\n",
      "Iteration number 5400 loss: 4.310366153717041\n",
      "Iteration number 5500 loss: 4.313529968261719\n",
      "Iteration number 5600 loss: 4.629687309265137\n",
      "Iteration number 5700 loss: 4.592857360839844\n",
      "Iteration number 5800 loss: 4.708907604217529\n",
      "Iteration number 5900 loss: 4.706448554992676\n",
      "Iteration number 6000 loss: 4.521752834320068\n",
      "Iteration number 6100 loss: 4.5373687744140625\n",
      "Iteration number 6200 loss: 4.957708835601807\n",
      "Iteration number 6300 loss: 4.739439487457275\n",
      "Iteration number 6400 loss: 4.741506576538086\n",
      "Iteration number 6500 loss: 4.810170650482178\n",
      "Iteration number 6600 loss: 4.427321434020996\n",
      "Iteration number 6700 loss: 4.371676445007324\n",
      "Iteration number 6800 loss: 4.764358043670654\n",
      "Iteration number 6900 loss: 3.8487117290496826\n",
      "Iteration number 7000 loss: 4.3508524894714355\n",
      "Iteration number 7100 loss: 4.333559513092041\n",
      "Iteration number 7200 loss: 4.810309886932373\n",
      "Iteration number 7300 loss: 4.826721668243408\n",
      "Iteration number 7400 loss: 4.7291741371154785\n",
      "Iteration number 7500 loss: 4.663399696350098\n",
      "Iteration number 7600 loss: 4.194510459899902\n",
      "Iteration number 7700 loss: 4.423694610595703\n",
      "Iteration number 7800 loss: 4.6045823097229\n",
      "Iteration number 7900 loss: 4.896811485290527\n",
      "Iteration number 8000 loss: 5.309804916381836\n",
      "Iteration number 8100 loss: 4.4944915771484375\n",
      "Iteration number 8200 loss: 4.995110511779785\n",
      "Iteration number 8300 loss: 4.620121955871582\n",
      "Iteration number 8400 loss: 4.797530174255371\n",
      "Iteration number 8500 loss: 4.612209320068359\n",
      "Iteration number 8600 loss: 4.996293067932129\n",
      "Iteration number 8700 loss: 4.165384292602539\n",
      "Iteration number 8800 loss: 4.439528465270996\n",
      "Iteration number 8900 loss: 4.909159183502197\n",
      "Iteration number 9000 loss: 4.574377536773682\n",
      "Iteration number 9100 loss: 4.794347763061523\n",
      "Iteration number 9200 loss: 4.725767135620117\n",
      "Iteration number 9300 loss: 4.084221839904785\n",
      "Iteration number 9400 loss: 4.375733375549316\n",
      "Iteration number 9500 loss: 5.312694549560547\n",
      "Iteration number 9600 loss: 4.352288246154785\n",
      "Iteration number 9700 loss: 5.0558671951293945\n",
      "Iteration number 9800 loss: 4.9814276695251465\n",
      "Iteration number 9900 loss: 4.093048572540283\n",
      "Iteration number 10000 loss: 4.524252891540527\n",
      "Iteration number 10100 loss: 4.504829406738281\n",
      "Iteration number 10200 loss: 4.854836940765381\n",
      "Iteration number 10300 loss: 4.369476318359375\n",
      "Iteration number 10400 loss: 4.788617134094238\n",
      "Iteration number 10500 loss: 4.539978981018066\n",
      "Iteration number 10600 loss: 4.562335968017578\n",
      "Iteration number 10700 loss: 4.188467025756836\n",
      "Iteration number 10800 loss: 4.7414140701293945\n",
      "Iteration number 10900 loss: 4.672977447509766\n",
      "Iteration number 11000 loss: 4.914243698120117\n",
      "Iteration number 11100 loss: 5.474521636962891\n",
      "Iteration number 11200 loss: 4.888020038604736\n",
      "Iteration number 11300 loss: 4.967197418212891\n",
      "Iteration number 11400 loss: 4.706820964813232\n",
      "Iteration number 11500 loss: 4.254327774047852\n",
      "Iteration number 11600 loss: 4.493291854858398\n",
      "Iteration number 11700 loss: 4.903001308441162\n",
      "Iteration number 11800 loss: 4.584089279174805\n",
      "Iteration number 11900 loss: 4.353693008422852\n",
      "Iteration number 12000 loss: 5.024774551391602\n",
      "Iteration number 12100 loss: 5.352592945098877\n",
      "Iteration number 12200 loss: 4.9936323165893555\n",
      "Iteration number 12300 loss: 4.687219142913818\n",
      "Iteration number 12400 loss: 4.93587589263916\n",
      "Iteration number 12500 loss: 4.543407440185547\n",
      "Iteration number 12600 loss: 4.261054992675781\n",
      "Iteration number 12700 loss: 5.264610767364502\n",
      "Iteration number 12800 loss: 4.415622234344482\n",
      "Iteration number 12900 loss: 4.617066383361816\n",
      "Iteration number 13000 loss: 4.964866638183594\n",
      "Iteration number 13100 loss: 4.710412979125977\n",
      "Iteration number 13200 loss: 4.239398002624512\n",
      "Iteration number 13300 loss: 4.934628486633301\n",
      "Iteration number 13400 loss: 5.4026923179626465\n",
      "Iteration number 13500 loss: 4.660227298736572\n",
      "Iteration number 13600 loss: 4.57524299621582\n",
      "Iteration number 13700 loss: 4.771032333374023\n",
      "Iteration number 13800 loss: 5.00994873046875\n",
      "Iteration number 13900 loss: 5.345132827758789\n",
      "Iteration number 14000 loss: 4.840573787689209\n",
      "Iteration number 14100 loss: 5.236289024353027\n",
      "Iteration number 14200 loss: 4.9188995361328125\n",
      "Iteration number 14300 loss: 4.281770706176758\n",
      "Iteration number 14400 loss: 4.699895858764648\n",
      "Iteration number 14500 loss: 4.63167142868042\n",
      "Iteration number 14600 loss: 4.420937538146973\n",
      "Iteration number 14700 loss: 4.228639602661133\n",
      "Iteration number 14800 loss: 4.182736396789551\n",
      "Iteration number 14900 loss: 4.6023664474487305\n",
      "Iteration number 15000 loss: 4.306360721588135\n",
      "Iteration number 15100 loss: 4.504589557647705\n",
      "Iteration number 15200 loss: 4.868096351623535\n",
      "Iteration number 15300 loss: 4.159859657287598\n",
      "Iteration number 15400 loss: 4.223570346832275\n",
      "Iteration number 15500 loss: 4.197321891784668\n",
      "Iteration number 15600 loss: 4.4180731773376465\n",
      "Iteration number 15700 loss: 4.500548362731934\n",
      "Iteration number 15800 loss: 4.664670944213867\n",
      "Iteration number 15900 loss: 5.080757141113281\n",
      "Iteration number 16000 loss: 4.343899250030518\n",
      "Iteration number 16100 loss: 4.658840656280518\n",
      "Iteration number 16200 loss: 4.727379322052002\n",
      "Iteration number 16300 loss: 4.729803085327148\n",
      "Iteration number 16400 loss: 5.245687007904053\n",
      "Iteration number 16500 loss: 3.814880132675171\n",
      "Iteration number 16600 loss: 3.8943393230438232\n",
      "Iteration number 16700 loss: 4.432258129119873\n",
      "Iteration number 16800 loss: 3.942889451980591\n",
      "Iteration number 16900 loss: 4.552361011505127\n",
      "Iteration number 17000 loss: 4.095210552215576\n",
      "Iteration number 17100 loss: 4.441434860229492\n",
      "Iteration number 17200 loss: 4.137441635131836\n",
      "Iteration number 17300 loss: 4.396328926086426\n",
      "Iteration number 17400 loss: 4.352267742156982\n",
      "Iteration number 17500 loss: 4.337576866149902\n",
      "Iteration number 17600 loss: 3.740913152694702\n",
      "Iteration number 17700 loss: 4.299587249755859\n",
      "Iteration number 17800 loss: 4.211627960205078\n",
      "Iteration number 17900 loss: 4.656156063079834\n",
      "Iteration number 18000 loss: 4.273999214172363\n",
      "Iteration number 18100 loss: 4.164587497711182\n",
      "Iteration number 18200 loss: 4.114345073699951\n",
      "Iteration number 18300 loss: 4.632932186126709\n",
      "Iteration number 18400 loss: 4.014220237731934\n",
      "Iteration number 18500 loss: 4.278545379638672\n",
      "Iteration number 18600 loss: 4.220526695251465\n",
      "Iteration number 18700 loss: 4.769181728363037\n",
      "Iteration number 18800 loss: 3.7906596660614014\n",
      "Iteration number 18900 loss: 4.787405014038086\n",
      "Iteration number 19000 loss: 4.078652381896973\n",
      "Iteration number 19100 loss: 4.483709335327148\n",
      "Iteration number 19200 loss: 4.238182544708252\n",
      "Iteration number 19300 loss: 4.487163066864014\n",
      "Iteration number 19400 loss: 4.432655334472656\n",
      "Iteration number 19500 loss: 4.455066680908203\n",
      "Iteration number 19600 loss: 3.9107937812805176\n",
      "Iteration number 19700 loss: 4.205129623413086\n",
      "Iteration number 19800 loss: 4.138980388641357\n",
      "Iteration number 19900 loss: 4.710085868835449\n",
      "Iteration number 20000 loss: 4.377135753631592\n",
      "Iteration number 20100 loss: 4.240756034851074\n",
      "Iteration number 20200 loss: 4.363423824310303\n",
      "Iteration number 20300 loss: 3.655698537826538\n",
      "Iteration number 20400 loss: 4.100161552429199\n",
      "Iteration number 20500 loss: 4.480726718902588\n",
      "Iteration number 20600 loss: 3.9456419944763184\n",
      "Iteration number 20700 loss: 4.208600044250488\n",
      "Iteration number 20800 loss: 4.791483402252197\n",
      "Iteration number 20900 loss: 4.346748352050781\n",
      "Iteration number 21000 loss: 4.202452182769775\n",
      "Iteration number 21100 loss: 4.418395042419434\n",
      "Iteration number 21200 loss: 4.491271018981934\n",
      "Iteration number 21300 loss: 3.951455593109131\n",
      "Iteration number 21400 loss: 4.346188545227051\n",
      "Iteration number 21500 loss: 4.74505090713501\n",
      "Iteration number 21600 loss: 4.238094329833984\n",
      "Iteration number 21700 loss: 4.336481094360352\n",
      "Iteration number 21800 loss: 4.432117938995361\n",
      "Iteration number 21900 loss: 4.564619064331055\n",
      "Iteration number 22000 loss: 4.362676620483398\n",
      "Iteration number 22100 loss: 3.994096279144287\n",
      "Iteration number 22200 loss: 4.4711384773254395\n",
      "Iteration number 22300 loss: 4.586302280426025\n",
      "Iteration number 22400 loss: 4.312453269958496\n",
      "Iteration number 22500 loss: 4.019784450531006\n",
      "Iteration number 22600 loss: 4.664979934692383\n",
      "Iteration number 22700 loss: 4.74896240234375\n",
      "Iteration number 22800 loss: 4.835564613342285\n",
      "Iteration number 22900 loss: 4.214606761932373\n",
      "Iteration number 23000 loss: 4.424576282501221\n",
      "Iteration number 23100 loss: 4.639355659484863\n",
      "Iteration number 23200 loss: 4.1684794425964355\n",
      "Iteration number 23300 loss: 3.8673791885375977\n",
      "Iteration number 23400 loss: 4.098280906677246\n",
      "Iteration number 23500 loss: 4.566821098327637\n",
      "Iteration number 23600 loss: 4.051447868347168\n",
      "Iteration number 23700 loss: 4.30888557434082\n",
      "Iteration number 23800 loss: 4.66682243347168\n",
      "Iteration number 23900 loss: 4.195552825927734\n",
      "Iteration number 24000 loss: 4.564136028289795\n",
      "Iteration number 24100 loss: 4.255102634429932\n",
      "Iteration number 24200 loss: 4.01534366607666\n",
      "Iteration number 24300 loss: 4.2339324951171875\n",
      "Iteration number 24400 loss: 4.480334758758545\n",
      "Iteration number 24500 loss: 4.215779781341553\n",
      "Iteration number 24600 loss: 4.196676731109619\n",
      "Iteration number 24700 loss: 4.57892370223999\n",
      "Iteration number 24800 loss: 4.123088359832764\n",
      "Iteration number 24900 loss: 4.9345808029174805\n",
      "Iteration number 25000 loss: 3.941216468811035\n",
      "Iteration number 25100 loss: 4.107199192047119\n",
      "Iteration number 25200 loss: 4.419607162475586\n",
      "Iteration number 25300 loss: 4.0919952392578125\n",
      "Iteration number 25400 loss: 3.749570608139038\n",
      "Iteration number 25500 loss: 4.086766242980957\n",
      "Iteration number 25600 loss: 4.242684364318848\n",
      "Iteration number 25700 loss: 4.0761919021606445\n",
      "Iteration number 25800 loss: 4.159440040588379\n",
      "Iteration number 25900 loss: 4.519900321960449\n",
      "Iteration number 26000 loss: 4.051258563995361\n",
      "Iteration number 26100 loss: 4.264703750610352\n",
      "Iteration number 26200 loss: 4.43196964263916\n",
      "Iteration number 26300 loss: 4.766584396362305\n",
      "Iteration number 26400 loss: 4.700702667236328\n",
      "Iteration number 26500 loss: 4.275103569030762\n",
      "Iteration number 26600 loss: 4.148465156555176\n",
      "Iteration number 26700 loss: 4.312368869781494\n",
      "Iteration number 26800 loss: 4.712579727172852\n",
      "Iteration number 26900 loss: 4.224174499511719\n",
      "Iteration number 27000 loss: 4.135100364685059\n",
      "Iteration number 27100 loss: 4.626312255859375\n",
      "Iteration number 27200 loss: 4.637852668762207\n",
      "Iteration number 27300 loss: 4.05504035949707\n",
      "Iteration number 27400 loss: 4.5413970947265625\n",
      "Iteration number 27500 loss: 4.771657943725586\n",
      "Iteration number 27600 loss: 4.405298709869385\n",
      "Iteration number 27700 loss: 4.051826477050781\n",
      "Iteration number 27800 loss: 4.302850723266602\n",
      "Iteration number 27900 loss: 4.128473281860352\n",
      "Iteration number 28000 loss: 4.246404647827148\n",
      "Iteration number 28100 loss: 3.803788185119629\n",
      "Iteration number 28200 loss: 4.1666579246521\n",
      "Iteration number 28300 loss: 4.223081588745117\n",
      "Iteration number 28400 loss: 4.266358375549316\n",
      "Iteration number 28500 loss: 4.403558731079102\n",
      "Iteration number 28600 loss: 4.410365104675293\n",
      "Iteration number 28700 loss: 4.2479143142700195\n",
      "Iteration number 28800 loss: 4.335659980773926\n",
      "Iteration number 28900 loss: 3.765279769897461\n",
      "Iteration number 29000 loss: 4.680346965789795\n",
      "Iteration number 29100 loss: 4.462661266326904\n",
      "Iteration number 29200 loss: 4.184778690338135\n",
      "Iteration number 29300 loss: 4.556392192840576\n",
      "Iteration number 29400 loss: 4.069913864135742\n",
      "Iteration number 29500 loss: 4.402714729309082\n",
      "Iteration number 29600 loss: 4.216899871826172\n",
      "Iteration number 29700 loss: 4.16143798828125\n",
      "Iteration number 29800 loss: 4.231697082519531\n",
      "Iteration number 29900 loss: 4.343879699707031\n",
      "Iteration number 30000 loss: 4.136190414428711\n",
      "Iteration number 30100 loss: 5.086422443389893\n",
      "Iteration number 30200 loss: 4.431386947631836\n",
      "Iteration number 30300 loss: 4.5196051597595215\n",
      "Iteration number 30400 loss: 4.265666961669922\n",
      "Iteration number 30500 loss: 4.251580238342285\n",
      "Iteration number 30600 loss: 4.117459297180176\n",
      "Iteration number 30700 loss: 4.227349758148193\n",
      "Iteration number 30800 loss: 4.644847869873047\n",
      "Iteration number 30900 loss: 4.508927345275879\n",
      "Iteration number 31000 loss: 4.395793914794922\n",
      "Iteration number 31100 loss: 4.044159889221191\n",
      "Iteration number 31200 loss: 4.188794136047363\n",
      "Iteration number 31300 loss: 4.368356704711914\n",
      "Iteration number 31400 loss: 4.258976936340332\n",
      "Iteration number 31500 loss: 3.8134663105010986\n",
      "Iteration number 31600 loss: 4.059352874755859\n",
      "Iteration number 31700 loss: 4.377423286437988\n",
      "Iteration number 31800 loss: 4.178747177124023\n",
      "Iteration number 31900 loss: 4.586296558380127\n",
      "Iteration number 32000 loss: 4.586350440979004\n",
      "Iteration number 32100 loss: 4.5558881759643555\n",
      "Iteration number 32200 loss: 4.266040325164795\n",
      "Iteration number 32300 loss: 4.421472549438477\n",
      "Iteration number 32400 loss: 4.577916622161865\n",
      "Iteration number 32500 loss: 4.0034284591674805\n",
      "Iteration number 32600 loss: 4.072663307189941\n",
      "Iteration number 32700 loss: 4.0515594482421875\n",
      "Iteration number 32800 loss: 4.297912120819092\n",
      "Iteration number 32900 loss: 4.519476890563965\n",
      "Iteration number 33000 loss: 4.102795600891113\n",
      "Iteration number 33100 loss: 4.968862533569336\n",
      "Iteration number 33200 loss: 4.251926422119141\n",
      "Iteration number 33300 loss: 4.967715740203857\n",
      "Iteration number 33400 loss: 4.325167179107666\n",
      "Iteration number 33500 loss: 4.063335418701172\n",
      "Iteration number 33600 loss: 4.554569244384766\n",
      "Iteration number 33700 loss: 4.692600250244141\n",
      "Iteration number 33800 loss: 3.8859758377075195\n",
      "Iteration number 33900 loss: 3.968416213989258\n",
      "Iteration number 34000 loss: 4.451476097106934\n",
      "Iteration number 34100 loss: 4.173795700073242\n",
      "Iteration number 34200 loss: 3.9594228267669678\n",
      "Iteration number 34300 loss: 4.540916442871094\n",
      "Iteration number 34400 loss: 4.454109191894531\n",
      "Iteration number 34500 loss: 3.965712785720825\n",
      "Iteration number 34600 loss: 3.9295406341552734\n",
      "Iteration number 34700 loss: 4.340462684631348\n",
      "Iteration number 34800 loss: 4.011183738708496\n",
      "Iteration number 34900 loss: 4.024180889129639\n",
      "Iteration number 35000 loss: 4.236201286315918\n",
      "Iteration number 35100 loss: 4.605251312255859\n",
      "Iteration number 35200 loss: 4.1232171058654785\n",
      "Iteration number 35300 loss: 4.489877700805664\n",
      "Iteration number 35400 loss: 4.391618728637695\n",
      "Iteration number 35500 loss: 4.239443778991699\n",
      "Iteration number 35600 loss: 4.233187198638916\n",
      "Iteration number 35700 loss: 4.545297622680664\n",
      "Iteration number 35800 loss: 4.494717121124268\n",
      "Iteration number 35900 loss: 4.083096504211426\n",
      "Iteration number 36000 loss: 4.587676048278809\n",
      "Iteration number 36100 loss: 4.363839149475098\n",
      "Iteration number 36200 loss: 4.648416042327881\n",
      "Iteration number 36300 loss: 4.26349401473999\n",
      "Iteration number 36400 loss: 4.313572883605957\n",
      "Iteration number 36500 loss: 4.190862655639648\n",
      "Iteration number 36600 loss: 4.077201843261719\n",
      "Iteration number 36700 loss: 3.7968051433563232\n",
      "Iteration number 36800 loss: 4.271401882171631\n",
      "Iteration number 36900 loss: 4.217138290405273\n",
      "Iteration number 37000 loss: 4.21891975402832\n",
      "Iteration number 37100 loss: 4.3011369705200195\n",
      "Iteration number 37200 loss: 4.157410144805908\n",
      "Iteration number 37300 loss: 4.732446670532227\n",
      "Iteration number 37400 loss: 4.655282020568848\n",
      "Iteration number 37500 loss: 4.274878978729248\n",
      "Iteration number 37600 loss: 4.755905628204346\n",
      "Iteration number 37700 loss: 4.4403581619262695\n",
      "Iteration number 37800 loss: 4.168282985687256\n",
      "Iteration number 37900 loss: 4.146893501281738\n",
      "Iteration number 38000 loss: 4.037388801574707\n",
      "Iteration number 38100 loss: 4.200219631195068\n",
      "Iteration number 38200 loss: 4.380798816680908\n",
      "Iteration number 38300 loss: 4.339003562927246\n",
      "Iteration number 38400 loss: 4.573855400085449\n",
      "Iteration number 38500 loss: 4.2277374267578125\n",
      "Iteration number 38600 loss: 3.8828020095825195\n",
      "Iteration number 38700 loss: 4.773005485534668\n",
      "Iteration number 38800 loss: 4.100940704345703\n",
      "Iteration number 38900 loss: 4.332198619842529\n",
      "Iteration number 39000 loss: 4.408868312835693\n",
      "Iteration number 39100 loss: 4.284465312957764\n",
      "Iteration number 39200 loss: 4.870091438293457\n",
      "Iteration number 39300 loss: 4.403473377227783\n",
      "Iteration number 39400 loss: 4.416566848754883\n",
      "Iteration number 39500 loss: 4.884881973266602\n",
      "Iteration number 39600 loss: 4.02168083190918\n",
      "Iteration number 39700 loss: 4.3883748054504395\n",
      "Iteration number 39800 loss: 3.669682741165161\n",
      "Iteration number 39900 loss: 4.168150424957275\n",
      "Iteration number 40000 loss: 4.342026233673096\n",
      "Iteration number 40100 loss: 4.260431289672852\n",
      "Iteration number 40200 loss: 3.9572603702545166\n",
      "Iteration number 40300 loss: 4.506801605224609\n",
      "Iteration number 40400 loss: 4.401554584503174\n",
      "Iteration number 40500 loss: 4.493560791015625\n",
      "Iteration number 40600 loss: 4.627372741699219\n",
      "Iteration number 40700 loss: 4.189853668212891\n",
      "Iteration number 40800 loss: 4.648991584777832\n",
      "Iteration number 40900 loss: 4.14570426940918\n",
      "Iteration number 41000 loss: 4.1829071044921875\n",
      "Iteration number 41100 loss: 3.7535510063171387\n",
      "Iteration number 41200 loss: 4.345307350158691\n",
      "Iteration number 41300 loss: 4.089685916900635\n",
      "Iteration number 41400 loss: 4.71075439453125\n",
      "Iteration number 41500 loss: 4.616247177124023\n",
      "Iteration number 41600 loss: 4.393780708312988\n",
      "Iteration number 41700 loss: 4.628152847290039\n",
      "Iteration number 41800 loss: 4.4590253829956055\n",
      "Iteration number 41900 loss: 4.3609185218811035\n",
      "Iteration number 42000 loss: 4.2002949714660645\n",
      "Iteration number 42100 loss: 4.707701683044434\n",
      "Iteration number 42200 loss: 4.194321632385254\n",
      "Iteration number 42300 loss: 3.935380220413208\n",
      "Iteration number 42400 loss: 4.529394149780273\n",
      "Iteration number 42500 loss: 4.706535339355469\n",
      "Iteration number 42600 loss: 4.006082057952881\n",
      "Iteration number 42700 loss: 4.486388206481934\n",
      "Iteration number 42800 loss: 4.662896156311035\n",
      "Iteration number 42900 loss: 4.218935489654541\n",
      "Iteration number 43000 loss: 3.597842216491699\n",
      "Iteration number 43100 loss: 4.039825916290283\n",
      "Iteration number 43200 loss: 4.492398262023926\n",
      "Iteration number 43300 loss: 3.9155473709106445\n",
      "Iteration number 43400 loss: 4.354920387268066\n",
      "Iteration number 43500 loss: 4.86528205871582\n",
      "Iteration number 43600 loss: 3.990175247192383\n",
      "Iteration number 43700 loss: 4.015655517578125\n",
      "Iteration number 43800 loss: 4.158910274505615\n",
      "Iteration number 43900 loss: 3.911757469177246\n",
      "Iteration number 44000 loss: 4.467493534088135\n",
      "Iteration number 44100 loss: 4.399284362792969\n",
      "Iteration number 44200 loss: 4.216479301452637\n",
      "Iteration number 44300 loss: 3.9610047340393066\n",
      "Iteration number 44400 loss: 3.836413860321045\n",
      "Iteration number 44500 loss: 4.510705947875977\n",
      "Iteration number 44600 loss: 4.312202453613281\n",
      "Iteration number 44700 loss: 4.271631240844727\n",
      "Iteration number 44800 loss: 4.416855335235596\n",
      "Iteration number 44900 loss: 4.394962310791016\n",
      "Iteration number 45000 loss: 4.648888111114502\n",
      "Iteration number 45100 loss: 3.901092529296875\n",
      "Iteration number 45200 loss: 4.106870174407959\n",
      "Iteration number 45300 loss: 3.805931568145752\n",
      "Iteration number 45400 loss: 3.5602426528930664\n",
      "Iteration number 45500 loss: 3.837766647338867\n",
      "Iteration number 45600 loss: 4.683771133422852\n",
      "Iteration number 45700 loss: 3.746589183807373\n",
      "Iteration number 45800 loss: 4.22520637512207\n",
      "Iteration number 45900 loss: 3.829315185546875\n",
      "Iteration number 46000 loss: 3.9386515617370605\n",
      "Iteration number 46100 loss: 3.737095355987549\n",
      "Iteration number 46200 loss: 4.480216979980469\n",
      "Iteration number 46300 loss: 4.1181230545043945\n",
      "Iteration number 46400 loss: 4.256110191345215\n",
      "Iteration number 46500 loss: 4.200827121734619\n",
      "Iteration number 46600 loss: 4.216004371643066\n",
      "Iteration number 46700 loss: 4.467055320739746\n",
      "Iteration number 46800 loss: 3.992847204208374\n",
      "Iteration number 46900 loss: 4.09358549118042\n",
      "Iteration number 47000 loss: 4.139092922210693\n",
      "Iteration number 47100 loss: 4.03903341293335\n",
      "Iteration number 47200 loss: 4.048825263977051\n",
      "Iteration number 47300 loss: 3.8698112964630127\n",
      "Iteration number 47400 loss: 3.788945198059082\n",
      "Iteration number 47500 loss: 3.875067710876465\n",
      "Iteration number 47600 loss: 3.931466817855835\n",
      "Iteration number 47700 loss: 3.993407964706421\n",
      "Iteration number 47800 loss: 4.11431360244751\n",
      "Iteration number 47900 loss: 4.188131332397461\n",
      "Iteration number 48000 loss: 3.93674898147583\n",
      "Iteration number 48100 loss: 4.162453651428223\n",
      "Iteration number 48200 loss: 4.180112838745117\n",
      "Iteration number 48300 loss: 3.9295358657836914\n",
      "Iteration number 48400 loss: 4.071786880493164\n",
      "Iteration number 48500 loss: 3.894730806350708\n",
      "Iteration number 48600 loss: 3.79129695892334\n",
      "Iteration number 48700 loss: 4.058727264404297\n",
      "Iteration number 48800 loss: 3.7416186332702637\n",
      "Iteration number 48900 loss: 3.764254570007324\n",
      "Iteration number 49000 loss: 3.478017807006836\n",
      "Iteration number 49100 loss: 3.8154149055480957\n",
      "Iteration number 49200 loss: 3.705984354019165\n",
      "Iteration number 49300 loss: 3.7321250438690186\n",
      "Iteration number 49400 loss: 3.295191764831543\n",
      "Iteration number 49500 loss: 3.430546283721924\n",
      "Iteration number 49600 loss: 3.578582286834717\n",
      "Iteration number 49700 loss: 3.932809352874756\n",
      "Iteration number 49800 loss: 3.7681660652160645\n",
      "Iteration number 49900 loss: 2.7396199703216553\n",
      "Iteration number 50000 loss: 4.088393688201904\n",
      "Iteration number 50100 loss: 3.9473135471343994\n",
      "Iteration number 50200 loss: 3.911452054977417\n",
      "Iteration number 50300 loss: 4.036888122558594\n",
      "Iteration number 50400 loss: 3.8663012981414795\n",
      "Iteration number 50500 loss: 3.4785585403442383\n",
      "Iteration number 50600 loss: 3.9511048793792725\n",
      "Iteration number 50700 loss: 4.025639533996582\n",
      "Iteration number 50800 loss: 3.5346531867980957\n",
      "Iteration number 50900 loss: 3.788733959197998\n",
      "Iteration number 51000 loss: 3.9657087326049805\n",
      "Iteration number 51100 loss: 3.7148072719573975\n",
      "Iteration number 51200 loss: 3.4161887168884277\n",
      "Iteration number 51300 loss: 4.110747337341309\n",
      "Iteration number 51400 loss: 4.218266487121582\n",
      "Iteration number 51500 loss: 3.2617664337158203\n",
      "Iteration number 51600 loss: 4.229598045349121\n",
      "Iteration number 51700 loss: 3.72808837890625\n",
      "Iteration number 51800 loss: 3.8400468826293945\n",
      "Iteration number 51900 loss: 3.484307289123535\n",
      "Iteration number 52000 loss: 4.754798412322998\n",
      "Iteration number 52100 loss: 3.1134085655212402\n",
      "Iteration number 52200 loss: 3.811717987060547\n",
      "Iteration number 52300 loss: 3.629718542098999\n",
      "Iteration number 52400 loss: 4.470792293548584\n",
      "Iteration number 52500 loss: 3.7367806434631348\n",
      "Iteration number 52600 loss: 3.664036273956299\n",
      "Iteration number 52700 loss: 3.436256170272827\n",
      "Iteration number 52800 loss: 3.473400115966797\n",
      "Iteration number 52900 loss: 3.5605926513671875\n",
      "Iteration number 53000 loss: 3.6925675868988037\n",
      "Iteration number 53100 loss: 3.7311155796051025\n",
      "Iteration number 53200 loss: 3.611321210861206\n",
      "Iteration number 53300 loss: 3.3577067852020264\n",
      "Iteration number 53400 loss: 3.7582144737243652\n",
      "Iteration number 53500 loss: 3.7088561058044434\n",
      "Iteration number 53600 loss: 3.221559762954712\n",
      "Iteration number 53700 loss: 4.660783767700195\n",
      "Iteration number 53800 loss: 3.6016845703125\n",
      "Iteration number 53900 loss: 4.201549053192139\n",
      "Iteration number 54000 loss: 2.985107898712158\n",
      "Iteration number 54100 loss: 2.811344623565674\n",
      "Iteration number 54200 loss: 3.284540891647339\n",
      "Iteration number 54300 loss: 4.046656131744385\n",
      "Iteration number 54400 loss: 4.420791149139404\n",
      "Iteration number 54500 loss: 4.442413330078125\n",
      "Iteration number 54600 loss: 4.026115417480469\n",
      "Iteration number 54700 loss: 4.001297473907471\n",
      "Iteration number 54800 loss: 3.422168731689453\n",
      "Iteration number 54900 loss: 3.8908536434173584\n",
      "Iteration number 55000 loss: 4.219593048095703\n",
      "Iteration number 55100 loss: 3.386411666870117\n",
      "Iteration number 55200 loss: 3.9739465713500977\n",
      "Iteration number 55300 loss: 3.8390164375305176\n",
      "Iteration number 55400 loss: 3.3104779720306396\n",
      "Iteration number 55500 loss: 4.598829746246338\n",
      "Iteration number 55600 loss: 3.3372840881347656\n",
      "Iteration number 55700 loss: 3.7305595874786377\n",
      "Iteration number 55800 loss: 4.134057998657227\n",
      "Iteration number 55900 loss: 4.380706787109375\n",
      "Iteration number 56000 loss: 2.9212656021118164\n",
      "Iteration number 56100 loss: 3.3831801414489746\n",
      "Iteration number 56200 loss: 3.7519850730895996\n",
      "Iteration number 56300 loss: 4.391864776611328\n",
      "Iteration number 56400 loss: 3.2724924087524414\n",
      "Iteration number 56500 loss: 3.2005486488342285\n",
      "Iteration number 56600 loss: 3.9949052333831787\n",
      "Iteration number 56700 loss: 2.98341703414917\n",
      "Iteration number 56800 loss: 3.5077810287475586\n",
      "Iteration number 56900 loss: 4.288569450378418\n",
      "Iteration number 57000 loss: 2.5506153106689453\n",
      "Iteration number 57100 loss: 4.397554397583008\n",
      "Iteration number 57200 loss: 3.8345327377319336\n",
      "Iteration number 57300 loss: 3.5237045288085938\n",
      "Iteration number 57400 loss: 3.137481212615967\n",
      "Iteration number 57500 loss: 3.9697256088256836\n",
      "Iteration number 57600 loss: 3.5063581466674805\n",
      "Iteration number 57700 loss: 3.40738582611084\n",
      "Iteration number 57800 loss: 3.9044525623321533\n",
      "Iteration number 57900 loss: 3.597784996032715\n",
      "Iteration number 58000 loss: 2.841813325881958\n",
      "Iteration number 58100 loss: 3.709843873977661\n",
      "Iteration number 58200 loss: 3.8186628818511963\n",
      "Iteration number 58300 loss: 4.340855598449707\n",
      "Iteration number 58400 loss: 3.895211696624756\n",
      "Iteration number 58500 loss: 4.126681804656982\n",
      "Iteration number 58600 loss: 3.446826934814453\n",
      "Iteration number 58700 loss: 4.115410804748535\n",
      "Iteration number 58800 loss: 3.52805233001709\n",
      "Iteration number 58900 loss: 3.491453170776367\n",
      "Iteration number 59000 loss: 4.018442630767822\n",
      "Iteration number 59100 loss: 4.062259674072266\n",
      "Iteration number 59200 loss: 3.086958408355713\n",
      "Iteration number 59300 loss: 4.520317077636719\n",
      "Iteration number 59400 loss: 3.9518237113952637\n",
      "Iteration number 59500 loss: 3.9524195194244385\n",
      "Iteration number 59600 loss: 3.9049136638641357\n",
      "Iteration number 59700 loss: 3.889679193496704\n",
      "Iteration number 59800 loss: 3.352496862411499\n",
      "Iteration number 59900 loss: 4.183695316314697\n",
      "Iteration number 60000 loss: 3.9472780227661133\n",
      "Iteration number 60100 loss: 3.7540760040283203\n",
      "Iteration number 60200 loss: 3.643646717071533\n",
      "Iteration number 60300 loss: 3.5529189109802246\n",
      "Iteration number 60400 loss: 4.11247444152832\n",
      "Iteration number 60500 loss: 3.9796972274780273\n",
      "Iteration number 60600 loss: 3.6936588287353516\n",
      "Iteration number 60700 loss: 4.258993148803711\n",
      "Iteration number 60800 loss: 4.072204113006592\n",
      "Iteration number 60900 loss: 4.180511951446533\n",
      "Iteration number 61000 loss: 3.893578290939331\n",
      "Iteration number 61100 loss: 3.5753965377807617\n",
      "Iteration number 61200 loss: 3.5601985454559326\n",
      "Iteration number 61300 loss: 3.0305752754211426\n",
      "Iteration number 61400 loss: 4.185639381408691\n",
      "Iteration number 61500 loss: 4.1096696853637695\n",
      "Iteration number 61600 loss: 3.8222079277038574\n",
      "Iteration number 61700 loss: 3.0329055786132812\n",
      "Iteration number 61800 loss: 3.1844334602355957\n",
      "Iteration number 61900 loss: 3.9879209995269775\n",
      "Iteration number 62000 loss: 3.4322824478149414\n",
      "Iteration number 62100 loss: 4.237694263458252\n",
      "Iteration number 62200 loss: 4.606220245361328\n",
      "Iteration number 62300 loss: 3.820730686187744\n",
      "Iteration number 62400 loss: 4.20047664642334\n",
      "Iteration number 62500 loss: 3.599346876144409\n",
      "Iteration number 62600 loss: 3.820725917816162\n",
      "Iteration number 62700 loss: 3.6632606983184814\n",
      "Iteration number 62800 loss: 3.7370402812957764\n",
      "Iteration number 62900 loss: 3.083735942840576\n",
      "Iteration number 63000 loss: 2.818455219268799\n",
      "Iteration number 63100 loss: 3.865324020385742\n",
      "Iteration number 63200 loss: 3.7096099853515625\n",
      "Iteration number 63300 loss: 4.089456081390381\n",
      "Iteration number 63400 loss: 2.6700191497802734\n",
      "Iteration number 63500 loss: 3.43038010597229\n",
      "Iteration number 63600 loss: 4.103132724761963\n",
      "Iteration number 63700 loss: 4.539761543273926\n",
      "Iteration number 63800 loss: 2.538550853729248\n",
      "Iteration number 63900 loss: 3.457792043685913\n",
      "Iteration number 64000 loss: 3.3152830600738525\n",
      "Iteration number 64100 loss: 3.3958468437194824\n",
      "Iteration number 64200 loss: 3.838477611541748\n",
      "Iteration number 64300 loss: 3.2166762351989746\n",
      "Iteration number 64400 loss: 4.305639743804932\n",
      "Iteration number 64500 loss: 3.0265469551086426\n",
      "Iteration number 64600 loss: 3.7828056812286377\n",
      "Iteration number 64700 loss: 3.284266710281372\n",
      "Iteration number 64800 loss: 3.319565773010254\n",
      "Iteration number 64900 loss: 2.8058700561523438\n",
      "Iteration number 65000 loss: 3.617701768875122\n",
      "Iteration number 65100 loss: 3.9605941772460938\n",
      "Iteration number 65200 loss: 2.12174129486084\n",
      "Iteration number 65300 loss: 3.3237829208374023\n",
      "Iteration number 65400 loss: 3.767906665802002\n",
      "Iteration number 65500 loss: 3.188209056854248\n",
      "Iteration number 65600 loss: 2.986104965209961\n",
      "Iteration number 65700 loss: 2.8436074256896973\n",
      "Iteration number 65800 loss: 2.521580696105957\n",
      "Iteration number 65900 loss: 3.3001508712768555\n",
      "Iteration number 66000 loss: 3.0976500511169434\n",
      "Iteration number 66100 loss: 3.0934364795684814\n",
      "Iteration number 66200 loss: 3.351076602935791\n",
      "Iteration number 66300 loss: 3.7925405502319336\n",
      "Iteration number 66400 loss: 2.8503165245056152\n",
      "Iteration number 66500 loss: 3.2742161750793457\n",
      "Iteration number 66600 loss: 3.6350417137145996\n",
      "Iteration number 66700 loss: 3.37568998336792\n",
      "Iteration number 66800 loss: 3.095963478088379\n",
      "Iteration number 66900 loss: 2.7276506423950195\n",
      "Iteration number 67000 loss: 4.167224407196045\n",
      "Iteration number 67100 loss: 3.521038770675659\n",
      "Iteration number 67200 loss: 3.6683177947998047\n",
      "Iteration number 67300 loss: 3.429427146911621\n",
      "Iteration number 67400 loss: 3.035357713699341\n",
      "Iteration number 67500 loss: 2.7470340728759766\n",
      "Iteration number 67600 loss: 3.973706007003784\n",
      "Iteration number 67700 loss: 3.9076437950134277\n",
      "Iteration number 67800 loss: 3.2424325942993164\n",
      "Iteration number 67900 loss: 2.677432060241699\n",
      "Iteration number 68000 loss: 3.3656187057495117\n",
      "Iteration number 68100 loss: 3.4336142539978027\n",
      "Iteration number 68200 loss: 2.383697032928467\n",
      "Iteration number 68300 loss: 3.51706600189209\n",
      "Iteration number 68400 loss: 3.5281105041503906\n",
      "Iteration number 68500 loss: 3.064952850341797\n",
      "Iteration number 68600 loss: 2.7873427867889404\n",
      "Iteration number 68700 loss: 3.304474353790283\n",
      "Iteration number 68800 loss: 3.1199560165405273\n",
      "Iteration number 68900 loss: 3.8674778938293457\n",
      "Iteration number 69000 loss: 2.7914271354675293\n",
      "Iteration number 69100 loss: 3.3659706115722656\n",
      "Iteration number 69200 loss: 2.7982568740844727\n",
      "Iteration number 69300 loss: 4.367489814758301\n",
      "Iteration number 69400 loss: 2.8164830207824707\n",
      "Iteration number 69500 loss: 2.448113441467285\n",
      "Iteration number 69600 loss: 3.2287819385528564\n",
      "Iteration number 69700 loss: 3.8631088733673096\n",
      "Iteration number 69800 loss: 1.7155346870422363\n",
      "Iteration number 69900 loss: 1.4951772689819336\n",
      "Iteration number 70000 loss: 3.9860639572143555\n",
      "Iteration number 70100 loss: 3.1874704360961914\n",
      "Iteration number 70200 loss: 3.0424280166625977\n",
      "Iteration number 70300 loss: 3.408522129058838\n",
      "Iteration number 70400 loss: 3.1655893325805664\n",
      "Iteration number 70500 loss: 3.8205313682556152\n",
      "Iteration number 70600 loss: 3.806887149810791\n",
      "Iteration number 70700 loss: 1.3081953525543213\n",
      "Iteration number 70800 loss: 4.178028106689453\n",
      "Iteration number 70900 loss: 3.2232718467712402\n",
      "Iteration number 71000 loss: 3.8011972904205322\n",
      "Iteration number 71100 loss: 1.9906153678894043\n",
      "Iteration number 71200 loss: 3.8665082454681396\n",
      "Iteration number 71300 loss: 4.460646152496338\n",
      "Iteration number 71400 loss: 2.175441265106201\n",
      "Iteration number 71500 loss: 3.1956992149353027\n",
      "Iteration number 71600 loss: 1.4058772325515747\n",
      "Iteration number 71700 loss: 3.403944969177246\n",
      "Iteration number 71800 loss: 2.6238367557525635\n",
      "Iteration number 71900 loss: 3.969998836517334\n",
      "Iteration number 72000 loss: 2.2575843334198\n",
      "Iteration number 72100 loss: 2.7436749935150146\n",
      "Iteration number 72200 loss: 2.2508833408355713\n",
      "Iteration number 72300 loss: 2.5318782329559326\n",
      "Iteration number 72400 loss: 2.730670690536499\n",
      "Iteration number 72500 loss: 3.2849416732788086\n",
      "Iteration number 72600 loss: 3.3508687019348145\n",
      "Iteration number 72700 loss: 2.5123937129974365\n",
      "Iteration number 72800 loss: 3.3780112266540527\n",
      "Iteration number 72900 loss: 3.788939952850342\n",
      "Iteration number 73000 loss: 3.5518064498901367\n",
      "Iteration number 73100 loss: 2.901881456375122\n",
      "Iteration number 73200 loss: 3.0924222469329834\n",
      "Iteration number 73300 loss: 1.9179496765136719\n",
      "Iteration number 73400 loss: 4.040948867797852\n",
      "Iteration number 73500 loss: 2.4699158668518066\n",
      "Iteration number 73600 loss: 2.3475723266601562\n",
      "Iteration number 73700 loss: 3.116752862930298\n",
      "Iteration number 73800 loss: 3.046865701675415\n",
      "Iteration number 73900 loss: 2.5265650749206543\n",
      "Iteration number 74000 loss: 5.860014915466309\n",
      "Iteration number 74100 loss: 1.4510443210601807\n",
      "Iteration number 74200 loss: 2.956955909729004\n",
      "Iteration number 74300 loss: 3.249174118041992\n",
      "Iteration number 74400 loss: 2.0330731868743896\n",
      "Iteration number 74500 loss: 1.823734998703003\n",
      "Iteration number 74600 loss: 2.303943157196045\n",
      "Iteration number 74700 loss: 4.7610883712768555\n",
      "Iteration number 74800 loss: 1.3076510429382324\n",
      "Iteration number 74900 loss: 2.1456265449523926\n",
      "Iteration number 75000 loss: 3.9180946350097656\n",
      "Iteration number 75100 loss: 3.8849661350250244\n",
      "Iteration number 75200 loss: 3.4417307376861572\n",
      "Iteration number 75300 loss: 2.646606922149658\n",
      "Iteration number 75400 loss: 3.4791717529296875\n",
      "Iteration number 75500 loss: 2.0421125888824463\n",
      "Iteration number 75600 loss: 3.7008886337280273\n",
      "Iteration number 75700 loss: 4.9479522705078125\n",
      "Iteration number 75800 loss: 3.5519442558288574\n",
      "Iteration number 75900 loss: 2.3584909439086914\n",
      "Iteration number 76000 loss: 3.25874662399292\n",
      "Iteration number 76100 loss: 3.3985068798065186\n",
      "Iteration number 76200 loss: 4.082851409912109\n",
      "Iteration number 76300 loss: 3.153998613357544\n",
      "Iteration number 76400 loss: 2.614246129989624\n",
      "Iteration number 76500 loss: 4.21903657913208\n",
      "Iteration number 76600 loss: 3.745164394378662\n",
      "Iteration number 76700 loss: 2.5774195194244385\n",
      "Iteration number 76800 loss: 1.8288674354553223\n",
      "Iteration number 76900 loss: 3.195791721343994\n",
      "Iteration number 77000 loss: 2.3553194999694824\n",
      "Iteration number 77100 loss: 3.0033016204833984\n",
      "Iteration number 77200 loss: 2.249851703643799\n",
      "Iteration number 77300 loss: 2.3963119983673096\n",
      "Iteration number 77400 loss: 2.9500880241394043\n",
      "Iteration number 77500 loss: 2.939326763153076\n",
      "Iteration number 77600 loss: 3.5383100509643555\n",
      "Iteration number 77700 loss: 3.4692020416259766\n",
      "Iteration number 77800 loss: 2.686722755432129\n",
      "Iteration number 77900 loss: 3.435173988342285\n",
      "Iteration number 78000 loss: 2.732412576675415\n",
      "Iteration number 78100 loss: 2.683178424835205\n",
      "Iteration number 78200 loss: 3.0053420066833496\n",
      "Iteration number 78300 loss: 2.6486923694610596\n",
      "Iteration number 78400 loss: 2.9523589611053467\n",
      "Iteration number 78500 loss: 2.541865587234497\n",
      "Iteration number 78600 loss: 2.6152000427246094\n",
      "Iteration number 78700 loss: 2.9494404792785645\n",
      "Iteration number 78800 loss: 3.885190010070801\n",
      "Iteration number 78900 loss: 3.673322916030884\n",
      "Iteration number 79000 loss: 3.7357640266418457\n",
      "Iteration number 79100 loss: 3.6027755737304688\n",
      "Iteration number 79200 loss: 3.6539900302886963\n",
      "Iteration number 79300 loss: 3.447841167449951\n",
      "Iteration number 79400 loss: 3.016352891921997\n",
      "Iteration number 79500 loss: 3.499607563018799\n",
      "Iteration number 79600 loss: 3.226879119873047\n",
      "Iteration number 79700 loss: 3.243499517440796\n",
      "Iteration number 79800 loss: 3.6582298278808594\n",
      "Iteration number 79900 loss: 3.3358378410339355\n",
      "Iteration number 80000 loss: 3.113441228866577\n",
      "Iteration number 80100 loss: 3.521184206008911\n",
      "Iteration number 80200 loss: 3.4627034664154053\n",
      "Iteration number 80300 loss: 3.213524580001831\n",
      "Iteration number 80400 loss: 3.0644171237945557\n",
      "Iteration number 80500 loss: 3.1194915771484375\n",
      "Iteration number 80600 loss: 3.4897818565368652\n",
      "Iteration number 80700 loss: 3.725654125213623\n",
      "Iteration number 80800 loss: 3.861910581588745\n",
      "Iteration number 80900 loss: 3.65579891204834\n",
      "Iteration number 81000 loss: 3.3334403038024902\n",
      "Iteration number 81100 loss: 3.189822196960449\n",
      "Iteration number 81200 loss: 3.762277126312256\n",
      "Iteration number 81300 loss: 3.630831241607666\n",
      "Iteration number 81400 loss: 4.302196979522705\n",
      "Iteration number 81500 loss: 3.889988422393799\n",
      "Iteration number 81600 loss: 3.38482666015625\n",
      "Iteration number 81700 loss: 3.4162073135375977\n",
      "Iteration number 81800 loss: 3.9294393062591553\n",
      "Iteration number 81900 loss: 2.8355143070220947\n",
      "Iteration number 82000 loss: 2.999702215194702\n",
      "Iteration number 82100 loss: 3.646493911743164\n",
      "Iteration number 82200 loss: 2.881143093109131\n",
      "Iteration number 82300 loss: 3.3014793395996094\n",
      "Iteration number 82400 loss: 3.363701820373535\n",
      "Iteration number 82500 loss: 3.7328362464904785\n",
      "Iteration number 82600 loss: 2.756103038787842\n",
      "Iteration number 82700 loss: 2.8993685245513916\n",
      "Iteration number 82800 loss: 3.0416407585144043\n",
      "Iteration number 82900 loss: 3.46171236038208\n",
      "Iteration number 83000 loss: 3.099846601486206\n",
      "Iteration number 83100 loss: 3.4903175830841064\n",
      "Iteration number 83200 loss: 3.2390120029449463\n",
      "Iteration number 83300 loss: 2.93036150932312\n",
      "Iteration number 83400 loss: 2.398329973220825\n",
      "Iteration number 83500 loss: 3.0078723430633545\n",
      "Iteration number 83600 loss: 2.889495611190796\n",
      "Iteration number 83700 loss: 3.481898307800293\n",
      "Iteration number 83800 loss: 3.438551187515259\n",
      "Iteration number 83900 loss: 3.3452582359313965\n",
      "Iteration number 84000 loss: 2.880311965942383\n",
      "Iteration number 84100 loss: 3.376962661743164\n",
      "Iteration number 84200 loss: 3.683368682861328\n",
      "Iteration number 84300 loss: 2.959164619445801\n",
      "Iteration number 84400 loss: 3.0313124656677246\n",
      "Iteration number 84500 loss: 3.4234116077423096\n",
      "Iteration number 84600 loss: 2.33107852935791\n",
      "Iteration number 84700 loss: 2.713589668273926\n",
      "Iteration number 84800 loss: 2.3115041255950928\n",
      "Iteration number 84900 loss: 3.098022937774658\n",
      "Iteration number 85000 loss: 3.3325138092041016\n",
      "Iteration number 85100 loss: 3.9373021125793457\n",
      "Iteration number 85200 loss: 2.7061948776245117\n",
      "Iteration number 85300 loss: 2.2905614376068115\n",
      "Iteration number 85400 loss: 2.731436014175415\n",
      "Iteration number 85500 loss: 3.287771701812744\n",
      "Iteration number 85600 loss: 3.4814870357513428\n",
      "Iteration number 85700 loss: 3.1375837326049805\n",
      "Iteration number 85800 loss: 4.119226455688477\n",
      "Iteration number 85900 loss: 3.163647174835205\n",
      "Iteration number 86000 loss: 2.8557324409484863\n",
      "Iteration number 86100 loss: 3.765117883682251\n",
      "Iteration number 86200 loss: 3.3197901248931885\n",
      "Iteration number 86300 loss: 2.7828705310821533\n",
      "Iteration number 86400 loss: 2.9738659858703613\n",
      "Iteration number 86500 loss: 3.3331284523010254\n",
      "Iteration number 86600 loss: 3.0064079761505127\n",
      "Iteration number 86700 loss: 2.760047435760498\n",
      "Iteration number 86800 loss: 2.9656004905700684\n",
      "Iteration number 86900 loss: 3.0212016105651855\n",
      "Iteration number 87000 loss: 3.3443565368652344\n",
      "Iteration number 87100 loss: 2.5716023445129395\n",
      "Iteration number 87200 loss: 3.1158337593078613\n",
      "Iteration number 87300 loss: 3.1863040924072266\n",
      "Iteration number 87400 loss: 2.978912115097046\n",
      "Iteration number 87500 loss: 2.879653215408325\n",
      "Iteration number 87600 loss: 3.1184725761413574\n",
      "Iteration number 87700 loss: 2.952066421508789\n",
      "Iteration number 87800 loss: 3.1665234565734863\n",
      "Iteration number 87900 loss: 3.0953712463378906\n",
      "Iteration number 88000 loss: 3.1067957878112793\n",
      "Iteration number 88100 loss: 2.9526491165161133\n",
      "Iteration number 88200 loss: 3.113452911376953\n",
      "Iteration number 88300 loss: 2.6805977821350098\n",
      "Iteration number 88400 loss: 2.64288330078125\n",
      "Iteration number 88500 loss: 2.9602043628692627\n",
      "Iteration number 88600 loss: 3.2306480407714844\n",
      "Iteration number 88700 loss: 2.8877792358398438\n",
      "Iteration number 88800 loss: 2.8910460472106934\n",
      "Iteration number 88900 loss: 2.7959022521972656\n",
      "Iteration number 89000 loss: 3.219841718673706\n",
      "Iteration number 89100 loss: 2.6809585094451904\n",
      "Iteration number 89200 loss: 2.640521764755249\n",
      "Iteration number 89300 loss: 2.9844412803649902\n",
      "Iteration number 89400 loss: 2.871608257293701\n",
      "Iteration number 89500 loss: 2.6149678230285645\n",
      "Iteration number 89600 loss: 2.9466052055358887\n",
      "Iteration number 89700 loss: 2.795290470123291\n",
      "Iteration number 89800 loss: 2.6774849891662598\n",
      "Iteration number 89900 loss: 2.8076162338256836\n",
      "Iteration number 90000 loss: 2.775515556335449\n",
      "Iteration number 90100 loss: 3.0974767208099365\n",
      "Iteration number 90200 loss: 2.674964427947998\n",
      "Iteration number 90300 loss: 2.956355571746826\n",
      "Iteration number 90400 loss: 2.578559398651123\n",
      "Iteration number 90500 loss: 2.7253026962280273\n",
      "Iteration number 90600 loss: 2.781493902206421\n",
      "Iteration number 90700 loss: 2.50639009475708\n",
      "Iteration number 90800 loss: 2.3015735149383545\n",
      "Iteration number 90900 loss: 2.876030445098877\n",
      "Iteration number 91000 loss: 3.051528215408325\n",
      "Iteration number 91100 loss: 2.7621045112609863\n",
      "Iteration number 91200 loss: 2.7063138484954834\n",
      "Iteration number 91300 loss: 2.9427478313446045\n",
      "Iteration number 91400 loss: 3.102433919906616\n",
      "Iteration number 91500 loss: 2.438091278076172\n",
      "Iteration number 91600 loss: 2.454564094543457\n",
      "Iteration number 91700 loss: 2.6890671253204346\n",
      "Iteration number 91800 loss: 2.78355073928833\n",
      "Iteration number 91900 loss: 2.4587769508361816\n",
      "Iteration number 92000 loss: 2.6205763816833496\n",
      "Iteration number 92100 loss: 3.208826780319214\n",
      "Iteration number 92200 loss: 2.507756233215332\n",
      "Iteration number 92300 loss: 3.240044116973877\n",
      "Iteration number 92400 loss: 2.8200604915618896\n",
      "Iteration number 92500 loss: 3.0834951400756836\n",
      "Iteration number 92600 loss: 2.831425666809082\n",
      "Iteration number 92700 loss: 2.8568897247314453\n",
      "Iteration number 92800 loss: 3.894350528717041\n",
      "Iteration number 92900 loss: 2.6431498527526855\n",
      "Iteration number 93000 loss: 2.91259765625\n",
      "Iteration number 93100 loss: 2.968578815460205\n",
      "Iteration number 93200 loss: 3.128978729248047\n",
      "Iteration number 93300 loss: 3.646885871887207\n",
      "Iteration number 93400 loss: 3.124221086502075\n",
      "Iteration number 93500 loss: 2.9280121326446533\n",
      "Iteration number 93600 loss: 2.9840199947357178\n",
      "Iteration number 93700 loss: 3.1881165504455566\n",
      "Iteration number 93800 loss: 3.105358600616455\n",
      "Iteration number 93900 loss: 3.1886563301086426\n",
      "Iteration number 94000 loss: 3.381498336791992\n",
      "Iteration number 94100 loss: 3.917970895767212\n",
      "Iteration number 94200 loss: 4.428544998168945\n",
      "Iteration number 94300 loss: 2.6154534816741943\n",
      "Iteration number 94400 loss: 3.5148987770080566\n",
      "Iteration number 94500 loss: 3.074309825897217\n",
      "Iteration number 94600 loss: 3.4977245330810547\n",
      "Iteration number 94700 loss: 2.7867374420166016\n",
      "Iteration number 94800 loss: 3.114553928375244\n",
      "Iteration number 94900 loss: 2.9393391609191895\n",
      "Iteration number 95000 loss: 2.78877329826355\n",
      "Iteration number 95100 loss: 2.0492141246795654\n",
      "Iteration number 95200 loss: 2.3296127319335938\n",
      "Iteration number 95300 loss: 2.6207683086395264\n",
      "Iteration number 95400 loss: 2.297943592071533\n",
      "Iteration number 95500 loss: 2.1220757961273193\n",
      "Iteration number 95600 loss: 2.1394848823547363\n",
      "Iteration number 95700 loss: 2.6248676776885986\n",
      "Iteration number 95800 loss: 2.560194969177246\n",
      "Iteration number 95900 loss: 2.8439226150512695\n",
      "Iteration number 96000 loss: 2.893357276916504\n",
      "Iteration number 96100 loss: 2.625781297683716\n",
      "Iteration number 96200 loss: 3.0035901069641113\n",
      "Iteration number 96300 loss: 2.7187275886535645\n",
      "Iteration number 96400 loss: 2.8285369873046875\n",
      "Iteration number 96500 loss: 2.9172868728637695\n",
      "Iteration number 96600 loss: 2.82443904876709\n",
      "Iteration number 96700 loss: 3.0212955474853516\n",
      "Iteration number 96800 loss: 2.7984509468078613\n",
      "Iteration number 96900 loss: 2.849841833114624\n",
      "Iteration number 97000 loss: 3.383359909057617\n",
      "Iteration number 97100 loss: 2.8649697303771973\n",
      "Iteration number 97200 loss: 2.7056403160095215\n",
      "Iteration number 97300 loss: 3.2181878089904785\n",
      "Iteration number 97400 loss: 3.3111166954040527\n",
      "Iteration number 97500 loss: 3.166783571243286\n",
      "Iteration number 97600 loss: 3.124605655670166\n",
      "Iteration number 97700 loss: 3.088212490081787\n",
      "Iteration number 97800 loss: 3.0401549339294434\n",
      "Iteration number 97900 loss: 2.7463741302490234\n",
      "Iteration number 98000 loss: 2.731442451477051\n",
      "Iteration number 98100 loss: 2.373919725418091\n",
      "Iteration number 98200 loss: 3.2847671508789062\n",
      "Iteration number 98300 loss: 2.6037893295288086\n",
      "Iteration number 98400 loss: 3.1412808895111084\n",
      "Iteration number 98500 loss: 3.6990609169006348\n",
      "Iteration number 98600 loss: 3.3706107139587402\n",
      "Iteration number 98700 loss: 4.039784908294678\n",
      "Iteration number 98800 loss: 4.370746612548828\n",
      "Iteration number 98900 loss: 3.113844156265259\n",
      "Iteration number 99000 loss: 3.7055845260620117\n",
      "Iteration number 99100 loss: 2.928603172302246\n",
      "Iteration number 99200 loss: 3.371224880218506\n",
      "Iteration number 99300 loss: 3.682036876678467\n",
      "Iteration number 99400 loss: 3.2517168521881104\n",
      "Iteration number 99500 loss: 3.045807361602783\n",
      "Iteration number 99600 loss: 3.907780170440674\n",
      "Iteration number 99700 loss: 2.0274486541748047\n",
      "Iteration number 99800 loss: 2.287929058074951\n",
      "Iteration number 99900 loss: 2.4729723930358887\n",
      "Iteration number 100000 loss: 4.244590759277344\n",
      "Iteration number 100100 loss: 2.4410829544067383\n",
      "Iteration number 100200 loss: 3.4052886962890625\n",
      "Iteration number 100300 loss: 3.3370361328125\n",
      "Iteration number 100400 loss: 3.554173469543457\n",
      "Iteration number 100500 loss: 3.2899296283721924\n",
      "Iteration number 100600 loss: 2.64284086227417\n",
      "Iteration number 100700 loss: 3.88584566116333\n",
      "Iteration number 100800 loss: 2.750302314758301\n",
      "Iteration number 100900 loss: 3.679720878601074\n",
      "Iteration number 101000 loss: 4.20464563369751\n",
      "Iteration number 101100 loss: 3.43278169631958\n",
      "Iteration number 101200 loss: 2.7003097534179688\n",
      "Iteration number 101300 loss: 3.0293760299682617\n",
      "Iteration number 101400 loss: 3.9092488288879395\n",
      "Iteration number 101500 loss: 3.4321465492248535\n",
      "Iteration number 101600 loss: 3.7502670288085938\n",
      "Iteration number 101700 loss: 4.083871364593506\n",
      "Iteration number 101800 loss: 2.8918545246124268\n",
      "Iteration number 101900 loss: 3.675631523132324\n",
      "Iteration number 102000 loss: 4.117816925048828\n",
      "Iteration number 102100 loss: 2.816537380218506\n",
      "Iteration number 102200 loss: 4.266048431396484\n",
      "Iteration number 102300 loss: 3.245824098587036\n",
      "Iteration number 102400 loss: 3.383765697479248\n",
      "Iteration number 102500 loss: 3.6161420345306396\n",
      "Iteration number 102600 loss: 3.0587501525878906\n",
      "Iteration number 102700 loss: 3.2656421661376953\n",
      "Iteration number 102800 loss: 3.294922351837158\n",
      "Iteration number 102900 loss: 3.768127202987671\n",
      "Iteration number 103000 loss: 2.8057706356048584\n",
      "Iteration number 103100 loss: 2.9386000633239746\n",
      "Iteration number 103200 loss: 3.1466941833496094\n",
      "Iteration number 103300 loss: 2.837902307510376\n",
      "Iteration number 103400 loss: 3.163710355758667\n",
      "Iteration number 103500 loss: 2.995166301727295\n",
      "Iteration number 103600 loss: 2.7622413635253906\n",
      "Iteration number 103700 loss: 2.9850058555603027\n",
      "Iteration number 103800 loss: 2.716275453567505\n",
      "Iteration number 103900 loss: 3.5040810108184814\n",
      "Iteration number 104000 loss: 3.859327793121338\n",
      "Iteration number 104100 loss: 3.2185583114624023\n",
      "Iteration number 104200 loss: 3.0100278854370117\n",
      "Iteration number 104300 loss: 3.0671136379241943\n",
      "Iteration number 104400 loss: 2.643266439437866\n",
      "Iteration number 104500 loss: 3.4477481842041016\n",
      "Iteration number 104600 loss: 3.2937159538269043\n",
      "Iteration number 104700 loss: 2.942361354827881\n",
      "Iteration number 104800 loss: 3.0845680236816406\n",
      "Iteration number 104900 loss: 3.0187273025512695\n",
      "Iteration number 105000 loss: 2.8698670864105225\n",
      "Iteration number 105100 loss: 3.145822048187256\n",
      "Iteration number 105200 loss: 2.871032476425171\n",
      "Iteration number 105300 loss: 3.045414447784424\n",
      "Iteration number 105400 loss: 3.1934614181518555\n",
      "Iteration number 105500 loss: 3.3350908756256104\n",
      "Iteration number 105600 loss: 2.7700252532958984\n",
      "Iteration number 105700 loss: 2.298776149749756\n",
      "Iteration number 105800 loss: 2.5242087841033936\n",
      "Iteration number 105900 loss: 2.683581829071045\n",
      "Iteration number 106000 loss: 2.825218439102173\n",
      "Iteration number 106100 loss: 2.8291172981262207\n",
      "Iteration number 106200 loss: 3.045020580291748\n",
      "Iteration number 106300 loss: 2.660576820373535\n",
      "Iteration number 106400 loss: 2.4142303466796875\n",
      "Iteration number 106500 loss: 2.7435343265533447\n",
      "Iteration number 106600 loss: 3.041930675506592\n",
      "Iteration number 106700 loss: 3.0028622150421143\n",
      "Episode Number: 2\n",
      "Iteration number 0 loss: 2.86181902885437\n",
      "Iteration number 100 loss: 1.2981141805648804\n",
      "Iteration number 200 loss: 2.6049599647521973\n",
      "Iteration number 300 loss: 3.130746364593506\n",
      "Iteration number 400 loss: 3.241250991821289\n",
      "Iteration number 500 loss: 2.6247119903564453\n",
      "Iteration number 600 loss: 3.3216023445129395\n",
      "Iteration number 700 loss: 2.571140766143799\n",
      "Iteration number 800 loss: 2.486098289489746\n",
      "Iteration number 900 loss: 3.4182748794555664\n",
      "Iteration number 1000 loss: 2.4520604610443115\n",
      "Iteration number 1100 loss: 3.2878847122192383\n",
      "Iteration number 1200 loss: 2.838043212890625\n",
      "Iteration number 1300 loss: 3.6668701171875\n",
      "Iteration number 1400 loss: 2.973686695098877\n",
      "Iteration number 1500 loss: 3.3710618019104004\n",
      "Iteration number 1600 loss: 2.7341952323913574\n",
      "Iteration number 1700 loss: 2.7780275344848633\n",
      "Iteration number 1800 loss: 1.9758856296539307\n",
      "Iteration number 1900 loss: 2.836000680923462\n",
      "Iteration number 2000 loss: 3.336838722229004\n",
      "Iteration number 2100 loss: 3.22623348236084\n",
      "Iteration number 2200 loss: 1.777397632598877\n",
      "Iteration number 2300 loss: 3.5396246910095215\n",
      "Iteration number 2400 loss: 3.2397284507751465\n",
      "Iteration number 2500 loss: 2.486825466156006\n",
      "Iteration number 2600 loss: 2.900393486022949\n",
      "Iteration number 2700 loss: 2.7689671516418457\n",
      "Iteration number 2800 loss: 2.7155137062072754\n",
      "Iteration number 2900 loss: 2.688706874847412\n",
      "Iteration number 3000 loss: 2.930050849914551\n",
      "Iteration number 3100 loss: 3.300736427307129\n",
      "Iteration number 3200 loss: 3.6532797813415527\n",
      "Iteration number 3300 loss: 2.5148367881774902\n",
      "Iteration number 3400 loss: 2.804168224334717\n",
      "Iteration number 3500 loss: 3.27901029586792\n",
      "Iteration number 3600 loss: 3.0853381156921387\n",
      "Iteration number 3700 loss: 3.1867032051086426\n",
      "Iteration number 3800 loss: 3.47891902923584\n",
      "Iteration number 3900 loss: 3.800426959991455\n",
      "Iteration number 4000 loss: 3.3559513092041016\n",
      "Iteration number 4100 loss: 3.1583709716796875\n",
      "Iteration number 4200 loss: 4.137241840362549\n",
      "Iteration number 4300 loss: 2.918407440185547\n",
      "Iteration number 4400 loss: 2.9000182151794434\n",
      "Iteration number 4500 loss: 3.2761635780334473\n",
      "Iteration number 4600 loss: 3.44220232963562\n",
      "Iteration number 4700 loss: 2.949479103088379\n",
      "Iteration number 4800 loss: 3.225059986114502\n",
      "Iteration number 4900 loss: 3.2418580055236816\n",
      "Iteration number 5000 loss: 3.0272722244262695\n",
      "Iteration number 5100 loss: 2.9193315505981445\n",
      "Iteration number 5200 loss: 2.585616111755371\n",
      "Iteration number 5300 loss: 3.2082107067108154\n",
      "Iteration number 5400 loss: 3.228876829147339\n",
      "Iteration number 5500 loss: 3.3421473503112793\n",
      "Iteration number 5600 loss: 3.362313747406006\n",
      "Iteration number 5700 loss: 2.799001693725586\n",
      "Iteration number 5800 loss: 3.1518261432647705\n",
      "Iteration number 5900 loss: 2.597540855407715\n",
      "Iteration number 6000 loss: 3.0168399810791016\n",
      "Iteration number 6100 loss: 3.2168500423431396\n",
      "Iteration number 6200 loss: 2.7790303230285645\n",
      "Iteration number 6300 loss: 2.405501365661621\n",
      "Iteration number 6400 loss: 3.3441967964172363\n",
      "Iteration number 6500 loss: 2.7800698280334473\n",
      "Iteration number 6600 loss: 2.4407548904418945\n",
      "Iteration number 6700 loss: 2.850175619125366\n",
      "Iteration number 6800 loss: 2.608501434326172\n",
      "Iteration number 6900 loss: 2.7449707984924316\n",
      "Iteration number 7000 loss: 2.872971773147583\n",
      "Iteration number 7100 loss: 2.6585898399353027\n",
      "Iteration number 7200 loss: 2.9638512134552\n",
      "Iteration number 7300 loss: 3.1558492183685303\n",
      "Iteration number 7400 loss: 3.3747916221618652\n",
      "Iteration number 7500 loss: 2.9451675415039062\n",
      "Iteration number 7600 loss: 2.695549488067627\n",
      "Iteration number 7700 loss: 2.9035706520080566\n",
      "Iteration number 7800 loss: 3.5387330055236816\n",
      "Iteration number 7900 loss: 2.538506031036377\n",
      "Iteration number 8000 loss: 2.869138240814209\n",
      "Iteration number 8100 loss: 2.211491346359253\n",
      "Iteration number 8200 loss: 2.048220157623291\n",
      "Iteration number 8300 loss: 2.5275933742523193\n",
      "Iteration number 8400 loss: 2.642388105392456\n",
      "Iteration number 8500 loss: 2.680546760559082\n",
      "Iteration number 8600 loss: 3.1562061309814453\n",
      "Iteration number 8700 loss: 2.446411609649658\n",
      "Iteration number 8800 loss: 2.430678129196167\n",
      "Iteration number 8900 loss: 3.2215254306793213\n",
      "Iteration number 9000 loss: 2.998206377029419\n",
      "Iteration number 9100 loss: 2.8024744987487793\n",
      "Iteration number 9200 loss: 3.4578728675842285\n",
      "Iteration number 9300 loss: 3.146000862121582\n",
      "Iteration number 9400 loss: 2.932276964187622\n",
      "Iteration number 9500 loss: 3.3529281616210938\n",
      "Iteration number 9600 loss: 3.187410354614258\n",
      "Iteration number 9700 loss: 3.519498825073242\n",
      "Iteration number 9800 loss: 3.302142858505249\n",
      "Iteration number 9900 loss: 3.3243942260742188\n",
      "Iteration number 10000 loss: 3.5413033962249756\n",
      "Iteration number 10100 loss: 3.3716135025024414\n",
      "Iteration number 10200 loss: 3.5791704654693604\n",
      "Iteration number 10300 loss: 3.4753365516662598\n",
      "Iteration number 10400 loss: 3.7445340156555176\n",
      "Iteration number 10500 loss: 3.578768491744995\n",
      "Iteration number 10600 loss: 3.5173535346984863\n",
      "Iteration number 10700 loss: 3.3171539306640625\n",
      "Iteration number 10800 loss: 3.246342182159424\n",
      "Iteration number 10900 loss: 3.406644344329834\n",
      "Iteration number 11000 loss: 3.421933174133301\n",
      "Iteration number 11100 loss: 3.574932098388672\n",
      "Iteration number 11200 loss: 3.719646692276001\n",
      "Iteration number 11300 loss: 3.689659357070923\n",
      "Iteration number 11400 loss: 3.666670322418213\n",
      "Iteration number 11500 loss: 3.4422223567962646\n",
      "Iteration number 11600 loss: 3.443876266479492\n",
      "Iteration number 11700 loss: 3.507190465927124\n",
      "Iteration number 11800 loss: 3.3153727054595947\n",
      "Iteration number 11900 loss: 3.849395990371704\n",
      "Iteration number 12000 loss: 3.7272467613220215\n",
      "Iteration number 12100 loss: 3.726632595062256\n",
      "Iteration number 12200 loss: 3.9391708374023438\n",
      "Iteration number 12300 loss: 4.097110748291016\n",
      "Iteration number 12400 loss: 3.76486873626709\n",
      "Iteration number 12500 loss: 3.7848663330078125\n",
      "Iteration number 12600 loss: 3.6861467361450195\n",
      "Iteration number 12700 loss: 3.7275187969207764\n",
      "Iteration number 12800 loss: 3.9301657676696777\n",
      "Iteration number 12900 loss: 3.847280979156494\n",
      "Iteration number 13000 loss: 3.6582422256469727\n",
      "Iteration number 13100 loss: 3.5356221199035645\n",
      "Iteration number 13200 loss: 3.981619358062744\n",
      "Iteration number 13300 loss: 3.8813729286193848\n",
      "Iteration number 13400 loss: 3.697047233581543\n",
      "Iteration number 13500 loss: 3.8200950622558594\n",
      "Iteration number 13600 loss: 3.8789172172546387\n",
      "Iteration number 13700 loss: 3.9706525802612305\n",
      "Iteration number 13800 loss: 3.885934829711914\n",
      "Iteration number 13900 loss: 3.6811208724975586\n",
      "Iteration number 14000 loss: 3.6516456604003906\n",
      "Iteration number 14100 loss: 3.715294122695923\n",
      "Iteration number 14200 loss: 4.023768901824951\n",
      "Iteration number 14300 loss: 3.620455265045166\n",
      "Iteration number 14400 loss: 3.946719169616699\n",
      "Iteration number 14500 loss: 3.6227941513061523\n",
      "Iteration number 14600 loss: 3.7467586994171143\n",
      "Iteration number 14700 loss: 3.83626127243042\n",
      "Iteration number 14800 loss: 3.6339049339294434\n",
      "Iteration number 14900 loss: 3.953745126724243\n",
      "Iteration number 15000 loss: 3.59751296043396\n",
      "Iteration number 15100 loss: 3.7706751823425293\n",
      "Iteration number 15200 loss: 3.7924489974975586\n",
      "Iteration number 15300 loss: 3.8280739784240723\n",
      "Iteration number 15400 loss: 3.6462483406066895\n",
      "Iteration number 15500 loss: 3.4875707626342773\n",
      "Iteration number 15600 loss: 3.6332406997680664\n",
      "Iteration number 15700 loss: 3.7041168212890625\n",
      "Iteration number 15800 loss: 3.8062329292297363\n",
      "Iteration number 15900 loss: 3.118640422821045\n",
      "Iteration number 16000 loss: 3.7917251586914062\n",
      "Iteration number 16100 loss: 3.675292491912842\n",
      "Iteration number 16200 loss: 3.8792872428894043\n",
      "Iteration number 16300 loss: 3.3633079528808594\n",
      "Iteration number 16400 loss: 3.610739231109619\n",
      "Iteration number 16500 loss: 3.69401216506958\n",
      "Iteration number 16600 loss: 3.4541656970977783\n",
      "Iteration number 16700 loss: 3.3968162536621094\n",
      "Iteration number 16800 loss: 3.3398520946502686\n",
      "Iteration number 16900 loss: 3.578322172164917\n",
      "Iteration number 17000 loss: 3.6095781326293945\n",
      "Iteration number 17100 loss: 3.4457852840423584\n",
      "Iteration number 17200 loss: 3.376138210296631\n",
      "Iteration number 17300 loss: 3.6214561462402344\n",
      "Iteration number 17400 loss: 3.275045156478882\n",
      "Iteration number 17500 loss: 3.328949451446533\n",
      "Iteration number 17600 loss: 3.0076181888580322\n",
      "Iteration number 17700 loss: 3.1247053146362305\n",
      "Iteration number 17800 loss: 3.445331335067749\n",
      "Iteration number 17900 loss: 3.2910866737365723\n",
      "Iteration number 18000 loss: 3.364147663116455\n",
      "Iteration number 18100 loss: 3.0477211475372314\n",
      "Iteration number 18200 loss: 3.326580762863159\n",
      "Iteration number 18300 loss: 3.4870765209198\n",
      "Iteration number 18400 loss: 2.895547866821289\n",
      "Iteration number 18500 loss: 3.181900978088379\n",
      "Iteration number 18600 loss: 3.1927120685577393\n",
      "Iteration number 18700 loss: 2.922131061553955\n",
      "Iteration number 18800 loss: 3.1618175506591797\n",
      "Iteration number 18900 loss: 3.3767664432525635\n",
      "Iteration number 19000 loss: 3.206724166870117\n",
      "Iteration number 19100 loss: 3.017578363418579\n",
      "Iteration number 19200 loss: 3.2637927532196045\n",
      "Iteration number 19300 loss: 2.9108664989471436\n",
      "Iteration number 19400 loss: 2.7507166862487793\n",
      "Iteration number 19500 loss: 2.7460007667541504\n",
      "Iteration number 19600 loss: 2.761042356491089\n",
      "Iteration number 19700 loss: 2.9502816200256348\n",
      "Iteration number 19800 loss: 3.1076393127441406\n",
      "Iteration number 19900 loss: 3.0692694187164307\n",
      "Iteration number 20000 loss: 2.6283788681030273\n",
      "Iteration number 20100 loss: 2.3065779209136963\n",
      "Iteration number 20200 loss: 3.0588085651397705\n",
      "Iteration number 20300 loss: 2.8197014331817627\n",
      "Iteration number 20400 loss: 2.742732286453247\n",
      "Iteration number 20500 loss: 2.435211420059204\n",
      "Iteration number 20600 loss: 2.7186686992645264\n",
      "Iteration number 20700 loss: 2.4896247386932373\n",
      "Iteration number 20800 loss: 2.5535340309143066\n",
      "Iteration number 20900 loss: 3.0135788917541504\n",
      "Iteration number 21000 loss: 3.0038790702819824\n",
      "Iteration number 21100 loss: 2.8924875259399414\n",
      "Iteration number 21200 loss: 2.9519267082214355\n",
      "Iteration number 21300 loss: 2.8838233947753906\n",
      "Iteration number 21400 loss: 2.765127182006836\n",
      "Iteration number 21500 loss: 2.6790966987609863\n",
      "Iteration number 21600 loss: 2.9682860374450684\n",
      "Iteration number 21700 loss: 2.836935520172119\n",
      "Iteration number 21800 loss: 2.4727535247802734\n",
      "Iteration number 21900 loss: 2.7670817375183105\n",
      "Iteration number 22000 loss: 2.87066912651062\n",
      "Iteration number 22100 loss: 2.9722037315368652\n",
      "Iteration number 22200 loss: 2.432107448577881\n",
      "Iteration number 22300 loss: 2.4589126110076904\n",
      "Iteration number 22400 loss: 2.3218834400177\n",
      "Iteration number 22500 loss: 2.5587363243103027\n",
      "Iteration number 22600 loss: 2.5358810424804688\n",
      "Iteration number 22700 loss: 2.1713876724243164\n",
      "Iteration number 22800 loss: 2.5952200889587402\n",
      "Iteration number 22900 loss: 2.444368839263916\n",
      "Iteration number 23000 loss: 2.455435276031494\n",
      "Iteration number 23100 loss: 2.1633243560791016\n",
      "Iteration number 23200 loss: 2.9281210899353027\n",
      "Iteration number 23300 loss: 2.290579319000244\n",
      "Iteration number 23400 loss: 2.2201623916625977\n",
      "Iteration number 23500 loss: 2.0240979194641113\n",
      "Iteration number 23600 loss: 2.6125617027282715\n",
      "Iteration number 23700 loss: 2.1740896701812744\n",
      "Iteration number 23800 loss: 2.180170774459839\n",
      "Iteration number 23900 loss: 2.1795637607574463\n",
      "Iteration number 24000 loss: 2.431102752685547\n",
      "Iteration number 24100 loss: 2.26657772064209\n",
      "Iteration number 24200 loss: 2.365309238433838\n",
      "Iteration number 24300 loss: 2.471890926361084\n",
      "Iteration number 24400 loss: 2.312924861907959\n",
      "Iteration number 24500 loss: 2.613276481628418\n",
      "Iteration number 24600 loss: 2.285951614379883\n",
      "Iteration number 24700 loss: 2.304089069366455\n",
      "Iteration number 24800 loss: 2.251148223876953\n",
      "Iteration number 24900 loss: 2.673274040222168\n",
      "Iteration number 25000 loss: 2.91489839553833\n",
      "Iteration number 25100 loss: 2.9711921215057373\n",
      "Iteration number 25200 loss: 2.917243480682373\n",
      "Iteration number 25300 loss: 2.728210210800171\n",
      "Iteration number 25400 loss: 2.4167237281799316\n",
      "Iteration number 25500 loss: 2.7192559242248535\n",
      "Iteration number 25600 loss: 2.4530088901519775\n",
      "Iteration number 25700 loss: 3.139533519744873\n",
      "Iteration number 25800 loss: 2.9954357147216797\n",
      "Iteration number 25900 loss: 3.384554147720337\n",
      "Iteration number 26000 loss: 3.1491355895996094\n",
      "Iteration number 26100 loss: 3.00579571723938\n",
      "Iteration number 26200 loss: 3.2500429153442383\n",
      "Iteration number 26300 loss: 3.0185766220092773\n",
      "Iteration number 26400 loss: 3.179342269897461\n",
      "Iteration number 26500 loss: 3.2560300827026367\n",
      "Iteration number 26600 loss: 3.395996570587158\n",
      "Iteration number 26700 loss: 3.52883243560791\n",
      "Iteration number 26800 loss: 3.6997525691986084\n",
      "Iteration number 26900 loss: 3.6534173488616943\n",
      "Iteration number 27000 loss: 3.536132335662842\n",
      "Iteration number 27100 loss: 3.5092601776123047\n",
      "Iteration number 27200 loss: 3.507732391357422\n",
      "Iteration number 27300 loss: 3.4976043701171875\n",
      "Iteration number 27400 loss: 3.586623191833496\n",
      "Iteration number 27500 loss: 3.480259895324707\n",
      "Iteration number 27600 loss: 3.8408403396606445\n",
      "Iteration number 27700 loss: 3.9085330963134766\n",
      "Iteration number 27800 loss: 3.6317057609558105\n",
      "Iteration number 27900 loss: 3.5818686485290527\n",
      "Iteration number 28000 loss: 3.692107677459717\n",
      "Iteration number 28100 loss: 3.524603843688965\n",
      "Iteration number 28200 loss: 3.4744246006011963\n",
      "Iteration number 28300 loss: 3.519495725631714\n",
      "Iteration number 28400 loss: 3.298332691192627\n",
      "Iteration number 28500 loss: 3.251725673675537\n",
      "Iteration number 28600 loss: 3.6998767852783203\n",
      "Iteration number 28700 loss: 3.394350290298462\n",
      "Iteration number 28800 loss: 3.41658616065979\n",
      "Iteration number 28900 loss: 3.6684603691101074\n",
      "Iteration number 29000 loss: 3.4903621673583984\n",
      "Iteration number 29100 loss: 3.898012161254883\n",
      "Iteration number 29200 loss: 3.977553367614746\n",
      "Iteration number 29300 loss: 3.9218759536743164\n",
      "Iteration number 29400 loss: 3.411200523376465\n",
      "Iteration number 29500 loss: 3.491612434387207\n",
      "Iteration number 29600 loss: 3.491443395614624\n",
      "Iteration number 29700 loss: 3.7156946659088135\n",
      "Iteration number 29800 loss: 3.4820876121520996\n",
      "Iteration number 29900 loss: 3.751681327819824\n",
      "Iteration number 30000 loss: 3.5157017707824707\n",
      "Iteration number 30100 loss: 3.4726107120513916\n",
      "Iteration number 30200 loss: 3.6733720302581787\n",
      "Iteration number 30300 loss: 3.5418951511383057\n",
      "Iteration number 30400 loss: 3.440117359161377\n",
      "Iteration number 30500 loss: 3.442751169204712\n",
      "Iteration number 30600 loss: 3.3073909282684326\n",
      "Iteration number 30700 loss: 3.195500135421753\n",
      "Iteration number 30800 loss: 4.0499725341796875\n",
      "Iteration number 30900 loss: 3.504631280899048\n",
      "Iteration number 31000 loss: 3.103879451751709\n",
      "Iteration number 31100 loss: 3.4108498096466064\n",
      "Iteration number 31200 loss: 3.344967842102051\n",
      "Iteration number 31300 loss: 3.059126853942871\n",
      "Iteration number 31400 loss: 3.4049692153930664\n",
      "Iteration number 31500 loss: 3.1717145442962646\n",
      "Iteration number 31600 loss: 3.0144004821777344\n",
      "Iteration number 31700 loss: 3.018252372741699\n",
      "Iteration number 31800 loss: 3.3627066612243652\n",
      "Iteration number 31900 loss: 3.8436288833618164\n",
      "Iteration number 32000 loss: 3.462973117828369\n",
      "Iteration number 32100 loss: 2.9241981506347656\n",
      "Iteration number 32200 loss: 3.410884380340576\n",
      "Iteration number 32300 loss: 2.8729333877563477\n",
      "Iteration number 32400 loss: 3.1237545013427734\n",
      "Iteration number 32500 loss: 2.972848415374756\n",
      "Iteration number 32600 loss: 3.027738332748413\n",
      "Iteration number 32700 loss: 2.8752877712249756\n",
      "Iteration number 32800 loss: 3.2724838256835938\n",
      "Iteration number 32900 loss: 2.83768367767334\n",
      "Iteration number 33000 loss: 2.827909469604492\n",
      "Iteration number 33100 loss: 2.625882863998413\n",
      "Iteration number 33200 loss: 2.779055595397949\n",
      "Iteration number 33300 loss: 3.0139594078063965\n",
      "Iteration number 33400 loss: 3.205306053161621\n",
      "Iteration number 33500 loss: 2.9162073135375977\n",
      "Iteration number 33600 loss: 2.690538167953491\n",
      "Iteration number 33700 loss: 2.9627909660339355\n",
      "Iteration number 33800 loss: 2.9894003868103027\n",
      "Iteration number 33900 loss: 2.730548620223999\n",
      "Iteration number 34000 loss: 3.014986038208008\n",
      "Iteration number 34100 loss: 2.861844062805176\n",
      "Iteration number 34200 loss: 2.9018025398254395\n",
      "Iteration number 34300 loss: 2.905251979827881\n",
      "Iteration number 34400 loss: 2.8604960441589355\n",
      "Iteration number 34500 loss: 3.082167148590088\n",
      "Iteration number 34600 loss: 2.719961166381836\n",
      "Iteration number 34700 loss: 3.1163487434387207\n",
      "Iteration number 34800 loss: 2.689441442489624\n",
      "Iteration number 34900 loss: 2.9442992210388184\n",
      "Iteration number 35000 loss: 3.144895315170288\n",
      "Iteration number 35100 loss: 3.138876438140869\n",
      "Iteration number 35200 loss: 3.017627000808716\n",
      "Iteration number 35300 loss: 2.925143241882324\n",
      "Iteration number 35400 loss: 3.215684652328491\n",
      "Iteration number 35500 loss: 2.7610297203063965\n",
      "Iteration number 35600 loss: 2.9787850379943848\n",
      "Iteration number 35700 loss: 2.9208316802978516\n",
      "Iteration number 35800 loss: 2.7643017768859863\n",
      "Iteration number 35900 loss: 2.9640729427337646\n",
      "Iteration number 36000 loss: 4.077347755432129\n",
      "Iteration number 36100 loss: 2.9915013313293457\n",
      "Iteration number 36200 loss: 3.142697334289551\n",
      "Iteration number 36300 loss: 2.99920654296875\n",
      "Iteration number 36400 loss: 3.177441358566284\n",
      "Iteration number 36500 loss: 3.176130771636963\n",
      "Iteration number 36600 loss: 3.4071574211120605\n",
      "Iteration number 36700 loss: 3.19043231010437\n",
      "Iteration number 36800 loss: 3.311434745788574\n",
      "Iteration number 36900 loss: 3.4023661613464355\n",
      "Iteration number 37000 loss: 3.0870532989501953\n",
      "Iteration number 37100 loss: 3.499058246612549\n",
      "Iteration number 37200 loss: 3.0323920249938965\n",
      "Iteration number 37300 loss: 3.2572083473205566\n",
      "Iteration number 37400 loss: 3.073841094970703\n",
      "Iteration number 37500 loss: 3.23482608795166\n",
      "Iteration number 37600 loss: 2.8032491207122803\n",
      "Iteration number 37700 loss: 3.1057546138763428\n",
      "Iteration number 37800 loss: 3.28035306930542\n",
      "Iteration number 37900 loss: 3.0946526527404785\n",
      "Iteration number 38000 loss: 3.101928234100342\n",
      "Iteration number 38100 loss: 2.864452600479126\n",
      "Iteration number 38200 loss: 3.253072500228882\n",
      "Iteration number 38300 loss: 2.9553980827331543\n",
      "Iteration number 38400 loss: 3.1954848766326904\n",
      "Iteration number 38500 loss: 3.209761619567871\n",
      "Iteration number 38600 loss: 3.662757396697998\n",
      "Iteration number 38700 loss: 2.877377510070801\n",
      "Iteration number 38800 loss: 3.308586359024048\n",
      "Iteration number 38900 loss: 3.335054636001587\n",
      "Iteration number 39000 loss: 3.3105697631835938\n",
      "Iteration number 39100 loss: 3.138174533843994\n",
      "Iteration number 39200 loss: 2.7376954555511475\n",
      "Iteration number 39300 loss: 3.1620800495147705\n",
      "Iteration number 39400 loss: 3.3185081481933594\n",
      "Iteration number 39500 loss: 3.5085902214050293\n",
      "Iteration number 39600 loss: 2.980010747909546\n",
      "Iteration number 39700 loss: 2.902756690979004\n",
      "Iteration number 39800 loss: 3.178354263305664\n",
      "Iteration number 39900 loss: 3.127791404724121\n",
      "Iteration number 40000 loss: 2.997958183288574\n",
      "Iteration number 40100 loss: 3.2511584758758545\n",
      "Iteration number 40200 loss: 2.906360149383545\n",
      "Iteration number 40300 loss: 3.27036714553833\n",
      "Iteration number 40400 loss: 3.210561990737915\n",
      "Iteration number 40500 loss: 3.182319164276123\n",
      "Iteration number 40600 loss: 2.7640364170074463\n",
      "Iteration number 40700 loss: 3.007624626159668\n",
      "Iteration number 40800 loss: 3.0175657272338867\n",
      "Iteration number 40900 loss: 3.130157947540283\n",
      "Iteration number 41000 loss: 3.1854147911071777\n",
      "Iteration number 41100 loss: 2.9939961433410645\n",
      "Iteration number 41200 loss: 2.9633851051330566\n",
      "Iteration number 41300 loss: 2.9720818996429443\n",
      "Iteration number 41400 loss: 3.0614774227142334\n",
      "Iteration number 41500 loss: 3.298696994781494\n",
      "Iteration number 41600 loss: 2.989783763885498\n",
      "Iteration number 41700 loss: 2.683929920196533\n",
      "Iteration number 41800 loss: 3.072826385498047\n",
      "Iteration number 41900 loss: 3.1237380504608154\n",
      "Iteration number 42000 loss: 3.215597152709961\n",
      "Iteration number 42100 loss: 3.3047749996185303\n",
      "Iteration number 42200 loss: 3.4825854301452637\n",
      "Iteration number 42300 loss: 3.2926669120788574\n",
      "Iteration number 42400 loss: 2.859980344772339\n",
      "Iteration number 42500 loss: 3.2287797927856445\n",
      "Iteration number 42600 loss: 3.2226247787475586\n",
      "Iteration number 42700 loss: 2.9137144088745117\n",
      "Iteration number 42800 loss: 3.1345279216766357\n",
      "Iteration number 42900 loss: 2.9756317138671875\n",
      "Iteration number 43000 loss: 2.7975475788116455\n",
      "Iteration number 43100 loss: 2.8412070274353027\n",
      "Iteration number 43200 loss: 2.9433038234710693\n",
      "Iteration number 43300 loss: 3.166104793548584\n",
      "Iteration number 43400 loss: 3.399318218231201\n",
      "Iteration number 43500 loss: 3.1555871963500977\n",
      "Iteration number 43600 loss: 3.157061815261841\n",
      "Iteration number 43700 loss: 2.900205612182617\n",
      "Iteration number 43800 loss: 2.968888998031616\n",
      "Iteration number 43900 loss: 3.0469894409179688\n",
      "Iteration number 44000 loss: 2.630361318588257\n",
      "Iteration number 44100 loss: 2.865851879119873\n",
      "Iteration number 44200 loss: 3.0829997062683105\n",
      "Iteration number 44300 loss: 3.420090436935425\n",
      "Iteration number 44400 loss: 2.962965965270996\n",
      "Iteration number 44500 loss: 3.037034511566162\n",
      "Iteration number 44600 loss: 3.122311592102051\n",
      "Episode Number: 3\n",
      "Iteration number 0 loss: 2.281289577484131\n",
      "Iteration number 100 loss: 2.4769763946533203\n",
      "Iteration number 200 loss: 2.2609832286834717\n",
      "Iteration number 300 loss: 2.299574613571167\n",
      "Iteration number 400 loss: 2.6962084770202637\n",
      "Iteration number 500 loss: 2.040869951248169\n",
      "Iteration number 600 loss: 2.369774341583252\n",
      "Iteration number 700 loss: 2.367896556854248\n",
      "Iteration number 800 loss: 2.4226558208465576\n",
      "Iteration number 900 loss: 2.1938698291778564\n",
      "Iteration number 1000 loss: 2.496133327484131\n",
      "Iteration number 1100 loss: 2.8136463165283203\n",
      "Iteration number 1200 loss: 2.6165976524353027\n",
      "Iteration number 1300 loss: 2.1659679412841797\n",
      "Iteration number 1400 loss: 2.6061854362487793\n",
      "Iteration number 1500 loss: 2.361342430114746\n",
      "Iteration number 1600 loss: 2.0808615684509277\n",
      "Iteration number 1700 loss: 2.4585747718811035\n",
      "Iteration number 1800 loss: 2.3753795623779297\n",
      "Iteration number 1900 loss: 2.2584493160247803\n",
      "Iteration number 2000 loss: 2.3493385314941406\n",
      "Iteration number 2100 loss: 2.4750213623046875\n",
      "Iteration number 2200 loss: 2.0710761547088623\n",
      "Iteration number 2300 loss: 2.36794376373291\n",
      "Iteration number 2400 loss: 2.409242630004883\n",
      "Iteration number 2500 loss: 2.1981565952301025\n",
      "Iteration number 2600 loss: 2.8311684131622314\n",
      "Iteration number 2700 loss: 2.278285503387451\n",
      "Iteration number 2800 loss: 2.2892520427703857\n",
      "Iteration number 2900 loss: 2.299790382385254\n",
      "Iteration number 3000 loss: 2.368696451187134\n",
      "Iteration number 3100 loss: 2.377570629119873\n",
      "Iteration number 3200 loss: 2.4668164253234863\n",
      "Iteration number 3300 loss: 2.6084775924682617\n",
      "Iteration number 3400 loss: 2.4478707313537598\n",
      "Iteration number 3500 loss: 2.7080087661743164\n",
      "Iteration number 3600 loss: 2.27164888381958\n",
      "Iteration number 3700 loss: 2.059439182281494\n",
      "Iteration number 3800 loss: 2.23649263381958\n",
      "Iteration number 3900 loss: 2.4273829460144043\n",
      "Episode Number: 4\n",
      "Iteration number 0 loss: 2.1100425720214844\n",
      "Iteration number 100 loss: 2.0461111068725586\n",
      "Iteration number 200 loss: 2.3055059909820557\n",
      "Iteration number 300 loss: 2.3400182723999023\n",
      "Iteration number 400 loss: 2.2579002380371094\n",
      "Iteration number 500 loss: 2.0474350452423096\n",
      "Iteration number 600 loss: 2.3972229957580566\n",
      "Iteration number 700 loss: 2.503787040710449\n",
      "Iteration number 800 loss: 2.3993921279907227\n",
      "Iteration number 900 loss: 2.453340530395508\n",
      "Iteration number 1000 loss: 2.225560426712036\n",
      "Iteration number 1100 loss: 2.420013904571533\n",
      "Iteration number 1200 loss: 2.4680583477020264\n",
      "Iteration number 1300 loss: 2.5455663204193115\n",
      "Iteration number 1400 loss: 2.2480974197387695\n",
      "Iteration number 1500 loss: 2.130251884460449\n",
      "Iteration number 1600 loss: 2.32077693939209\n",
      "Iteration number 1700 loss: 2.5907790660858154\n",
      "Iteration number 1800 loss: 2.575641632080078\n",
      "Iteration number 1900 loss: 2.402444362640381\n",
      "Iteration number 2000 loss: 2.3176493644714355\n",
      "Iteration number 2100 loss: 2.123875856399536\n",
      "Iteration number 2200 loss: 2.0847840309143066\n",
      "Iteration number 2300 loss: 2.489434242248535\n",
      "Iteration number 2400 loss: 2.5118303298950195\n",
      "Iteration number 2500 loss: 2.224513530731201\n",
      "Iteration number 2600 loss: 2.1752126216888428\n",
      "Iteration number 2700 loss: 2.400986671447754\n",
      "Iteration number 2800 loss: 2.5831127166748047\n",
      "Iteration number 2900 loss: 2.5546467304229736\n",
      "Iteration number 3000 loss: 2.316115140914917\n",
      "Iteration number 3100 loss: 2.3400793075561523\n",
      "Iteration number 3200 loss: 2.446099281311035\n",
      "Iteration number 3300 loss: 2.6407670974731445\n",
      "Iteration number 3400 loss: 2.140009880065918\n",
      "Iteration number 3500 loss: 2.2835023403167725\n",
      "Iteration number 3600 loss: 2.47462797164917\n",
      "Iteration number 3700 loss: 2.611375331878662\n",
      "Iteration number 3800 loss: 2.397658586502075\n",
      "Iteration number 3900 loss: 2.359462261199951\n",
      "Iteration number 4000 loss: 2.5881855487823486\n",
      "Iteration number 4100 loss: 2.9314966201782227\n",
      "Iteration number 4200 loss: 2.4524056911468506\n",
      "Iteration number 4300 loss: 2.3136024475097656\n",
      "Iteration number 4400 loss: 2.6267402172088623\n",
      "Iteration number 4500 loss: 2.0654473304748535\n",
      "Iteration number 4600 loss: 2.322073459625244\n",
      "Iteration number 4700 loss: 2.1997292041778564\n",
      "Iteration number 4800 loss: 2.2943601608276367\n",
      "Iteration number 4900 loss: 2.0617270469665527\n",
      "Iteration number 5000 loss: 2.661635398864746\n",
      "Iteration number 5100 loss: 2.5814719200134277\n",
      "Iteration number 5200 loss: 2.7579798698425293\n",
      "Episode Number: 5\n",
      "Iteration number 0 loss: 2.548186779022217\n",
      "Iteration number 100 loss: 2.669661283493042\n",
      "Iteration number 200 loss: 2.184051036834717\n",
      "Iteration number 300 loss: 2.442115306854248\n",
      "Iteration number 400 loss: 2.825464963912964\n",
      "Iteration number 500 loss: 2.2405214309692383\n",
      "Iteration number 600 loss: 2.159294605255127\n",
      "Iteration number 700 loss: 2.2591781616210938\n",
      "Iteration number 800 loss: 2.248710870742798\n",
      "Iteration number 900 loss: 2.0855813026428223\n",
      "Iteration number 1000 loss: 2.28411865234375\n",
      "Iteration number 1100 loss: 2.3377292156219482\n",
      "Iteration number 1200 loss: 2.4944849014282227\n",
      "Iteration number 1300 loss: 2.254756212234497\n",
      "Iteration number 1400 loss: 2.522991180419922\n",
      "Iteration number 1500 loss: 2.508615493774414\n",
      "Iteration number 1600 loss: 1.79860520362854\n",
      "Iteration number 1700 loss: 2.2683775424957275\n",
      "Iteration number 1800 loss: 2.5178709030151367\n",
      "Iteration number 1900 loss: 2.6064674854278564\n",
      "Iteration number 2000 loss: 2.3254520893096924\n",
      "Iteration number 2100 loss: 2.33677339553833\n",
      "Iteration number 2200 loss: 2.229618787765503\n",
      "Iteration number 2300 loss: 2.524583578109741\n",
      "Iteration number 2400 loss: 2.1866259574890137\n",
      "Iteration number 2500 loss: 2.0990376472473145\n",
      "Iteration number 2600 loss: 2.3763442039489746\n",
      "Iteration number 2700 loss: 2.372447967529297\n",
      "Iteration number 2800 loss: 2.650527000427246\n",
      "Iteration number 2900 loss: 2.3289337158203125\n",
      "Iteration number 3000 loss: 2.1580328941345215\n",
      "Iteration number 3100 loss: 2.1335668563842773\n",
      "Iteration number 3200 loss: 2.2723336219787598\n",
      "Iteration number 3300 loss: 2.3878848552703857\n",
      "Iteration number 3400 loss: 2.1612353324890137\n",
      "Iteration number 3500 loss: 2.813316822052002\n",
      "Iteration number 3600 loss: 2.3344297409057617\n",
      "Iteration number 3700 loss: 2.392467498779297\n",
      "Iteration number 3800 loss: 2.7499775886535645\n",
      "Iteration number 3900 loss: 2.134186029434204\n",
      "Iteration number 4000 loss: 2.1731815338134766\n",
      "Iteration number 4100 loss: 2.374265193939209\n",
      "Iteration number 4200 loss: 2.2393336296081543\n",
      "Iteration number 4300 loss: 2.2999191284179688\n",
      "Iteration number 4400 loss: 2.419435977935791\n",
      "Iteration number 4500 loss: 2.3520584106445312\n",
      "Iteration number 4600 loss: 2.1789135932922363\n",
      "Iteration number 4700 loss: 2.3472352027893066\n",
      "Iteration number 4800 loss: 2.2892813682556152\n",
      "Iteration number 4900 loss: 2.4594695568084717\n",
      "Iteration number 5000 loss: 2.4581727981567383\n",
      "Iteration number 5100 loss: 2.3930416107177734\n",
      "Iteration number 5200 loss: 2.4575934410095215\n",
      "Iteration number 5300 loss: 2.3303775787353516\n",
      "Iteration number 5400 loss: 2.386854887008667\n",
      "Iteration number 5500 loss: 2.2538514137268066\n",
      "Iteration number 5600 loss: 2.1930348873138428\n",
      "Iteration number 5700 loss: 1.931182622909546\n",
      "Iteration number 5800 loss: 2.172677993774414\n",
      "Iteration number 5900 loss: 2.629129409790039\n",
      "Iteration number 6000 loss: 2.271073341369629\n",
      "Iteration number 6100 loss: 2.3865156173706055\n",
      "Iteration number 6200 loss: 2.3690481185913086\n",
      "Iteration number 6300 loss: 2.2529916763305664\n",
      "Iteration number 6400 loss: 2.3442955017089844\n",
      "Iteration number 6500 loss: 2.478139638900757\n",
      "Iteration number 6600 loss: 1.9823284149169922\n",
      "Iteration number 6700 loss: 2.4907102584838867\n",
      "Iteration number 6800 loss: 2.369535446166992\n",
      "Iteration number 6900 loss: 2.315103054046631\n",
      "Iteration number 7000 loss: 2.3123371601104736\n",
      "Iteration number 7100 loss: 1.9905822277069092\n",
      "Iteration number 7200 loss: 2.4026293754577637\n",
      "Iteration number 7300 loss: 2.0621352195739746\n",
      "Iteration number 7400 loss: 1.9842045307159424\n",
      "Iteration number 7500 loss: 1.9538438320159912\n",
      "Iteration number 7600 loss: 2.387681722640991\n",
      "Iteration number 7700 loss: 2.169827461242676\n",
      "Iteration number 7800 loss: 2.2818996906280518\n",
      "Iteration number 7900 loss: 2.1064465045928955\n",
      "Iteration number 8000 loss: 2.3686201572418213\n",
      "Iteration number 8100 loss: 2.864710569381714\n",
      "Iteration number 8200 loss: 2.4698128700256348\n",
      "Iteration number 8300 loss: 2.5869626998901367\n",
      "Iteration number 8400 loss: 2.522428512573242\n",
      "Iteration number 8500 loss: 2.099583625793457\n",
      "Iteration number 8600 loss: 2.3746495246887207\n",
      "Iteration number 8700 loss: 2.5941295623779297\n",
      "Iteration number 8800 loss: 2.4710500240325928\n",
      "Iteration number 8900 loss: 2.4998326301574707\n",
      "Iteration number 9000 loss: 2.1148786544799805\n",
      "Iteration number 9100 loss: 2.2161600589752197\n",
      "Iteration number 9200 loss: 1.8728837966918945\n",
      "Iteration number 9300 loss: 2.4529128074645996\n",
      "Iteration number 9400 loss: 2.4021048545837402\n",
      "Iteration number 9500 loss: 2.342376232147217\n",
      "Iteration number 9600 loss: 2.4636447429656982\n",
      "Iteration number 9700 loss: 2.58516263961792\n",
      "Iteration number 9800 loss: 2.405247688293457\n",
      "Iteration number 9900 loss: 2.2759077548980713\n",
      "Iteration number 10000 loss: 2.662428617477417\n",
      "Iteration number 10100 loss: 2.4209837913513184\n",
      "Iteration number 10200 loss: 2.6554031372070312\n",
      "Iteration number 10300 loss: 2.227823257446289\n",
      "Iteration number 10400 loss: 2.512077808380127\n",
      "Iteration number 10500 loss: 2.4465324878692627\n",
      "Iteration number 10600 loss: 2.612077474594116\n",
      "Iteration number 10700 loss: 2.2789876461029053\n",
      "Iteration number 10800 loss: 2.0694851875305176\n",
      "Iteration number 10900 loss: 2.483339786529541\n",
      "Iteration number 11000 loss: 2.408088445663452\n",
      "Iteration number 11100 loss: 2.143892288208008\n",
      "Iteration number 11200 loss: 2.414541482925415\n",
      "Iteration number 11300 loss: 2.0356509685516357\n",
      "Iteration number 11400 loss: 2.4558889865875244\n",
      "Iteration number 11500 loss: 2.3989267349243164\n",
      "Iteration number 11600 loss: 2.5992727279663086\n",
      "Iteration number 11700 loss: 2.4354066848754883\n",
      "Iteration number 11800 loss: 2.592155933380127\n",
      "Iteration number 11900 loss: 2.549335241317749\n",
      "Iteration number 12000 loss: 2.762007236480713\n",
      "Iteration number 12100 loss: 2.292573928833008\n",
      "Iteration number 12200 loss: 2.27476167678833\n",
      "Iteration number 12300 loss: 2.8579907417297363\n",
      "Iteration number 12400 loss: 2.6395211219787598\n",
      "Iteration number 12500 loss: 2.129758596420288\n",
      "Iteration number 12600 loss: 2.324930191040039\n",
      "Iteration number 12700 loss: 2.294304847717285\n",
      "Iteration number 12800 loss: 2.5786848068237305\n",
      "Iteration number 12900 loss: 2.4415650367736816\n",
      "Iteration number 13000 loss: 2.459733486175537\n",
      "Iteration number 13100 loss: 2.46755051612854\n",
      "Iteration number 13200 loss: 2.4704294204711914\n",
      "Iteration number 13300 loss: 2.158019781112671\n",
      "Iteration number 13400 loss: 2.660228967666626\n",
      "Iteration number 13500 loss: 2.4836440086364746\n",
      "Iteration number 13600 loss: 2.7890987396240234\n",
      "Iteration number 13700 loss: 2.4414000511169434\n",
      "Iteration number 13800 loss: 2.178496837615967\n",
      "Iteration number 13900 loss: 2.8129773139953613\n",
      "Iteration number 14000 loss: 2.5273642539978027\n",
      "Iteration number 14100 loss: 2.3675971031188965\n",
      "Iteration number 14200 loss: 2.8647284507751465\n",
      "Iteration number 14300 loss: 2.076216220855713\n",
      "Iteration number 14400 loss: 2.7092247009277344\n",
      "Iteration number 14500 loss: 2.5424294471740723\n",
      "Iteration number 14600 loss: 2.5512146949768066\n",
      "Iteration number 14700 loss: 2.386356830596924\n",
      "Iteration number 14800 loss: 2.4633145332336426\n",
      "Iteration number 14900 loss: 2.222311496734619\n",
      "Iteration number 15000 loss: 2.523195743560791\n",
      "Iteration number 15100 loss: 2.3723738193511963\n",
      "Iteration number 15200 loss: 2.2927069664001465\n",
      "Iteration number 15300 loss: 2.433530330657959\n",
      "Iteration number 15400 loss: 2.466899871826172\n",
      "Iteration number 15500 loss: 2.2557272911071777\n",
      "Iteration number 15600 loss: 2.3087732791900635\n",
      "Iteration number 15700 loss: 2.504788875579834\n",
      "Iteration number 15800 loss: 2.4257700443267822\n",
      "Iteration number 15900 loss: 2.4930219650268555\n",
      "Iteration number 16000 loss: 2.2832047939300537\n",
      "Iteration number 16100 loss: 2.5680971145629883\n",
      "Iteration number 16200 loss: 2.6144745349884033\n",
      "Iteration number 16300 loss: 2.506263256072998\n",
      "Iteration number 16400 loss: 2.701070785522461\n",
      "Iteration number 16500 loss: 2.7712104320526123\n",
      "Iteration number 16600 loss: 2.2548227310180664\n",
      "Iteration number 16700 loss: 2.4655489921569824\n",
      "Iteration number 16800 loss: 2.126331090927124\n",
      "Iteration number 16900 loss: 2.010552406311035\n",
      "Iteration number 17000 loss: 2.367125988006592\n",
      "Iteration number 17100 loss: 2.5753707885742188\n",
      "Iteration number 17200 loss: 2.3942344188690186\n",
      "Iteration number 17300 loss: 2.152742624282837\n",
      "Iteration number 17400 loss: 2.5050137042999268\n",
      "Iteration number 17500 loss: 2.1934733390808105\n",
      "Iteration number 17600 loss: 2.2834320068359375\n",
      "Iteration number 17700 loss: 2.1384854316711426\n",
      "Iteration number 17800 loss: 2.263882875442505\n",
      "Iteration number 17900 loss: 2.223271369934082\n",
      "Iteration number 18000 loss: 2.011688709259033\n",
      "Iteration number 18100 loss: 2.1980466842651367\n",
      "Iteration number 18200 loss: 1.8114581108093262\n",
      "Iteration number 18300 loss: 2.0233263969421387\n",
      "Iteration number 18400 loss: 2.1103858947753906\n",
      "Iteration number 18500 loss: 2.1497740745544434\n",
      "Iteration number 18600 loss: 2.001370429992676\n",
      "Iteration number 18700 loss: 2.0000009536743164\n",
      "Iteration number 18800 loss: 1.9731416702270508\n",
      "Iteration number 18900 loss: 1.942313313484192\n",
      "Iteration number 19000 loss: 2.3384275436401367\n",
      "Iteration number 19100 loss: 2.0679304599761963\n",
      "Iteration number 19200 loss: 1.9560120105743408\n",
      "Iteration number 19300 loss: 1.8976813554763794\n",
      "Iteration number 19400 loss: 1.8339067697525024\n",
      "Iteration number 19500 loss: 2.3378782272338867\n",
      "Iteration number 19600 loss: 2.3345770835876465\n",
      "Iteration number 19700 loss: 1.926870584487915\n",
      "Iteration number 19800 loss: 2.015477180480957\n",
      "Iteration number 19900 loss: 2.075955867767334\n",
      "Iteration number 20000 loss: 2.3476924896240234\n",
      "Iteration number 20100 loss: 2.2516956329345703\n",
      "Episode Number: 6\n",
      "Iteration number 0 loss: 2.9340052604675293\n",
      "Iteration number 100 loss: 2.9492626190185547\n",
      "Iteration number 200 loss: 2.530313014984131\n",
      "Iteration number 300 loss: 2.762317657470703\n",
      "Iteration number 400 loss: 2.804443836212158\n",
      "Iteration number 500 loss: 2.9447083473205566\n",
      "Iteration number 600 loss: 2.8287386894226074\n",
      "Iteration number 700 loss: 2.6445517539978027\n",
      "Iteration number 800 loss: 2.7533130645751953\n",
      "Iteration number 900 loss: 2.7496113777160645\n",
      "Iteration number 1000 loss: 2.547219753265381\n",
      "Iteration number 1100 loss: 2.624533176422119\n",
      "Iteration number 1200 loss: 2.811074733734131\n",
      "Iteration number 1300 loss: 2.611795425415039\n",
      "Iteration number 1400 loss: 2.40073823928833\n",
      "Iteration number 1500 loss: 2.8894095420837402\n",
      "Iteration number 1600 loss: 2.7914352416992188\n",
      "Iteration number 1700 loss: 2.7478017807006836\n",
      "Iteration number 1800 loss: 2.530148506164551\n",
      "Iteration number 1900 loss: 2.953543186187744\n",
      "Iteration number 2000 loss: 2.809110641479492\n",
      "Iteration number 2100 loss: 3.018962860107422\n",
      "Iteration number 2200 loss: 3.035449981689453\n",
      "Iteration number 2300 loss: 3.1331324577331543\n",
      "Iteration number 2400 loss: 2.822040319442749\n",
      "Iteration number 2500 loss: 2.780730962753296\n",
      "Iteration number 2600 loss: 2.8026340007781982\n",
      "Iteration number 2700 loss: 3.0222885608673096\n",
      "Iteration number 2800 loss: 2.969688892364502\n",
      "Iteration number 2900 loss: 2.948134183883667\n",
      "Iteration number 3000 loss: 2.9527039527893066\n",
      "Iteration number 3100 loss: 2.869960069656372\n",
      "Iteration number 3200 loss: 3.0420312881469727\n",
      "Iteration number 3300 loss: 2.9378442764282227\n",
      "Iteration number 3400 loss: 2.8270111083984375\n",
      "Iteration number 3500 loss: 3.0744566917419434\n",
      "Iteration number 3600 loss: 2.9642419815063477\n",
      "Iteration number 3700 loss: 2.813744068145752\n",
      "Iteration number 3800 loss: 2.972384452819824\n",
      "Iteration number 3900 loss: 2.7427167892456055\n",
      "Iteration number 4000 loss: 3.076956272125244\n",
      "Iteration number 4100 loss: 3.050881862640381\n",
      "Iteration number 4200 loss: 2.8852810859680176\n",
      "Iteration number 4300 loss: 2.868239402770996\n",
      "Iteration number 4400 loss: 3.1075782775878906\n",
      "Iteration number 4500 loss: 2.938887119293213\n",
      "Iteration number 4600 loss: 2.795257568359375\n",
      "Iteration number 4700 loss: 2.803626537322998\n",
      "Iteration number 4800 loss: 3.1014046669006348\n",
      "Iteration number 4900 loss: 2.9337284564971924\n",
      "Iteration number 5000 loss: 2.9786300659179688\n",
      "Iteration number 5100 loss: 2.9350430965423584\n",
      "Iteration number 5200 loss: 2.7368431091308594\n",
      "Iteration number 5300 loss: 3.0847866535186768\n",
      "Iteration number 5400 loss: 2.8142080307006836\n",
      "Iteration number 5500 loss: 2.7379989624023438\n",
      "Iteration number 5600 loss: 2.7404258251190186\n",
      "Iteration number 5700 loss: 2.9051742553710938\n",
      "Iteration number 5800 loss: 3.2059104442596436\n",
      "Iteration number 5900 loss: 2.507870674133301\n",
      "Iteration number 6000 loss: 2.3420045375823975\n",
      "Iteration number 6100 loss: 2.2739644050598145\n",
      "Iteration number 6200 loss: 2.301492214202881\n",
      "Iteration number 6300 loss: 2.116478443145752\n",
      "Iteration number 6400 loss: 2.325965404510498\n",
      "Iteration number 6500 loss: 2.774466037750244\n",
      "Iteration number 6600 loss: 2.9050121307373047\n",
      "Iteration number 6700 loss: 2.676098585128784\n",
      "Iteration number 6800 loss: 2.7304000854492188\n",
      "Iteration number 6900 loss: 2.7760863304138184\n",
      "Iteration number 7000 loss: 2.8350839614868164\n",
      "Iteration number 7100 loss: 2.8703317642211914\n",
      "Iteration number 7200 loss: 2.9561915397644043\n",
      "Iteration number 7300 loss: 2.3438668251037598\n",
      "Iteration number 7400 loss: 1.8633283376693726\n",
      "Iteration number 7500 loss: 1.921055793762207\n",
      "Iteration number 7600 loss: 2.1367499828338623\n",
      "Iteration number 7700 loss: 2.2743418216705322\n",
      "Iteration number 7800 loss: 2.123239517211914\n",
      "Iteration number 7900 loss: 1.860971450805664\n",
      "Iteration number 8000 loss: 2.388439416885376\n",
      "Iteration number 8100 loss: 2.5071511268615723\n",
      "Iteration number 8200 loss: 2.7308104038238525\n",
      "Iteration number 8300 loss: 2.4695510864257812\n",
      "Episode Number: 7\n",
      "Iteration number 0 loss: 2.231501579284668\n",
      "Iteration number 100 loss: 2.1588294506073\n",
      "Iteration number 200 loss: 2.462221622467041\n",
      "Iteration number 300 loss: 2.524609088897705\n",
      "Iteration number 400 loss: 2.3546016216278076\n",
      "Iteration number 500 loss: 2.4047911167144775\n",
      "Iteration number 600 loss: 2.3284502029418945\n",
      "Iteration number 700 loss: 2.3050894737243652\n",
      "Iteration number 800 loss: 2.2848000526428223\n",
      "Iteration number 900 loss: 2.2489733695983887\n",
      "Iteration number 1000 loss: 1.9648290872573853\n",
      "Iteration number 1100 loss: 2.222797393798828\n",
      "Iteration number 1200 loss: 1.8403573036193848\n",
      "Iteration number 1300 loss: 2.3159399032592773\n",
      "Iteration number 1400 loss: 2.141338348388672\n",
      "Iteration number 1500 loss: 2.16672945022583\n",
      "Iteration number 1600 loss: 2.0108306407928467\n",
      "Iteration number 1700 loss: 2.086113452911377\n",
      "Iteration number 1800 loss: 2.0560712814331055\n",
      "Iteration number 1900 loss: 2.1001715660095215\n",
      "Iteration number 2000 loss: 2.5105245113372803\n",
      "Iteration number 2100 loss: 2.2094473838806152\n",
      "Iteration number 2200 loss: 1.877150535583496\n",
      "Iteration number 2300 loss: 2.4612696170806885\n",
      "Iteration number 2400 loss: 2.0586626529693604\n",
      "Iteration number 2500 loss: 2.225602626800537\n",
      "Iteration number 2600 loss: 2.2609498500823975\n",
      "Iteration number 2700 loss: 2.1044130325317383\n",
      "Iteration number 2800 loss: 1.7708408832550049\n",
      "Iteration number 2900 loss: 2.010939836502075\n",
      "Iteration number 3000 loss: 2.1401209831237793\n",
      "Iteration number 3100 loss: 1.9053800106048584\n",
      "Iteration number 3200 loss: 2.3634238243103027\n",
      "Iteration number 3300 loss: 1.9717777967453003\n",
      "Iteration number 3400 loss: 2.06870174407959\n",
      "Episode Number: 8\n",
      "Iteration number 0 loss: 1.8531358242034912\n",
      "Iteration number 100 loss: 2.2074995040893555\n",
      "Iteration number 200 loss: 2.1232430934906006\n",
      "Iteration number 300 loss: 2.0853495597839355\n",
      "Iteration number 400 loss: 2.0712790489196777\n",
      "Iteration number 500 loss: 1.8775500059127808\n",
      "Iteration number 600 loss: 1.9915400743484497\n",
      "Iteration number 700 loss: 2.1624598503112793\n",
      "Iteration number 800 loss: 2.057793140411377\n",
      "Iteration number 900 loss: 2.116288900375366\n",
      "Iteration number 1000 loss: 2.226384401321411\n",
      "Iteration number 1100 loss: 2.2529263496398926\n",
      "Iteration number 1200 loss: 1.7244566679000854\n",
      "Iteration number 1300 loss: 2.179475784301758\n",
      "Iteration number 1400 loss: 2.2537875175476074\n",
      "Iteration number 1500 loss: 2.0995917320251465\n",
      "Iteration number 1600 loss: 1.9997668266296387\n",
      "Iteration number 1700 loss: 2.278592824935913\n",
      "Iteration number 1800 loss: 2.0443098545074463\n",
      "Iteration number 1900 loss: 2.1807591915130615\n",
      "Iteration number 2000 loss: 2.382481098175049\n",
      "Iteration number 2100 loss: 2.1379611492156982\n",
      "Iteration number 2200 loss: 2.1130640506744385\n",
      "Iteration number 2300 loss: 2.0131025314331055\n",
      "Iteration number 2400 loss: 2.263340950012207\n",
      "Iteration number 2500 loss: 2.1043145656585693\n",
      "Iteration number 2600 loss: 2.331500768661499\n",
      "Iteration number 2700 loss: 1.8982917070388794\n",
      "Iteration number 2800 loss: 2.160552501678467\n",
      "Iteration number 2900 loss: 2.0992400646209717\n",
      "Iteration number 3000 loss: 2.003598690032959\n",
      "Iteration number 3100 loss: 2.0474822521209717\n",
      "Iteration number 3200 loss: 2.3826653957366943\n",
      "Iteration number 3300 loss: 1.96555757522583\n",
      "Iteration number 3400 loss: 2.113272190093994\n",
      "Iteration number 3500 loss: 2.037205219268799\n",
      "Iteration number 3600 loss: 2.3537533283233643\n",
      "Iteration number 3700 loss: 2.2380292415618896\n",
      "Iteration number 3800 loss: 2.3215231895446777\n",
      "Iteration number 3900 loss: 1.8354532718658447\n",
      "Iteration number 4000 loss: 2.365084171295166\n",
      "Iteration number 4100 loss: 2.0091893672943115\n",
      "Iteration number 4200 loss: 2.070012331008911\n",
      "Iteration number 4300 loss: 1.9031399488449097\n",
      "Iteration number 4400 loss: 2.2037322521209717\n",
      "Iteration number 4500 loss: 2.1663084030151367\n",
      "Iteration number 4600 loss: 2.428405284881592\n",
      "Iteration number 4700 loss: 2.196791172027588\n",
      "Iteration number 4800 loss: 2.5492444038391113\n",
      "Iteration number 4900 loss: 1.8916577100753784\n",
      "Iteration number 5000 loss: 2.229417085647583\n",
      "Iteration number 5100 loss: 2.1776041984558105\n",
      "Iteration number 5200 loss: 2.3185086250305176\n",
      "Iteration number 5300 loss: 2.1051361560821533\n",
      "Iteration number 5400 loss: 1.9792274236679077\n",
      "Iteration number 5500 loss: 2.4721810817718506\n",
      "Iteration number 5600 loss: 2.4015283584594727\n",
      "Iteration number 5700 loss: 2.31245493888855\n",
      "Iteration number 5800 loss: 2.7080633640289307\n",
      "Iteration number 5900 loss: 2.438375949859619\n",
      "Iteration number 6000 loss: 2.132185935974121\n",
      "Iteration number 6100 loss: 2.0595107078552246\n",
      "Iteration number 6200 loss: 2.672048807144165\n",
      "Iteration number 6300 loss: 2.512136459350586\n",
      "Iteration number 6400 loss: 2.4427003860473633\n",
      "Iteration number 6500 loss: 2.1200623512268066\n",
      "Iteration number 6600 loss: 1.835866928100586\n",
      "Iteration number 6700 loss: 2.3683886528015137\n",
      "Iteration number 6800 loss: 1.9727704524993896\n",
      "Iteration number 6900 loss: 1.9301855564117432\n",
      "Iteration number 7000 loss: 2.10744571685791\n",
      "Iteration number 7100 loss: 2.1407227516174316\n",
      "Iteration number 7200 loss: 2.083704710006714\n",
      "Iteration number 7300 loss: 2.0902326107025146\n",
      "Iteration number 7400 loss: 1.9706958532333374\n",
      "Iteration number 7500 loss: 1.8729522228240967\n",
      "Iteration number 7600 loss: 2.057476043701172\n",
      "Iteration number 7700 loss: 2.3266351222991943\n",
      "Iteration number 7800 loss: 2.0638175010681152\n",
      "Iteration number 7900 loss: 1.9978152513504028\n",
      "Iteration number 8000 loss: 2.041071891784668\n",
      "Iteration number 8100 loss: 1.9711635112762451\n",
      "Iteration number 8200 loss: 2.093564748764038\n",
      "Iteration number 8300 loss: 1.9337213039398193\n",
      "Iteration number 8400 loss: 2.1663010120391846\n",
      "Iteration number 8500 loss: 2.114436388015747\n",
      "Iteration number 8600 loss: 1.8730231523513794\n",
      "Iteration number 8700 loss: 2.4136717319488525\n",
      "Iteration number 8800 loss: 2.145197629928589\n",
      "Iteration number 8900 loss: 2.1343729496002197\n",
      "Iteration number 9000 loss: 2.1742234230041504\n",
      "Iteration number 9100 loss: 1.8575263023376465\n",
      "Iteration number 9200 loss: 2.142609119415283\n",
      "Iteration number 9300 loss: 1.9927102327346802\n",
      "Iteration number 9400 loss: 2.0077126026153564\n",
      "Iteration number 9500 loss: 2.333878517150879\n",
      "Iteration number 9600 loss: 1.9937793016433716\n",
      "Iteration number 9700 loss: 2.0175442695617676\n",
      "Iteration number 9800 loss: 1.8262399435043335\n",
      "Iteration number 9900 loss: 1.870387315750122\n",
      "Iteration number 10000 loss: 2.122537612915039\n",
      "Iteration number 10100 loss: 1.785504937171936\n",
      "Iteration number 10200 loss: 2.1148855686187744\n",
      "Iteration number 10300 loss: 1.8798677921295166\n",
      "Iteration number 10400 loss: 2.043682098388672\n",
      "Iteration number 10500 loss: 2.0325827598571777\n",
      "Iteration number 10600 loss: 2.0651755332946777\n",
      "Iteration number 10700 loss: 1.9310803413391113\n",
      "Iteration number 10800 loss: 1.9685193300247192\n",
      "Iteration number 10900 loss: 1.9461013078689575\n",
      "Iteration number 11000 loss: 1.9453051090240479\n",
      "Iteration number 11100 loss: 1.8519680500030518\n",
      "Iteration number 11200 loss: 2.0446436405181885\n",
      "Iteration number 11300 loss: 1.8543381690979004\n",
      "Iteration number 11400 loss: 1.8522019386291504\n",
      "Iteration number 11500 loss: 2.167922019958496\n",
      "Iteration number 11600 loss: 2.0497732162475586\n",
      "Iteration number 11700 loss: 2.353808879852295\n",
      "Iteration number 11800 loss: 1.824310064315796\n",
      "Iteration number 11900 loss: 1.8007996082305908\n",
      "Iteration number 12000 loss: 2.1810028553009033\n",
      "Iteration number 12100 loss: 2.1500585079193115\n",
      "Iteration number 12200 loss: 1.8847837448120117\n",
      "Iteration number 12300 loss: 2.13114595413208\n",
      "Iteration number 12400 loss: 1.8643033504486084\n",
      "Iteration number 12500 loss: 2.2546157836914062\n",
      "Iteration number 12600 loss: 2.077258586883545\n",
      "Iteration number 12700 loss: 1.872281551361084\n",
      "Iteration number 12800 loss: 2.012439250946045\n",
      "Iteration number 12900 loss: 2.0059618949890137\n",
      "Iteration number 13000 loss: 2.118868350982666\n",
      "Iteration number 13100 loss: 2.2159931659698486\n",
      "Iteration number 13200 loss: 2.1918787956237793\n",
      "Iteration number 13300 loss: 1.9900321960449219\n",
      "Iteration number 13400 loss: 2.115762948989868\n",
      "Iteration number 13500 loss: 1.965796947479248\n",
      "Iteration number 13600 loss: 2.0280966758728027\n",
      "Iteration number 13700 loss: 1.680696725845337\n",
      "Iteration number 13800 loss: 1.8330131769180298\n",
      "Iteration number 13900 loss: 1.9512571096420288\n",
      "Iteration number 14000 loss: 2.165604591369629\n",
      "Iteration number 14100 loss: 1.7725731134414673\n",
      "Iteration number 14200 loss: 1.8655922412872314\n",
      "Iteration number 14300 loss: 2.0228235721588135\n",
      "Iteration number 14400 loss: 1.9238057136535645\n",
      "Iteration number 14500 loss: 2.046107292175293\n",
      "Iteration number 14600 loss: 1.8162237405776978\n",
      "Iteration number 14700 loss: 2.123959541320801\n",
      "Iteration number 14800 loss: 1.9172663688659668\n",
      "Iteration number 14900 loss: 1.947127103805542\n",
      "Iteration number 15000 loss: 1.8413538932800293\n",
      "Iteration number 15100 loss: 2.052643299102783\n",
      "Iteration number 15200 loss: 1.78093683719635\n",
      "Iteration number 15300 loss: 1.6769652366638184\n",
      "Iteration number 15400 loss: 1.9201503992080688\n",
      "Iteration number 15500 loss: 1.732636570930481\n",
      "Iteration number 15600 loss: 2.0694470405578613\n",
      "Iteration number 15700 loss: 2.06826114654541\n",
      "Iteration number 15800 loss: 1.7902569770812988\n",
      "Iteration number 15900 loss: 1.8797478675842285\n",
      "Iteration number 16000 loss: 1.9165109395980835\n",
      "Iteration number 16100 loss: 1.8714678287506104\n",
      "Iteration number 16200 loss: 1.9944052696228027\n",
      "Iteration number 16300 loss: 2.073307514190674\n",
      "Iteration number 16400 loss: 2.018104076385498\n",
      "Iteration number 16500 loss: 1.9046130180358887\n",
      "Iteration number 16600 loss: 2.0457284450531006\n",
      "Iteration number 16700 loss: 1.8566635847091675\n",
      "Iteration number 16800 loss: 1.8174184560775757\n",
      "Iteration number 16900 loss: 1.9482189416885376\n",
      "Iteration number 17000 loss: 1.882431983947754\n",
      "Iteration number 17100 loss: 1.9773684740066528\n",
      "Episode Number: 9\n",
      "Iteration number 0 loss: 1.9635146856307983\n",
      "Iteration number 100 loss: 1.7482259273529053\n",
      "Iteration number 200 loss: 1.9653918743133545\n",
      "Iteration number 300 loss: 1.8439948558807373\n",
      "Iteration number 400 loss: 1.9436018466949463\n",
      "Iteration number 500 loss: 1.8870488405227661\n",
      "Iteration number 600 loss: 1.6637452840805054\n",
      "Iteration number 700 loss: 1.8466731309890747\n",
      "Iteration number 800 loss: 1.9918739795684814\n",
      "Iteration number 900 loss: 1.9719148874282837\n",
      "Iteration number 1000 loss: 1.8972468376159668\n",
      "Iteration number 1100 loss: 1.7992818355560303\n",
      "Iteration number 1200 loss: 1.8405839204788208\n",
      "Iteration number 1300 loss: 1.8929805755615234\n",
      "Iteration number 1400 loss: 1.7573556900024414\n",
      "Iteration number 1500 loss: 1.9116392135620117\n",
      "Iteration number 1600 loss: 1.8441400527954102\n",
      "Iteration number 1700 loss: 1.8770883083343506\n",
      "Iteration number 1800 loss: 1.6735646724700928\n",
      "Iteration number 1900 loss: 1.9326355457305908\n",
      "Iteration number 2000 loss: 1.8720057010650635\n",
      "Iteration number 2100 loss: 1.7422361373901367\n",
      "Iteration number 2200 loss: 1.9462440013885498\n",
      "Iteration number 2300 loss: 1.9552592039108276\n",
      "Iteration number 2400 loss: 1.7566968202590942\n",
      "Iteration number 2500 loss: 1.8627023696899414\n",
      "Iteration number 2600 loss: 1.6338858604431152\n",
      "Iteration number 2700 loss: 1.9520111083984375\n",
      "Iteration number 2800 loss: 1.6039371490478516\n",
      "Iteration number 2900 loss: 1.9168739318847656\n",
      "Iteration number 3000 loss: 1.8294106721878052\n",
      "Iteration number 3100 loss: 1.6407091617584229\n",
      "Iteration number 3200 loss: 1.8018338680267334\n",
      "Iteration number 3300 loss: 1.7980258464813232\n",
      "Iteration number 3400 loss: 1.8597047328948975\n",
      "Iteration number 3500 loss: 1.8990892171859741\n",
      "Iteration number 3600 loss: 1.8879144191741943\n",
      "Iteration number 3700 loss: 1.6840436458587646\n",
      "Iteration number 3800 loss: 1.7944811582565308\n",
      "Iteration number 3900 loss: 1.5709874629974365\n",
      "Iteration number 4000 loss: 1.7864668369293213\n",
      "Iteration number 4100 loss: 1.8190451860427856\n",
      "Iteration number 4200 loss: 1.9405624866485596\n",
      "Iteration number 4300 loss: 2.0345258712768555\n",
      "Iteration number 4400 loss: 1.9197338819503784\n",
      "Iteration number 4500 loss: 1.7220839262008667\n",
      "Iteration number 4600 loss: 1.954127311706543\n",
      "Iteration number 4700 loss: 1.8211034536361694\n",
      "Iteration number 4800 loss: 1.8831243515014648\n",
      "Iteration number 4900 loss: 1.7251696586608887\n",
      "Iteration number 5000 loss: 1.661011815071106\n",
      "Iteration number 5100 loss: 2.043065071105957\n",
      "Iteration number 5200 loss: 1.8531138896942139\n",
      "Iteration number 5300 loss: 1.7896931171417236\n",
      "Iteration number 5400 loss: 1.7889612913131714\n",
      "Iteration number 5500 loss: 2.003938674926758\n",
      "Iteration number 5600 loss: 2.001060962677002\n",
      "Iteration number 5700 loss: 1.9158153533935547\n",
      "Iteration number 5800 loss: 1.9535448551177979\n",
      "Iteration number 5900 loss: 1.8823415040969849\n",
      "Iteration number 6000 loss: 1.8857998847961426\n",
      "Iteration number 6100 loss: 2.01617169380188\n",
      "Iteration number 6200 loss: 1.7968568801879883\n",
      "Iteration number 6300 loss: 1.94027841091156\n",
      "Iteration number 6400 loss: 1.7188389301300049\n",
      "Iteration number 6500 loss: 1.964677333831787\n",
      "Iteration number 6600 loss: 1.9266762733459473\n",
      "Iteration number 6700 loss: 1.9980027675628662\n",
      "Iteration number 6800 loss: 1.9534804821014404\n",
      "Iteration number 6900 loss: 1.9531192779541016\n",
      "Iteration number 7000 loss: 2.0446107387542725\n",
      "Iteration number 7100 loss: 1.9615631103515625\n",
      "Iteration number 7200 loss: 2.0750226974487305\n",
      "Iteration number 7300 loss: 1.8308992385864258\n",
      "Iteration number 7400 loss: 2.018524169921875\n",
      "Iteration number 7500 loss: 1.6911141872406006\n",
      "Iteration number 7600 loss: 1.7545757293701172\n",
      "Iteration number 7700 loss: 1.9163360595703125\n",
      "Iteration number 7800 loss: 1.7350049018859863\n",
      "Iteration number 7900 loss: 1.8113778829574585\n",
      "Iteration number 8000 loss: 1.8338181972503662\n",
      "Iteration number 8100 loss: 1.8658961057662964\n",
      "Iteration number 8200 loss: 1.7549830675125122\n",
      "Iteration number 8300 loss: 1.7557392120361328\n",
      "Iteration number 8400 loss: 1.903146505355835\n",
      "Iteration number 8500 loss: 1.8382868766784668\n",
      "Iteration number 8600 loss: 1.902611494064331\n",
      "Iteration number 8700 loss: 1.8802778720855713\n",
      "Iteration number 8800 loss: 1.772303819656372\n",
      "Iteration number 8900 loss: 2.0299572944641113\n",
      "Iteration number 9000 loss: 1.856388807296753\n",
      "Iteration number 9100 loss: 1.8102946281433105\n",
      "Iteration number 9200 loss: 1.7155174016952515\n",
      "Iteration number 9300 loss: 1.9199857711791992\n",
      "Iteration number 9400 loss: 1.7399094104766846\n",
      "Iteration number 9500 loss: 1.706411361694336\n",
      "Iteration number 9600 loss: 1.962508201599121\n",
      "Iteration number 9700 loss: 1.9740104675292969\n",
      "Iteration number 9800 loss: 1.9119685888290405\n",
      "Iteration number 9900 loss: 1.9632304906845093\n",
      "Iteration number 10000 loss: 1.7386327981948853\n",
      "Iteration number 10100 loss: 1.934714674949646\n",
      "Iteration number 10200 loss: 1.880370855331421\n",
      "Iteration number 10300 loss: 2.010662794113159\n",
      "Iteration number 10400 loss: 1.7165393829345703\n",
      "Iteration number 10500 loss: 1.7189035415649414\n",
      "Iteration number 10600 loss: 1.7436869144439697\n",
      "Iteration number 10700 loss: 2.000516653060913\n",
      "Iteration number 10800 loss: 1.5995795726776123\n",
      "Iteration number 10900 loss: 1.907118797302246\n",
      "Iteration number 11000 loss: 1.761542797088623\n",
      "Iteration number 11100 loss: 1.8830329179763794\n",
      "Iteration number 11200 loss: 1.7804360389709473\n",
      "Iteration number 11300 loss: 1.6614056825637817\n",
      "Iteration number 11400 loss: 1.6852517127990723\n",
      "Iteration number 11500 loss: 1.845629334449768\n",
      "Iteration number 11600 loss: 1.8242857456207275\n",
      "Iteration number 11700 loss: 1.895625114440918\n",
      "Iteration number 11800 loss: 1.9942378997802734\n",
      "Iteration number 11900 loss: 1.8854148387908936\n",
      "Iteration number 12000 loss: 1.8163065910339355\n",
      "Iteration number 12100 loss: 1.73453950881958\n",
      "Iteration number 12200 loss: 1.6531081199645996\n",
      "Iteration number 12300 loss: 1.6510884761810303\n",
      "Iteration number 12400 loss: 1.826857328414917\n",
      "Iteration number 12500 loss: 1.8110136985778809\n",
      "Iteration number 12600 loss: 1.9447946548461914\n",
      "Iteration number 12700 loss: 1.6883368492126465\n",
      "Iteration number 12800 loss: 1.8984864950180054\n",
      "Iteration number 12900 loss: 1.8210194110870361\n",
      "Iteration number 13000 loss: 1.755181074142456\n",
      "Iteration number 13100 loss: 2.067647933959961\n",
      "Iteration number 13200 loss: 1.7529628276824951\n",
      "Iteration number 13300 loss: 1.7748019695281982\n",
      "Iteration number 13400 loss: 1.6098843812942505\n",
      "Iteration number 13500 loss: 1.8735039234161377\n",
      "Iteration number 13600 loss: 2.056558609008789\n",
      "Iteration number 13700 loss: 2.025315523147583\n",
      "Iteration number 13800 loss: 1.7309762239456177\n",
      "Iteration number 13900 loss: 1.9067919254302979\n",
      "Iteration number 14000 loss: 1.847857117652893\n",
      "Iteration number 14100 loss: 1.785449743270874\n",
      "Iteration number 14200 loss: 1.9352309703826904\n",
      "Iteration number 14300 loss: 1.939180850982666\n",
      "Iteration number 14400 loss: 1.7329879999160767\n",
      "Iteration number 14500 loss: 1.9700322151184082\n",
      "Iteration number 14600 loss: 1.8834601640701294\n",
      "Iteration number 14700 loss: 1.940352201461792\n",
      "Iteration number 14800 loss: 1.8893299102783203\n",
      "Iteration number 14900 loss: 1.8996868133544922\n",
      "Iteration number 15000 loss: 2.093656063079834\n",
      "Iteration number 15100 loss: 2.1108813285827637\n",
      "Iteration number 15200 loss: 1.7911183834075928\n",
      "Iteration number 15300 loss: 1.8405911922454834\n",
      "Iteration number 15400 loss: 1.9191169738769531\n",
      "Iteration number 15500 loss: 1.8528501987457275\n",
      "Iteration number 15600 loss: 1.4944860935211182\n",
      "Iteration number 15700 loss: 1.7332267761230469\n",
      "Iteration number 15800 loss: 1.9077637195587158\n",
      "Iteration number 15900 loss: 1.969895362854004\n",
      "Iteration number 16000 loss: 1.8992810249328613\n",
      "Iteration number 16100 loss: 1.8959581851959229\n",
      "Iteration number 16200 loss: 1.848402738571167\n",
      "Iteration number 16300 loss: 1.825626254081726\n",
      "Iteration number 16400 loss: 1.9844229221343994\n",
      "Iteration number 16500 loss: 1.8691575527191162\n",
      "Iteration number 16600 loss: 1.9780635833740234\n",
      "Iteration number 16700 loss: 1.8847136497497559\n",
      "Iteration number 16800 loss: 1.6462867259979248\n",
      "Iteration number 16900 loss: 1.7051596641540527\n",
      "Iteration number 17000 loss: 1.6983128786087036\n",
      "Iteration number 17100 loss: 1.7911975383758545\n",
      "Iteration number 17200 loss: 1.9384534358978271\n",
      "Iteration number 17300 loss: 1.765343189239502\n",
      "Iteration number 17400 loss: 1.910954475402832\n",
      "Iteration number 17500 loss: 1.5446460247039795\n",
      "Iteration number 17600 loss: 1.8429062366485596\n",
      "Iteration number 17700 loss: 1.6906538009643555\n",
      "Iteration number 17800 loss: 1.8870139122009277\n",
      "Iteration number 17900 loss: 1.9228407144546509\n",
      "Iteration number 18000 loss: 1.6744720935821533\n",
      "Iteration number 18100 loss: 1.8273537158966064\n",
      "Iteration number 18200 loss: 1.7082717418670654\n",
      "Iteration number 18300 loss: 1.851354956626892\n",
      "Iteration number 18400 loss: 2.0871057510375977\n",
      "Iteration number 18500 loss: 1.877882957458496\n",
      "Iteration number 18600 loss: 1.8989546298980713\n",
      "Iteration number 18700 loss: 1.68011474609375\n",
      "Iteration number 18800 loss: 1.6832205057144165\n",
      "Iteration number 18900 loss: 2.028768539428711\n",
      "Iteration number 19000 loss: 1.866260290145874\n",
      "Iteration number 19100 loss: 1.611370325088501\n",
      "Iteration number 19200 loss: 1.7383196353912354\n",
      "Iteration number 19300 loss: 1.8603171110153198\n",
      "Iteration number 19400 loss: 1.950799822807312\n",
      "Iteration number 19500 loss: 1.7682570219039917\n",
      "Iteration number 19600 loss: 1.8079984188079834\n",
      "Iteration number 19700 loss: 1.6537268161773682\n",
      "Iteration number 19800 loss: 1.6960017681121826\n",
      "Iteration number 19900 loss: 1.915083408355713\n",
      "Iteration number 20000 loss: 2.056030750274658\n",
      "Episode Number: 10\n",
      "Iteration number 0 loss: 1.9652509689331055\n",
      "Iteration number 100 loss: 1.898608922958374\n",
      "Iteration number 200 loss: 1.8339052200317383\n",
      "Iteration number 300 loss: 1.7803224325180054\n",
      "Iteration number 400 loss: 1.7727186679840088\n",
      "Iteration number 500 loss: 1.7641408443450928\n",
      "Iteration number 600 loss: 1.8246123790740967\n",
      "Iteration number 700 loss: 1.7074193954467773\n",
      "Iteration number 800 loss: 1.7264177799224854\n",
      "Iteration number 900 loss: 1.8208649158477783\n",
      "Iteration number 1000 loss: 1.6880543231964111\n",
      "Iteration number 1100 loss: 1.7149953842163086\n",
      "Iteration number 1200 loss: 1.5939913988113403\n",
      "Iteration number 1300 loss: 1.508162260055542\n",
      "Iteration number 1400 loss: 1.851301908493042\n",
      "Iteration number 1500 loss: 1.8549442291259766\n",
      "Iteration number 1600 loss: 1.8233319520950317\n",
      "Iteration number 1700 loss: 1.756364107131958\n",
      "Iteration number 1800 loss: 1.8884742259979248\n",
      "Iteration number 1900 loss: 1.9806100130081177\n",
      "Iteration number 2000 loss: 1.7132494449615479\n",
      "Iteration number 2100 loss: 1.9827722311019897\n",
      "Iteration number 2200 loss: 1.811447024345398\n",
      "Iteration number 2300 loss: 1.7035646438598633\n",
      "Iteration number 2400 loss: 1.6704596281051636\n",
      "Iteration number 2500 loss: 1.7246105670928955\n",
      "Iteration number 2600 loss: 2.0774142742156982\n",
      "Iteration number 2700 loss: 1.8272428512573242\n",
      "Iteration number 2800 loss: 1.586363434791565\n",
      "Iteration number 2900 loss: 1.6907613277435303\n",
      "Iteration number 3000 loss: 1.8528556823730469\n",
      "Iteration number 3100 loss: 1.7030344009399414\n",
      "Iteration number 3200 loss: 1.7977941036224365\n",
      "Iteration number 3300 loss: 1.7551978826522827\n",
      "Iteration number 3400 loss: 1.5949082374572754\n",
      "Iteration number 3500 loss: 1.7686749696731567\n",
      "Iteration number 3600 loss: 1.5296955108642578\n",
      "Iteration number 3700 loss: 1.5238434076309204\n",
      "Iteration number 3800 loss: 1.7199723720550537\n",
      "Iteration number 3900 loss: 1.524643898010254\n",
      "Iteration number 4000 loss: 1.6789175271987915\n",
      "Iteration number 4100 loss: 1.5084314346313477\n",
      "Iteration number 4200 loss: 1.550667643547058\n",
      "Iteration number 4300 loss: 1.703212857246399\n",
      "Iteration number 4400 loss: 1.4554083347320557\n",
      "Iteration number 4500 loss: 1.4864346981048584\n",
      "Iteration number 4600 loss: 1.5051345825195312\n",
      "Iteration number 4700 loss: 1.5792872905731201\n",
      "Iteration number 4800 loss: 1.6762111186981201\n",
      "Iteration number 4900 loss: 1.687610149383545\n",
      "Iteration number 5000 loss: 1.6309354305267334\n",
      "Iteration number 5100 loss: 1.6273137331008911\n",
      "Iteration number 5200 loss: 1.5184266567230225\n",
      "Iteration number 5300 loss: 1.504634141921997\n",
      "Iteration number 5400 loss: 1.8264875411987305\n",
      "Iteration number 5500 loss: 1.5402417182922363\n",
      "Iteration number 5600 loss: 1.7646028995513916\n",
      "Iteration number 5700 loss: 1.9490556716918945\n",
      "Iteration number 5800 loss: 1.8826584815979004\n",
      "Iteration number 5900 loss: 1.7142326831817627\n",
      "Iteration number 6000 loss: 1.81479811668396\n",
      "Iteration number 6100 loss: 1.6477423906326294\n",
      "Iteration number 6200 loss: 1.913289189338684\n",
      "Iteration number 6300 loss: 1.9359145164489746\n",
      "Iteration number 6400 loss: 2.028463840484619\n",
      "Iteration number 6500 loss: 2.1222641468048096\n",
      "Iteration number 6600 loss: 2.262115478515625\n",
      "Iteration number 6700 loss: 2.083374500274658\n",
      "Iteration number 6800 loss: 1.9620611667633057\n",
      "Iteration number 6900 loss: 1.7092325687408447\n",
      "Iteration number 7000 loss: 1.9886255264282227\n",
      "Iteration number 7100 loss: 2.2522010803222656\n",
      "Iteration number 7200 loss: 2.0771846771240234\n",
      "Iteration number 7300 loss: 1.7954041957855225\n",
      "Iteration number 7400 loss: 1.7357314825057983\n",
      "Iteration number 7500 loss: 1.7329456806182861\n",
      "Iteration number 7600 loss: 1.9043101072311401\n",
      "Iteration number 7700 loss: 1.6033589839935303\n",
      "Iteration number 7800 loss: 1.3165020942687988\n",
      "Iteration number 7900 loss: 1.9974422454833984\n",
      "Iteration number 8000 loss: 1.6490201950073242\n",
      "Iteration number 8100 loss: 2.1497294902801514\n",
      "Iteration number 8200 loss: 1.74452543258667\n",
      "Iteration number 8300 loss: 1.8120826482772827\n",
      "Iteration number 8400 loss: 2.069922924041748\n",
      "Iteration number 8500 loss: 1.9958932399749756\n",
      "Iteration number 8600 loss: 2.0290493965148926\n",
      "Iteration number 8700 loss: 2.117891311645508\n",
      "Iteration number 8800 loss: 1.8117010593414307\n",
      "Iteration number 8900 loss: 1.8047773838043213\n",
      "Iteration number 9000 loss: 1.657692790031433\n",
      "Iteration number 9100 loss: 1.849859356880188\n",
      "Iteration number 9200 loss: 1.8985326290130615\n",
      "Iteration number 9300 loss: 1.9543839693069458\n",
      "Iteration number 9400 loss: 1.959484338760376\n",
      "Iteration number 9500 loss: 1.5296051502227783\n",
      "Iteration number 9600 loss: 2.059311866760254\n",
      "Iteration number 9700 loss: 1.8097827434539795\n",
      "Iteration number 9800 loss: 2.3565163612365723\n",
      "Iteration number 9900 loss: 1.7541160583496094\n",
      "Iteration number 10000 loss: 1.991997480392456\n",
      "Iteration number 10100 loss: 1.7617030143737793\n",
      "Iteration number 10200 loss: 1.9002690315246582\n",
      "Iteration number 10300 loss: 1.5736489295959473\n",
      "Iteration number 10400 loss: 2.1944758892059326\n",
      "Iteration number 10500 loss: 1.4015545845031738\n",
      "Iteration number 10600 loss: 1.6824285984039307\n",
      "Iteration number 10700 loss: 1.561628818511963\n",
      "Iteration number 10800 loss: 1.463216781616211\n",
      "Iteration number 10900 loss: 1.7509101629257202\n",
      "Iteration number 11000 loss: 1.8563389778137207\n",
      "Iteration number 11100 loss: 2.2873730659484863\n",
      "Iteration number 11200 loss: 2.078613519668579\n",
      "Iteration number 11300 loss: 1.3941874504089355\n",
      "Iteration number 11400 loss: 1.9603785276412964\n",
      "Iteration number 11500 loss: 1.7871055603027344\n",
      "Iteration number 11600 loss: 1.6572082042694092\n",
      "Iteration number 11700 loss: 1.9538494348526\n",
      "Iteration number 11800 loss: 2.3023910522460938\n",
      "Iteration number 11900 loss: 1.5257803201675415\n",
      "Iteration number 12000 loss: 2.0424773693084717\n",
      "Iteration number 12100 loss: 1.599351167678833\n",
      "Iteration number 12200 loss: 1.8429584503173828\n",
      "Iteration number 12300 loss: 1.828208088874817\n",
      "Iteration number 12400 loss: 1.9732950925827026\n",
      "Iteration number 12500 loss: 2.070690155029297\n",
      "Iteration number 12600 loss: 2.287036180496216\n",
      "Iteration number 12700 loss: 1.95579195022583\n",
      "Iteration number 12800 loss: 1.709479570388794\n",
      "Iteration number 12900 loss: 1.5053110122680664\n",
      "Iteration number 13000 loss: 1.730739951133728\n",
      "Iteration number 13100 loss: 1.3040053844451904\n",
      "Iteration number 13200 loss: 1.5506138801574707\n",
      "Iteration number 13300 loss: 1.759016752243042\n",
      "Iteration number 13400 loss: 2.0458827018737793\n",
      "Iteration number 13500 loss: 1.8776501417160034\n",
      "Iteration number 13600 loss: 1.8604412078857422\n",
      "Iteration number 13700 loss: 1.8683768510818481\n",
      "Iteration number 13800 loss: 1.871080994606018\n",
      "Iteration number 13900 loss: 1.3620216846466064\n",
      "Iteration number 14000 loss: 1.8559813499450684\n",
      "Iteration number 14100 loss: 1.8194220066070557\n",
      "Iteration number 14200 loss: 1.5696378946304321\n",
      "Iteration number 14300 loss: 1.7458908557891846\n",
      "Iteration number 14400 loss: 1.402440071105957\n",
      "Iteration number 14500 loss: 1.7627921104431152\n",
      "Iteration number 14600 loss: 1.717198371887207\n",
      "Iteration number 14700 loss: 1.9811793565750122\n",
      "Iteration number 14800 loss: 2.0096683502197266\n",
      "Iteration number 14900 loss: 1.7986018657684326\n",
      "Iteration number 15000 loss: 2.063976526260376\n",
      "Iteration number 15100 loss: 1.8835011720657349\n",
      "Iteration number 15200 loss: 1.7863601446151733\n",
      "Iteration number 15300 loss: 1.9967116117477417\n",
      "Iteration number 15400 loss: 1.9930967092514038\n",
      "Iteration number 15500 loss: 1.875203251838684\n",
      "Iteration number 15600 loss: 2.011329174041748\n",
      "Iteration number 15700 loss: 1.9985345602035522\n",
      "Iteration number 15800 loss: 2.0097761154174805\n",
      "Iteration number 15900 loss: 1.7452611923217773\n",
      "Iteration number 16000 loss: 1.7904597520828247\n",
      "Iteration number 16100 loss: 1.9395320415496826\n",
      "Iteration number 16200 loss: 1.936315894126892\n",
      "Iteration number 16300 loss: 2.1818881034851074\n",
      "Iteration number 16400 loss: 1.8933459520339966\n",
      "Iteration number 16500 loss: 1.8412331342697144\n",
      "Iteration number 16600 loss: 1.7477550506591797\n",
      "Iteration number 16700 loss: 1.8750121593475342\n",
      "Iteration number 16800 loss: 1.9345797300338745\n",
      "Iteration number 16900 loss: 1.97408127784729\n",
      "Iteration number 17000 loss: 1.879288673400879\n",
      "Iteration number 17100 loss: 1.737804889678955\n",
      "Iteration number 17200 loss: 1.9190316200256348\n",
      "Iteration number 17300 loss: 1.916749358177185\n",
      "Iteration number 17400 loss: 1.9711885452270508\n",
      "Iteration number 17500 loss: 2.0248842239379883\n",
      "Iteration number 17600 loss: 1.791696310043335\n",
      "Iteration number 17700 loss: 1.8637255430221558\n",
      "Iteration number 17800 loss: 1.914739966392517\n",
      "Iteration number 17900 loss: 1.807756781578064\n",
      "Iteration number 18000 loss: 1.838667869567871\n",
      "Iteration number 18100 loss: 1.964570164680481\n",
      "Iteration number 18200 loss: 2.0300211906433105\n",
      "Iteration number 18300 loss: 1.8455660343170166\n",
      "Iteration number 18400 loss: 1.8435826301574707\n",
      "Iteration number 18500 loss: 2.002135753631592\n",
      "Iteration number 18600 loss: 1.7668319940567017\n",
      "Iteration number 18700 loss: 2.0990395545959473\n",
      "Iteration number 18800 loss: 1.7766869068145752\n",
      "Iteration number 18900 loss: 1.6590887308120728\n",
      "Iteration number 19000 loss: 1.9452768564224243\n",
      "Iteration number 19100 loss: 1.846769094467163\n",
      "Iteration number 19200 loss: 1.990135669708252\n",
      "Iteration number 19300 loss: 2.031447410583496\n",
      "Iteration number 19400 loss: 1.732527256011963\n",
      "Iteration number 19500 loss: 1.7790659666061401\n",
      "Iteration number 19600 loss: 1.9918406009674072\n",
      "Iteration number 19700 loss: 1.9504141807556152\n",
      "Iteration number 19800 loss: 1.777047038078308\n",
      "Iteration number 19900 loss: 1.7759146690368652\n",
      "Iteration number 20000 loss: 1.8456517457962036\n",
      "Iteration number 20100 loss: 1.7969837188720703\n",
      "Iteration number 20200 loss: 2.144876003265381\n",
      "Iteration number 20300 loss: 2.181342363357544\n",
      "Iteration number 20400 loss: 2.1819589138031006\n",
      "Iteration number 20500 loss: 1.9784448146820068\n",
      "Iteration number 20600 loss: 2.146070957183838\n",
      "Iteration number 20700 loss: 1.9166467189788818\n",
      "Iteration number 20800 loss: 2.1402859687805176\n",
      "Iteration number 20900 loss: 2.189932107925415\n",
      "Iteration number 21000 loss: 1.7577152252197266\n",
      "Iteration number 21100 loss: 1.8884928226470947\n",
      "Iteration number 21200 loss: 1.9359582662582397\n",
      "Iteration number 21300 loss: 1.8212534189224243\n",
      "Iteration number 21400 loss: 1.8390040397644043\n",
      "Iteration number 21500 loss: 1.557457685470581\n",
      "Iteration number 21600 loss: 2.0402817726135254\n",
      "Iteration number 21700 loss: 1.846447467803955\n",
      "Iteration number 21800 loss: 1.834280014038086\n",
      "Iteration number 21900 loss: 1.986051321029663\n",
      "Iteration number 22000 loss: 1.8954756259918213\n",
      "Iteration number 22100 loss: 1.268240213394165\n",
      "Iteration number 22200 loss: 1.7586345672607422\n",
      "Iteration number 22300 loss: 1.9083402156829834\n",
      "Iteration number 22400 loss: 1.8155176639556885\n",
      "Iteration number 22500 loss: 1.838659644126892\n",
      "Iteration number 22600 loss: 1.8737273216247559\n",
      "Iteration number 22700 loss: 1.9927005767822266\n",
      "Iteration number 22800 loss: 1.9725158214569092\n",
      "Iteration number 22900 loss: 1.6344399452209473\n",
      "Iteration number 23000 loss: 1.6603281497955322\n",
      "Iteration number 23100 loss: 1.823300838470459\n",
      "Iteration number 23200 loss: 1.3061678409576416\n",
      "Iteration number 23300 loss: 1.5667669773101807\n",
      "Iteration number 23400 loss: 1.8054691553115845\n",
      "Iteration number 23500 loss: 2.002246141433716\n",
      "Iteration number 23600 loss: 1.9072946310043335\n",
      "Iteration number 23700 loss: 1.9374432563781738\n",
      "Iteration number 23800 loss: 1.936464548110962\n",
      "Iteration number 23900 loss: 1.7539480924606323\n",
      "Iteration number 24000 loss: 1.8399574756622314\n",
      "Iteration number 24100 loss: 1.8675765991210938\n",
      "Iteration number 24200 loss: 2.003589153289795\n",
      "Iteration number 24300 loss: 1.819168210029602\n",
      "Iteration number 24400 loss: 1.666841745376587\n",
      "Iteration number 24500 loss: 1.6964495182037354\n",
      "Iteration number 24600 loss: 1.8199115991592407\n",
      "Iteration number 24700 loss: 1.9872899055480957\n",
      "Iteration number 24800 loss: 2.0594680309295654\n",
      "Iteration number 24900 loss: 1.9078367948532104\n",
      "Iteration number 25000 loss: 1.8573957681655884\n",
      "Iteration number 25100 loss: 1.7921278476715088\n",
      "Iteration number 25200 loss: 2.0151705741882324\n",
      "Iteration number 25300 loss: 1.6335304975509644\n",
      "Iteration number 25400 loss: 1.8992445468902588\n",
      "Iteration number 25500 loss: 1.7125121355056763\n",
      "Iteration number 25600 loss: 1.8993043899536133\n",
      "Iteration number 25700 loss: 1.586978793144226\n",
      "Iteration number 25800 loss: 1.6460862159729004\n",
      "Iteration number 25900 loss: 1.8974953889846802\n",
      "Iteration number 26000 loss: 1.9803098440170288\n",
      "Iteration number 26100 loss: 1.9688079357147217\n",
      "Iteration number 26200 loss: 1.920586347579956\n",
      "Iteration number 26300 loss: 2.0262815952301025\n",
      "Iteration number 26400 loss: 1.7178959846496582\n",
      "Iteration number 26500 loss: 1.8354064226150513\n",
      "Iteration number 26600 loss: 1.9042803049087524\n",
      "Iteration number 26700 loss: 1.8457481861114502\n",
      "Iteration number 26800 loss: 1.7596044540405273\n",
      "Iteration number 26900 loss: 1.742579460144043\n",
      "Iteration number 27000 loss: 1.9252033233642578\n",
      "Iteration number 27100 loss: 1.616858959197998\n",
      "Iteration number 27200 loss: 1.8508105278015137\n",
      "Iteration number 27300 loss: 1.7994015216827393\n",
      "Iteration number 27400 loss: 1.9352974891662598\n",
      "Iteration number 27500 loss: 1.958998441696167\n",
      "Iteration number 27600 loss: 1.7730704545974731\n",
      "Iteration number 27700 loss: 1.7495489120483398\n",
      "Iteration number 27800 loss: 1.9561405181884766\n",
      "Iteration number 27900 loss: 1.963383436203003\n",
      "Iteration number 28000 loss: 1.577327013015747\n",
      "Iteration number 28100 loss: 1.9256842136383057\n",
      "Iteration number 28200 loss: 1.7881178855895996\n",
      "Iteration number 28300 loss: 1.9838807582855225\n",
      "Iteration number 28400 loss: 1.8700978755950928\n",
      "Iteration number 28500 loss: 2.117161750793457\n",
      "Iteration number 28600 loss: 1.8436243534088135\n",
      "Iteration number 28700 loss: 1.713550090789795\n",
      "Iteration number 28800 loss: 2.1148104667663574\n",
      "Iteration number 28900 loss: 1.9399454593658447\n",
      "Iteration number 29000 loss: 1.9686964750289917\n",
      "Iteration number 29100 loss: 2.033484935760498\n",
      "Iteration number 29200 loss: 1.781829595565796\n",
      "Episode Number: 11\n",
      "Iteration number 0 loss: 1.5604162216186523\n",
      "Iteration number 100 loss: 2.160548210144043\n",
      "Iteration number 200 loss: 2.1957266330718994\n",
      "Iteration number 300 loss: 2.415013074874878\n",
      "Iteration number 400 loss: 2.6027064323425293\n",
      "Iteration number 500 loss: 2.2696428298950195\n",
      "Iteration number 600 loss: 2.4906954765319824\n",
      "Iteration number 700 loss: 2.2195491790771484\n",
      "Iteration number 800 loss: 2.303210973739624\n",
      "Iteration number 900 loss: 2.2839651107788086\n",
      "Iteration number 1000 loss: 2.3066020011901855\n",
      "Iteration number 1100 loss: 2.2224972248077393\n",
      "Iteration number 1200 loss: 2.3711318969726562\n",
      "Iteration number 1300 loss: 2.3161020278930664\n",
      "Iteration number 1400 loss: 1.9904292821884155\n",
      "Iteration number 1500 loss: 2.0273613929748535\n",
      "Iteration number 1600 loss: 1.9188132286071777\n",
      "Iteration number 1700 loss: 2.4186959266662598\n",
      "Iteration number 1800 loss: 2.512690544128418\n",
      "Iteration number 1900 loss: 2.428438425064087\n",
      "Iteration number 2000 loss: 2.04209566116333\n",
      "Iteration number 2100 loss: 2.18272066116333\n",
      "Iteration number 2200 loss: 2.6670541763305664\n",
      "Iteration number 2300 loss: 2.358288288116455\n",
      "Iteration number 2400 loss: 2.132500171661377\n",
      "Iteration number 2500 loss: 2.112262725830078\n",
      "Iteration number 2600 loss: 2.213313102722168\n",
      "Iteration number 2700 loss: 2.1157660484313965\n",
      "Iteration number 2800 loss: 2.10123348236084\n",
      "Iteration number 2900 loss: 2.038485527038574\n",
      "Iteration number 3000 loss: 2.3879189491271973\n",
      "Iteration number 3100 loss: 2.261746883392334\n",
      "Iteration number 3200 loss: 2.5316414833068848\n",
      "Iteration number 3300 loss: 2.2510879039764404\n",
      "Iteration number 3400 loss: 2.0066585540771484\n",
      "Iteration number 3500 loss: 2.740873098373413\n",
      "Iteration number 3600 loss: 2.146549940109253\n",
      "Episode Number: 12\n",
      "Iteration number 0 loss: 1.949201226234436\n",
      "Iteration number 100 loss: 1.990199327468872\n",
      "Iteration number 200 loss: 1.9768229722976685\n",
      "Iteration number 300 loss: 1.52849543094635\n",
      "Iteration number 400 loss: 1.8122225999832153\n",
      "Iteration number 500 loss: 1.703740119934082\n",
      "Iteration number 600 loss: 1.8397715091705322\n",
      "Iteration number 700 loss: 1.575583815574646\n",
      "Iteration number 800 loss: 2.020688056945801\n",
      "Iteration number 900 loss: 1.676593542098999\n",
      "Iteration number 1000 loss: 1.6975703239440918\n",
      "Iteration number 1100 loss: 2.014566421508789\n",
      "Iteration number 1200 loss: 1.7687256336212158\n",
      "Iteration number 1300 loss: 1.2096612453460693\n",
      "Iteration number 1400 loss: 1.5957309007644653\n",
      "Iteration number 1500 loss: 1.8802324533462524\n",
      "Iteration number 1600 loss: 2.3999738693237305\n",
      "Iteration number 1700 loss: 1.780360221862793\n",
      "Iteration number 1800 loss: 1.775024652481079\n",
      "Iteration number 1900 loss: 1.9019665718078613\n",
      "Iteration number 2000 loss: 1.9148764610290527\n",
      "Iteration number 2100 loss: 1.7747496366500854\n",
      "Iteration number 2200 loss: 1.4687775373458862\n",
      "Iteration number 2300 loss: 1.798025131225586\n",
      "Iteration number 2400 loss: 2.078807830810547\n",
      "Iteration number 2500 loss: 1.667574405670166\n",
      "Iteration number 2600 loss: 1.8783059120178223\n",
      "Iteration number 2700 loss: 1.9639432430267334\n",
      "Iteration number 2800 loss: 2.217212677001953\n",
      "Iteration number 2900 loss: 1.758076548576355\n",
      "Iteration number 3000 loss: 1.940219759941101\n",
      "Iteration number 3100 loss: 1.5283249616622925\n",
      "Iteration number 3200 loss: 2.026860475540161\n",
      "Iteration number 3300 loss: 1.7683830261230469\n",
      "Iteration number 3400 loss: 1.7226877212524414\n",
      "Iteration number 3500 loss: 1.9691358804702759\n",
      "Iteration number 3600 loss: 1.8685029745101929\n",
      "Iteration number 3700 loss: 1.7677414417266846\n",
      "Iteration number 3800 loss: 1.9012500047683716\n",
      "Iteration number 3900 loss: 1.9425580501556396\n",
      "Iteration number 4000 loss: 1.9475417137145996\n",
      "Iteration number 4100 loss: 1.708669662475586\n",
      "Iteration number 4200 loss: 1.4215874671936035\n",
      "Iteration number 4300 loss: 1.683513879776001\n",
      "Iteration number 4400 loss: 1.9043362140655518\n",
      "Iteration number 4500 loss: 1.6757497787475586\n",
      "Iteration number 4600 loss: 1.6759312152862549\n",
      "Iteration number 4700 loss: 2.257007122039795\n",
      "Iteration number 4800 loss: 1.6016685962677002\n",
      "Iteration number 4900 loss: 1.6022558212280273\n",
      "Iteration number 5000 loss: 1.615511417388916\n",
      "Iteration number 5100 loss: 1.498828411102295\n",
      "Iteration number 5200 loss: 2.2773327827453613\n",
      "Iteration number 5300 loss: 1.607662320137024\n",
      "Iteration number 5400 loss: 1.4909191131591797\n",
      "Iteration number 5500 loss: 1.8706858158111572\n",
      "Iteration number 5600 loss: 1.8274495601654053\n",
      "Iteration number 5700 loss: 1.825500249862671\n",
      "Iteration number 5800 loss: 1.8516777753829956\n",
      "Iteration number 5900 loss: 1.904334306716919\n",
      "Iteration number 6000 loss: 2.0546116828918457\n",
      "Iteration number 6100 loss: 1.7643460035324097\n",
      "Iteration number 6200 loss: 1.558302640914917\n",
      "Iteration number 6300 loss: 1.8668447732925415\n",
      "Iteration number 6400 loss: 1.8170503377914429\n",
      "Iteration number 6500 loss: 1.7101976871490479\n",
      "Iteration number 6600 loss: 1.897264838218689\n",
      "Iteration number 6700 loss: 2.0176169872283936\n",
      "Iteration number 6800 loss: 1.6343021392822266\n",
      "Iteration number 6900 loss: 1.7813340425491333\n",
      "Iteration number 7000 loss: 1.804062843322754\n",
      "Iteration number 7100 loss: 1.8733546733856201\n",
      "Iteration number 7200 loss: 1.693435549736023\n",
      "Iteration number 7300 loss: 1.702210545539856\n",
      "Iteration number 7400 loss: 1.6305294036865234\n",
      "Iteration number 7500 loss: 1.8770217895507812\n",
      "Iteration number 7600 loss: 1.856283187866211\n",
      "Iteration number 7700 loss: 1.747847080230713\n",
      "Iteration number 7800 loss: 1.651172399520874\n",
      "Iteration number 7900 loss: 1.6098790168762207\n",
      "Iteration number 8000 loss: 1.643821120262146\n",
      "Iteration number 8100 loss: 1.826326608657837\n",
      "Iteration number 8200 loss: 1.5203160047531128\n",
      "Iteration number 8300 loss: 1.6794898509979248\n",
      "Iteration number 8400 loss: 1.4960684776306152\n",
      "Iteration number 8500 loss: 1.7826640605926514\n",
      "Iteration number 8600 loss: 1.6163105964660645\n",
      "Iteration number 8700 loss: 1.535839557647705\n",
      "Iteration number 8800 loss: 1.564645767211914\n",
      "Iteration number 8900 loss: 2.0433239936828613\n",
      "Iteration number 9000 loss: 1.6919059753417969\n",
      "Iteration number 9100 loss: 1.5351879596710205\n",
      "Iteration number 9200 loss: 1.5937790870666504\n",
      "Iteration number 9300 loss: 1.5899256467819214\n",
      "Iteration number 9400 loss: 1.883881688117981\n",
      "Episode Number: 13\n",
      "Iteration number 0 loss: 1.649125337600708\n",
      "Iteration number 100 loss: 1.7217543125152588\n",
      "Iteration number 200 loss: 1.726351261138916\n",
      "Iteration number 300 loss: 1.689322590827942\n",
      "Iteration number 400 loss: 1.5895915031433105\n",
      "Iteration number 500 loss: 1.5518879890441895\n",
      "Iteration number 600 loss: 1.7582876682281494\n",
      "Iteration number 700 loss: 1.7613857984542847\n",
      "Iteration number 800 loss: 1.7466000318527222\n",
      "Iteration number 900 loss: 1.909227967262268\n",
      "Iteration number 1000 loss: 1.7483642101287842\n",
      "Iteration number 1100 loss: 1.6595549583435059\n",
      "Iteration number 1200 loss: 1.6360857486724854\n",
      "Iteration number 1300 loss: 1.5727732181549072\n",
      "Iteration number 1400 loss: 1.6768982410430908\n",
      "Iteration number 1500 loss: 1.7346246242523193\n",
      "Iteration number 1600 loss: 1.6584514379501343\n",
      "Iteration number 1700 loss: 1.925825834274292\n",
      "Iteration number 1800 loss: 1.6742756366729736\n",
      "Iteration number 1900 loss: 1.9323453903198242\n",
      "Iteration number 2000 loss: 1.6705787181854248\n",
      "Iteration number 2100 loss: 1.7699233293533325\n",
      "Iteration number 2200 loss: 1.7959694862365723\n",
      "Iteration number 2300 loss: 1.9149047136306763\n",
      "Iteration number 2400 loss: 1.5838782787322998\n",
      "Iteration number 2500 loss: 1.8406914472579956\n",
      "Iteration number 2600 loss: 1.6207438707351685\n",
      "Iteration number 2700 loss: 2.0553622245788574\n",
      "Iteration number 2800 loss: 1.8272029161453247\n",
      "Iteration number 2900 loss: 1.9410789012908936\n",
      "Iteration number 3000 loss: 1.5531049966812134\n",
      "Iteration number 3100 loss: 1.7152198553085327\n",
      "Iteration number 3200 loss: 1.6984684467315674\n",
      "Iteration number 3300 loss: 1.9220157861709595\n",
      "Iteration number 3400 loss: 1.815488576889038\n",
      "Iteration number 3500 loss: 1.755319595336914\n",
      "Iteration number 3600 loss: 1.963703989982605\n",
      "Iteration number 3700 loss: 1.842588186264038\n",
      "Iteration number 3800 loss: 1.7264636754989624\n",
      "Iteration number 3900 loss: 1.7757399082183838\n",
      "Iteration number 4000 loss: 1.6364176273345947\n",
      "Iteration number 4100 loss: 1.649293303489685\n",
      "Iteration number 4200 loss: 1.9879354238510132\n",
      "Iteration number 4300 loss: 1.5032551288604736\n",
      "Iteration number 4400 loss: 1.6104106903076172\n",
      "Iteration number 4500 loss: 1.7942121028900146\n",
      "Iteration number 4600 loss: 1.6078126430511475\n",
      "Iteration number 4700 loss: 1.6817710399627686\n",
      "Iteration number 4800 loss: 1.5330591201782227\n",
      "Iteration number 4900 loss: 1.6250269412994385\n",
      "Iteration number 5000 loss: 1.8261322975158691\n",
      "Iteration number 5100 loss: 1.8362611532211304\n",
      "Iteration number 5200 loss: 1.5358630418777466\n",
      "Iteration number 5300 loss: 1.9322776794433594\n",
      "Iteration number 5400 loss: 1.6748874187469482\n",
      "Iteration number 5500 loss: 1.9119296073913574\n",
      "Iteration number 5600 loss: 1.8521925210952759\n",
      "Iteration number 5700 loss: 1.6762475967407227\n",
      "Iteration number 5800 loss: 1.739862084388733\n",
      "Iteration number 5900 loss: 1.641295313835144\n",
      "Iteration number 6000 loss: 1.5799508094787598\n",
      "Iteration number 6100 loss: 1.875624656677246\n",
      "Iteration number 6200 loss: 1.7678741216659546\n",
      "Iteration number 6300 loss: 1.9633275270462036\n",
      "Iteration number 6400 loss: 1.8632773160934448\n",
      "Iteration number 6500 loss: 1.6886298656463623\n",
      "Iteration number 6600 loss: 1.722636342048645\n",
      "Iteration number 6700 loss: 1.675142765045166\n",
      "Iteration number 6800 loss: 1.7514946460723877\n",
      "Iteration number 6900 loss: 1.567021131515503\n",
      "Iteration number 7000 loss: 1.7205498218536377\n",
      "Iteration number 7100 loss: 1.660103678703308\n",
      "Iteration number 7200 loss: 1.714613437652588\n",
      "Iteration number 7300 loss: 1.7433850765228271\n",
      "Iteration number 7400 loss: 1.7430078983306885\n",
      "Iteration number 7500 loss: 1.9182082414627075\n",
      "Iteration number 7600 loss: 1.9222360849380493\n",
      "Iteration number 7700 loss: 1.6749098300933838\n",
      "Iteration number 7800 loss: 1.4776300191879272\n",
      "Iteration number 7900 loss: 1.748846411705017\n",
      "Iteration number 8000 loss: 1.6286499500274658\n",
      "Iteration number 8100 loss: 1.7452386617660522\n",
      "Iteration number 8200 loss: 1.500990390777588\n",
      "Iteration number 8300 loss: 1.797784686088562\n",
      "Iteration number 8400 loss: 1.8795087337493896\n",
      "Iteration number 8500 loss: 1.7854299545288086\n",
      "Iteration number 8600 loss: 1.70216703414917\n",
      "Iteration number 8700 loss: 1.5304269790649414\n",
      "Iteration number 8800 loss: 1.3065496683120728\n",
      "Iteration number 8900 loss: 1.5814002752304077\n",
      "Iteration number 9000 loss: 1.8604648113250732\n",
      "Iteration number 9100 loss: 1.6656808853149414\n",
      "Episode Number: 14\n",
      "Iteration number 0 loss: 1.9363532066345215\n",
      "Iteration number 100 loss: 1.6614477634429932\n",
      "Iteration number 200 loss: 1.5179078578948975\n",
      "Iteration number 300 loss: 1.5075321197509766\n",
      "Iteration number 400 loss: 1.5928866863250732\n",
      "Iteration number 500 loss: 1.7795772552490234\n",
      "Iteration number 600 loss: 1.669621229171753\n",
      "Iteration number 700 loss: 1.6218029260635376\n",
      "Iteration number 800 loss: 1.4154603481292725\n",
      "Iteration number 900 loss: 1.307173490524292\n",
      "Iteration number 1000 loss: 1.6344388723373413\n",
      "Iteration number 1100 loss: 1.1007344722747803\n",
      "Iteration number 1200 loss: 1.2249677181243896\n",
      "Iteration number 1300 loss: 1.4567161798477173\n",
      "Iteration number 1400 loss: 1.398910403251648\n",
      "Iteration number 1500 loss: 1.406665325164795\n",
      "Iteration number 1600 loss: 1.5003629922866821\n",
      "Iteration number 1700 loss: 1.4225866794586182\n",
      "Iteration number 1800 loss: 1.4778084754943848\n",
      "Iteration number 1900 loss: 1.4804946184158325\n",
      "Iteration number 2000 loss: 1.3966710567474365\n",
      "Iteration number 2100 loss: 1.5770611763000488\n",
      "Iteration number 2200 loss: 1.5780564546585083\n",
      "Iteration number 2300 loss: 1.4961128234863281\n",
      "Iteration number 2400 loss: 1.4235153198242188\n",
      "Iteration number 2500 loss: 1.1646599769592285\n",
      "Iteration number 2600 loss: 1.3335943222045898\n",
      "Iteration number 2700 loss: 1.328381896018982\n",
      "Iteration number 2800 loss: 1.6773868799209595\n",
      "Iteration number 2900 loss: 1.1721909046173096\n",
      "Iteration number 3000 loss: 1.2558164596557617\n",
      "Iteration number 3100 loss: 1.7167816162109375\n",
      "Iteration number 3200 loss: 1.5470268726348877\n",
      "Iteration number 3300 loss: 1.2170188426971436\n",
      "Iteration number 3400 loss: 1.8289347887039185\n",
      "Iteration number 3500 loss: 1.297048568725586\n",
      "Iteration number 3600 loss: 1.5434443950653076\n",
      "Iteration number 3700 loss: 1.349312424659729\n",
      "Iteration number 3800 loss: 1.226805567741394\n",
      "Iteration number 3900 loss: 1.44425630569458\n",
      "Iteration number 4000 loss: 1.3603076934814453\n",
      "Iteration number 4100 loss: 1.2793970108032227\n",
      "Iteration number 4200 loss: 1.512668251991272\n",
      "Iteration number 4300 loss: 1.6121567487716675\n",
      "Iteration number 4400 loss: 1.3969433307647705\n",
      "Iteration number 4500 loss: 1.655470848083496\n",
      "Iteration number 4600 loss: 1.8056832551956177\n",
      "Iteration number 4700 loss: 1.3285859823226929\n",
      "Iteration number 4800 loss: 1.7612123489379883\n",
      "Iteration number 4900 loss: 1.0940309762954712\n",
      "Iteration number 5000 loss: 1.168958067893982\n",
      "Iteration number 5100 loss: 1.3951175212860107\n",
      "Iteration number 5200 loss: 1.2911877632141113\n",
      "Iteration number 5300 loss: 1.3706154823303223\n",
      "Iteration number 5400 loss: 2.080265998840332\n",
      "Iteration number 5500 loss: 1.1640667915344238\n",
      "Iteration number 5600 loss: 1.442869782447815\n",
      "Iteration number 5700 loss: 1.335081696510315\n",
      "Iteration number 5800 loss: 1.2174389362335205\n",
      "Iteration number 5900 loss: 1.5177264213562012\n",
      "Iteration number 6000 loss: 1.5088618993759155\n",
      "Iteration number 6100 loss: 1.4233901500701904\n",
      "Iteration number 6200 loss: 1.4483227729797363\n",
      "Iteration number 6300 loss: 1.507440447807312\n",
      "Iteration number 6400 loss: 1.3324813842773438\n",
      "Iteration number 6500 loss: 1.4532625675201416\n",
      "Iteration number 6600 loss: 1.6049411296844482\n",
      "Iteration number 6700 loss: 1.389829397201538\n",
      "Iteration number 6800 loss: 1.412841796875\n",
      "Iteration number 6900 loss: 1.7996093034744263\n",
      "Iteration number 7000 loss: 1.4489312171936035\n",
      "Iteration number 7100 loss: 1.6340023279190063\n",
      "Iteration number 7200 loss: 1.4830063581466675\n",
      "Iteration number 7300 loss: 1.1286660432815552\n",
      "Iteration number 7400 loss: 1.6963977813720703\n",
      "Iteration number 7500 loss: 1.4276068210601807\n",
      "Iteration number 7600 loss: 1.3026618957519531\n",
      "Iteration number 7700 loss: 1.3808412551879883\n",
      "Iteration number 7800 loss: 1.186916708946228\n",
      "Iteration number 7900 loss: 1.6839896440505981\n",
      "Iteration number 8000 loss: 1.3945343494415283\n",
      "Iteration number 8100 loss: 1.4331040382385254\n",
      "Iteration number 8200 loss: 1.8261338472366333\n",
      "Iteration number 8300 loss: 1.9230871200561523\n",
      "Iteration number 8400 loss: 1.4093844890594482\n",
      "Iteration number 8500 loss: 1.6125367879867554\n",
      "Iteration number 8600 loss: 1.305887222290039\n",
      "Iteration number 8700 loss: 1.358550786972046\n",
      "Iteration number 8800 loss: 1.4728496074676514\n",
      "Iteration number 8900 loss: 1.6269004344940186\n",
      "Iteration number 9000 loss: 1.1046249866485596\n",
      "Iteration number 9100 loss: 1.767540454864502\n",
      "Iteration number 9200 loss: 1.577521800994873\n",
      "Iteration number 9300 loss: 1.382344126701355\n",
      "Iteration number 9400 loss: 1.616124153137207\n",
      "Iteration number 9500 loss: 1.3471245765686035\n",
      "Iteration number 9600 loss: 1.375212550163269\n",
      "Iteration number 9700 loss: 1.5019854307174683\n",
      "Iteration number 9800 loss: 1.6568951606750488\n",
      "Iteration number 9900 loss: 1.537388801574707\n",
      "Iteration number 10000 loss: 1.6344813108444214\n",
      "Iteration number 10100 loss: 1.6474609375\n",
      "Iteration number 10200 loss: 1.5624669790267944\n",
      "Iteration number 10300 loss: 1.478928565979004\n",
      "Iteration number 10400 loss: 1.6983258724212646\n",
      "Iteration number 10500 loss: 1.5915069580078125\n",
      "Iteration number 10600 loss: 1.6965283155441284\n",
      "Iteration number 10700 loss: 1.7217893600463867\n",
      "Iteration number 10800 loss: 1.448093056678772\n",
      "Iteration number 10900 loss: 1.6981799602508545\n",
      "Iteration number 11000 loss: 1.6019777059555054\n",
      "Iteration number 11100 loss: 1.5506207942962646\n",
      "Iteration number 11200 loss: 1.8589954376220703\n",
      "Iteration number 11300 loss: 1.7170915603637695\n",
      "Iteration number 11400 loss: 1.5399739742279053\n",
      "Iteration number 11500 loss: 1.5287734270095825\n",
      "Iteration number 11600 loss: 1.679034948348999\n",
      "Iteration number 11700 loss: 1.778441071510315\n",
      "Iteration number 11800 loss: 1.653771162033081\n",
      "Iteration number 11900 loss: 1.604772925376892\n",
      "Iteration number 12000 loss: 1.6868226528167725\n",
      "Iteration number 12100 loss: 1.6692416667938232\n",
      "Iteration number 12200 loss: 1.7806382179260254\n",
      "Iteration number 12300 loss: 1.6470247507095337\n",
      "Iteration number 12400 loss: 1.6944886445999146\n",
      "Iteration number 12500 loss: 1.794918417930603\n",
      "Iteration number 12600 loss: 1.5295802354812622\n",
      "Iteration number 12700 loss: 1.5185492038726807\n",
      "Iteration number 12800 loss: 1.9320813417434692\n",
      "Iteration number 12900 loss: 1.7178614139556885\n",
      "Iteration number 13000 loss: 1.485235333442688\n",
      "Iteration number 13100 loss: 1.6498339176177979\n",
      "Iteration number 13200 loss: 1.5547561645507812\n",
      "Iteration number 13300 loss: 1.7391455173492432\n",
      "Iteration number 13400 loss: 1.7371103763580322\n",
      "Iteration number 13500 loss: 1.581789255142212\n",
      "Iteration number 13600 loss: 1.6005545854568481\n",
      "Iteration number 13700 loss: 1.428230881690979\n",
      "Iteration number 13800 loss: 1.5860412120819092\n",
      "Iteration number 13900 loss: 1.4691100120544434\n",
      "Iteration number 14000 loss: 1.9133495092391968\n",
      "Iteration number 14100 loss: 1.860361099243164\n",
      "Iteration number 14200 loss: 1.727949857711792\n",
      "Iteration number 14300 loss: 1.5892351865768433\n",
      "Iteration number 14400 loss: 1.7485742568969727\n",
      "Iteration number 14500 loss: 1.6476337909698486\n",
      "Iteration number 14600 loss: 1.4965537786483765\n",
      "Iteration number 14700 loss: 1.5754666328430176\n",
      "Iteration number 14800 loss: 1.5967962741851807\n",
      "Iteration number 14900 loss: 1.6222662925720215\n",
      "Iteration number 15000 loss: 1.6397104263305664\n",
      "Iteration number 15100 loss: 1.5295122861862183\n",
      "Iteration number 15200 loss: 1.7386201620101929\n",
      "Iteration number 15300 loss: 1.5593698024749756\n",
      "Iteration number 15400 loss: 1.702061414718628\n",
      "Iteration number 15500 loss: 1.5765964984893799\n",
      "Iteration number 15600 loss: 1.7307064533233643\n",
      "Iteration number 15700 loss: 1.5823276042938232\n",
      "Iteration number 15800 loss: 1.678212285041809\n",
      "Episode Number: 15\n",
      "Iteration number 0 loss: 2.0963454246520996\n",
      "Iteration number 100 loss: 1.952786922454834\n",
      "Iteration number 200 loss: 1.911794662475586\n",
      "Iteration number 300 loss: 1.9055838584899902\n",
      "Iteration number 400 loss: 1.829204797744751\n",
      "Iteration number 500 loss: 2.0296409130096436\n",
      "Iteration number 600 loss: 2.016902446746826\n",
      "Iteration number 700 loss: 1.9844279289245605\n",
      "Iteration number 800 loss: 2.0029964447021484\n",
      "Iteration number 900 loss: 1.89736008644104\n",
      "Iteration number 1000 loss: 1.6503822803497314\n",
      "Iteration number 1100 loss: 1.7237154245376587\n",
      "Iteration number 1200 loss: 1.9831558465957642\n",
      "Iteration number 1300 loss: 1.9463801383972168\n",
      "Iteration number 1400 loss: 1.9909873008728027\n",
      "Iteration number 1500 loss: 1.9631998538970947\n",
      "Iteration number 1600 loss: 2.133686065673828\n",
      "Iteration number 1700 loss: 1.9103457927703857\n",
      "Iteration number 1800 loss: 1.703355073928833\n",
      "Iteration number 1900 loss: 1.661733865737915\n",
      "Iteration number 2000 loss: 2.1554226875305176\n",
      "Iteration number 2100 loss: 2.1046319007873535\n",
      "Iteration number 2200 loss: 2.212480068206787\n",
      "Iteration number 2300 loss: 2.000612258911133\n",
      "Iteration number 2400 loss: 2.031541109085083\n",
      "Iteration number 2500 loss: 2.225749969482422\n",
      "Iteration number 2600 loss: 2.3032586574554443\n",
      "Iteration number 2700 loss: 2.133610248565674\n",
      "Iteration number 2800 loss: 2.2620902061462402\n",
      "Iteration number 2900 loss: 2.1883678436279297\n",
      "Iteration number 3000 loss: 2.1755263805389404\n",
      "Iteration number 3100 loss: 2.240527629852295\n",
      "Iteration number 3200 loss: 2.0285308361053467\n",
      "Iteration number 3300 loss: 2.2550113201141357\n",
      "Iteration number 3400 loss: 2.2734856605529785\n",
      "Iteration number 3500 loss: 2.043311595916748\n",
      "Iteration number 3600 loss: 2.092298984527588\n",
      "Iteration number 3700 loss: 2.2715542316436768\n",
      "Iteration number 3800 loss: 2.062044620513916\n",
      "Iteration number 3900 loss: 2.036708354949951\n",
      "Iteration number 4000 loss: 2.033311605453491\n",
      "Iteration number 4100 loss: 1.8939573764801025\n",
      "Iteration number 4200 loss: 1.9698615074157715\n",
      "Iteration number 4300 loss: 2.0867602825164795\n",
      "Iteration number 4400 loss: 1.9857128858566284\n",
      "Iteration number 4500 loss: 2.1412715911865234\n",
      "Iteration number 4600 loss: 2.025998115539551\n",
      "Iteration number 4700 loss: 2.2299365997314453\n",
      "Iteration number 4800 loss: 2.112895965576172\n",
      "Iteration number 4900 loss: 2.202937126159668\n",
      "Iteration number 5000 loss: 2.060840606689453\n",
      "Iteration number 5100 loss: 1.89638090133667\n",
      "Iteration number 5200 loss: 1.9884891510009766\n",
      "Iteration number 5300 loss: 2.0892739295959473\n",
      "Iteration number 5400 loss: 1.7719593048095703\n",
      "Iteration number 5500 loss: 2.0156545639038086\n",
      "Iteration number 5600 loss: 2.109037160873413\n",
      "Iteration number 5700 loss: 1.823847770690918\n",
      "Iteration number 5800 loss: 1.931755542755127\n",
      "Iteration number 5900 loss: 1.860198736190796\n",
      "Iteration number 6000 loss: 1.989384412765503\n",
      "Iteration number 6100 loss: 1.7287042140960693\n",
      "Iteration number 6200 loss: 2.26334547996521\n",
      "Iteration number 6300 loss: 2.0633604526519775\n",
      "Iteration number 6400 loss: 2.232733726501465\n",
      "Iteration number 6500 loss: 1.9941132068634033\n",
      "Iteration number 6600 loss: 2.2039833068847656\n",
      "Iteration number 6700 loss: 2.212617874145508\n",
      "Iteration number 6800 loss: 2.080203056335449\n",
      "Iteration number 6900 loss: 2.20523738861084\n",
      "Iteration number 7000 loss: 2.6144919395446777\n",
      "Iteration number 7100 loss: 2.2360804080963135\n",
      "Iteration number 7200 loss: 2.0468287467956543\n",
      "Iteration number 7300 loss: 2.257521390914917\n",
      "Iteration number 7400 loss: 2.2376978397369385\n",
      "Iteration number 7500 loss: 2.30148983001709\n",
      "Iteration number 7600 loss: 2.0466527938842773\n",
      "Iteration number 7700 loss: 2.2347986698150635\n",
      "Iteration number 7800 loss: 1.9658856391906738\n",
      "Iteration number 7900 loss: 2.0016632080078125\n",
      "Iteration number 8000 loss: 2.0957655906677246\n",
      "Iteration number 8100 loss: 2.227494716644287\n",
      "Iteration number 8200 loss: 2.324894428253174\n",
      "Iteration number 8300 loss: 2.066953420639038\n",
      "Iteration number 8400 loss: 2.0427725315093994\n",
      "Iteration number 8500 loss: 1.9556690454483032\n",
      "Iteration number 8600 loss: 2.170323371887207\n",
      "Iteration number 8700 loss: 2.09562349319458\n",
      "Iteration number 8800 loss: 2.0567612648010254\n",
      "Iteration number 8900 loss: 1.9136688709259033\n",
      "Iteration number 9000 loss: 2.0692906379699707\n",
      "Iteration number 9100 loss: 2.3097386360168457\n",
      "Iteration number 9200 loss: 2.0271263122558594\n",
      "Iteration number 9300 loss: 2.0987367630004883\n",
      "Iteration number 9400 loss: 2.3053672313690186\n",
      "Iteration number 9500 loss: 2.0417749881744385\n",
      "Iteration number 9600 loss: 1.948225975036621\n",
      "Iteration number 9700 loss: 2.2327146530151367\n",
      "Iteration number 9800 loss: 2.273761749267578\n",
      "Iteration number 9900 loss: 2.06130313873291\n",
      "Iteration number 10000 loss: 1.983457326889038\n",
      "Iteration number 10100 loss: 2.290972948074341\n",
      "Iteration number 10200 loss: 1.9726176261901855\n",
      "Iteration number 10300 loss: 2.145401954650879\n",
      "Iteration number 10400 loss: 2.034055471420288\n",
      "Iteration number 10500 loss: 2.1252691745758057\n",
      "Iteration number 10600 loss: 2.088123083114624\n",
      "Iteration number 10700 loss: 2.005321741104126\n",
      "Iteration number 10800 loss: 2.0288338661193848\n",
      "Iteration number 10900 loss: 2.0965662002563477\n",
      "Iteration number 11000 loss: 2.281007766723633\n",
      "Iteration number 11100 loss: 2.1730005741119385\n",
      "Iteration number 11200 loss: 2.0160679817199707\n",
      "Iteration number 11300 loss: 2.234835147857666\n",
      "Iteration number 11400 loss: 2.369292736053467\n",
      "Iteration number 11500 loss: 2.0644335746765137\n",
      "Iteration number 11600 loss: 2.014556884765625\n",
      "Iteration number 11700 loss: 1.9945427179336548\n",
      "Iteration number 11800 loss: 1.9024409055709839\n",
      "Iteration number 11900 loss: 1.9307547807693481\n",
      "Iteration number 12000 loss: 2.106966495513916\n",
      "Iteration number 12100 loss: 2.2034506797790527\n",
      "Iteration number 12200 loss: 1.9178595542907715\n",
      "Iteration number 12300 loss: 2.2852587699890137\n",
      "Iteration number 12400 loss: 2.0608572959899902\n",
      "Iteration number 12500 loss: 2.1034555435180664\n",
      "Iteration number 12600 loss: 2.1889138221740723\n",
      "Iteration number 12700 loss: 2.031759023666382\n",
      "Iteration number 12800 loss: 2.1142544746398926\n",
      "Iteration number 12900 loss: 2.265885591506958\n",
      "Iteration number 13000 loss: 2.0821382999420166\n",
      "Iteration number 13100 loss: 2.0409562587738037\n",
      "Iteration number 13200 loss: 2.1398749351501465\n",
      "Iteration number 13300 loss: 2.1244261264801025\n",
      "Iteration number 13400 loss: 2.146573543548584\n",
      "Iteration number 13500 loss: 2.063526153564453\n",
      "Iteration number 13600 loss: 2.0812478065490723\n",
      "Iteration number 13700 loss: 2.0188450813293457\n",
      "Iteration number 13800 loss: 2.1226437091827393\n",
      "Iteration number 13900 loss: 1.9176902770996094\n",
      "Iteration number 14000 loss: 2.0037894248962402\n",
      "Iteration number 14100 loss: 1.980620265007019\n",
      "Iteration number 14200 loss: 2.033953905105591\n",
      "Iteration number 14300 loss: 1.8716154098510742\n",
      "Iteration number 14400 loss: 2.0349831581115723\n",
      "Iteration number 14500 loss: 2.0804953575134277\n",
      "Iteration number 14600 loss: 1.9686992168426514\n",
      "Iteration number 14700 loss: 2.071136713027954\n",
      "Iteration number 14800 loss: 2.1839098930358887\n",
      "Iteration number 14900 loss: 2.239299774169922\n",
      "Iteration number 15000 loss: 1.9450011253356934\n",
      "Iteration number 15100 loss: 1.9679042100906372\n",
      "Iteration number 15200 loss: 1.957693099975586\n",
      "Iteration number 15300 loss: 2.124828577041626\n",
      "Iteration number 15400 loss: 2.000791072845459\n",
      "Iteration number 15500 loss: 2.2150487899780273\n",
      "Iteration number 15600 loss: 2.0014452934265137\n",
      "Iteration number 15700 loss: 2.0310802459716797\n",
      "Iteration number 15800 loss: 2.0128014087677\n",
      "Iteration number 15900 loss: 1.9958171844482422\n",
      "Iteration number 16000 loss: 2.205099582672119\n",
      "Iteration number 16100 loss: 1.9846832752227783\n",
      "Iteration number 16200 loss: 1.9992084503173828\n",
      "Iteration number 16300 loss: 2.0288453102111816\n",
      "Iteration number 16400 loss: 2.1350531578063965\n",
      "Iteration number 16500 loss: 1.865167498588562\n",
      "Iteration number 16600 loss: 2.311100721359253\n",
      "Iteration number 16700 loss: 2.12717866897583\n",
      "Iteration number 16800 loss: 2.0570225715637207\n",
      "Iteration number 16900 loss: 2.003103256225586\n",
      "Iteration number 17000 loss: 2.028654098510742\n",
      "Iteration number 17100 loss: 2.118870735168457\n",
      "Iteration number 17200 loss: 2.045208215713501\n",
      "Iteration number 17300 loss: 1.995525598526001\n",
      "Iteration number 17400 loss: 2.0712509155273438\n",
      "Iteration number 17500 loss: 2.3054800033569336\n",
      "Iteration number 17600 loss: 2.1174674034118652\n",
      "Iteration number 17700 loss: 2.062601089477539\n",
      "Iteration number 17800 loss: 2.0960118770599365\n",
      "Iteration number 17900 loss: 2.1688456535339355\n",
      "Iteration number 18000 loss: 2.208040237426758\n",
      "Iteration number 18100 loss: 2.049717426300049\n",
      "Iteration number 18200 loss: 2.2142608165740967\n",
      "Iteration number 18300 loss: 2.1069393157958984\n",
      "Iteration number 18400 loss: 2.0132062435150146\n",
      "Iteration number 18500 loss: 1.8064601421356201\n",
      "Iteration number 18600 loss: 2.0425872802734375\n",
      "Iteration number 18700 loss: 2.142284870147705\n",
      "Iteration number 18800 loss: 2.083362579345703\n",
      "Iteration number 18900 loss: 2.183025598526001\n",
      "Iteration number 19000 loss: 2.024045944213867\n",
      "Iteration number 19100 loss: 2.2435407638549805\n",
      "Iteration number 19200 loss: 1.9843246936798096\n",
      "Iteration number 19300 loss: 2.0670723915100098\n",
      "Iteration number 19400 loss: 1.881231665611267\n",
      "Iteration number 19500 loss: 2.012582302093506\n",
      "Iteration number 19600 loss: 2.1387174129486084\n",
      "Iteration number 19700 loss: 2.1309075355529785\n",
      "Iteration number 19800 loss: 2.118389129638672\n",
      "Iteration number 19900 loss: 2.1613850593566895\n",
      "Iteration number 20000 loss: 2.073972702026367\n",
      "Iteration number 20100 loss: 2.049795150756836\n",
      "Iteration number 20200 loss: 2.257014751434326\n",
      "Iteration number 20300 loss: 2.2144036293029785\n",
      "Iteration number 20400 loss: 2.139206647872925\n",
      "Iteration number 20500 loss: 2.111079216003418\n",
      "Iteration number 20600 loss: 2.0912904739379883\n",
      "Iteration number 20700 loss: 2.0908565521240234\n",
      "Iteration number 20800 loss: 1.9485708475112915\n",
      "Iteration number 20900 loss: 2.3052334785461426\n",
      "Iteration number 21000 loss: 2.0612239837646484\n",
      "Iteration number 21100 loss: 1.8504778146743774\n",
      "Iteration number 21200 loss: 2.2008285522460938\n",
      "Iteration number 21300 loss: 2.1623189449310303\n",
      "Iteration number 21400 loss: 2.1890580654144287\n",
      "Iteration number 21500 loss: 1.9250187873840332\n",
      "Iteration number 21600 loss: 2.0545036792755127\n",
      "Iteration number 21700 loss: 2.227144956588745\n",
      "Iteration number 21800 loss: 2.1761064529418945\n",
      "Iteration number 21900 loss: 2.13946270942688\n",
      "Iteration number 22000 loss: 1.9551424980163574\n",
      "Iteration number 22100 loss: 2.057955265045166\n",
      "Iteration number 22200 loss: 2.061387062072754\n",
      "Iteration number 22300 loss: 2.071592092514038\n",
      "Iteration number 22400 loss: 1.9132457971572876\n",
      "Iteration number 22500 loss: 2.1600494384765625\n",
      "Iteration number 22600 loss: 2.0619051456451416\n",
      "Iteration number 22700 loss: 2.097684383392334\n",
      "Iteration number 22800 loss: 2.121458053588867\n",
      "Iteration number 22900 loss: 2.3143539428710938\n",
      "Iteration number 23000 loss: 2.363992929458618\n",
      "Iteration number 23100 loss: 2.1678271293640137\n",
      "Iteration number 23200 loss: 2.0590453147888184\n",
      "Iteration number 23300 loss: 2.193727493286133\n",
      "Iteration number 23400 loss: 2.0280470848083496\n",
      "Iteration number 23500 loss: 1.9385554790496826\n",
      "Iteration number 23600 loss: 2.0405097007751465\n",
      "Iteration number 23700 loss: 2.1671972274780273\n",
      "Iteration number 23800 loss: 2.273314952850342\n",
      "Iteration number 23900 loss: 2.0600690841674805\n",
      "Iteration number 24000 loss: 2.0934219360351562\n",
      "Iteration number 24100 loss: 1.909834384918213\n",
      "Iteration number 24200 loss: 2.0651655197143555\n",
      "Iteration number 24300 loss: 2.020432233810425\n",
      "Iteration number 24400 loss: 2.1658740043640137\n",
      "Iteration number 24500 loss: 2.0595545768737793\n",
      "Iteration number 24600 loss: 2.1736905574798584\n",
      "Iteration number 24700 loss: 1.9766333103179932\n",
      "Iteration number 24800 loss: 1.9660933017730713\n",
      "Iteration number 24900 loss: 2.020970344543457\n",
      "Iteration number 25000 loss: 2.109286308288574\n",
      "Iteration number 25100 loss: 1.9614198207855225\n",
      "Iteration number 25200 loss: 1.9519891738891602\n",
      "Iteration number 25300 loss: 1.8702473640441895\n",
      "Iteration number 25400 loss: 2.219785213470459\n",
      "Iteration number 25500 loss: 1.9103400707244873\n",
      "Iteration number 25600 loss: 2.0601775646209717\n",
      "Iteration number 25700 loss: 2.191150665283203\n",
      "Iteration number 25800 loss: 2.0673632621765137\n",
      "Iteration number 25900 loss: 1.9908037185668945\n",
      "Iteration number 26000 loss: 2.1728625297546387\n",
      "Iteration number 26100 loss: 2.0988826751708984\n",
      "Iteration number 26200 loss: 2.0669713020324707\n",
      "Iteration number 26300 loss: 2.051970958709717\n",
      "Iteration number 26400 loss: 2.1919734477996826\n",
      "Iteration number 26500 loss: 2.074692964553833\n",
      "Iteration number 26600 loss: 2.2322235107421875\n",
      "Iteration number 26700 loss: 2.110305070877075\n",
      "Iteration number 26800 loss: 2.0970048904418945\n",
      "Iteration number 26900 loss: 2.853595018386841\n",
      "Iteration number 27000 loss: 2.331325054168701\n",
      "Iteration number 27100 loss: 2.1836891174316406\n",
      "Iteration number 27200 loss: 2.1304092407226562\n",
      "Iteration number 27300 loss: 2.2082715034484863\n",
      "Iteration number 27400 loss: 2.2291696071624756\n",
      "Iteration number 27500 loss: 2.8141703605651855\n",
      "Iteration number 27600 loss: 2.500415802001953\n",
      "Iteration number 27700 loss: 2.901489496231079\n",
      "Iteration number 27800 loss: 2.4139249324798584\n",
      "Iteration number 27900 loss: 2.09220552444458\n",
      "Iteration number 28000 loss: 2.673309803009033\n",
      "Iteration number 28100 loss: 3.084784746170044\n",
      "Iteration number 28200 loss: 2.9417715072631836\n",
      "Iteration number 28300 loss: 2.5430407524108887\n",
      "Iteration number 28400 loss: 3.2160110473632812\n",
      "Iteration number 28500 loss: 2.716050624847412\n",
      "Iteration number 28600 loss: 2.778151035308838\n",
      "Iteration number 28700 loss: 2.9985666275024414\n",
      "Iteration number 28800 loss: 3.0384764671325684\n",
      "Iteration number 28900 loss: 2.8909425735473633\n",
      "Iteration number 29000 loss: 2.921912670135498\n",
      "Iteration number 29100 loss: 3.0780694484710693\n",
      "Episode Number: 16\n",
      "Iteration number 0 loss: 2.8098418712615967\n",
      "Iteration number 100 loss: 2.432589530944824\n",
      "Iteration number 200 loss: 2.869898796081543\n",
      "Iteration number 300 loss: 2.952667236328125\n",
      "Iteration number 400 loss: 2.2926671504974365\n",
      "Iteration number 500 loss: 2.542513370513916\n",
      "Iteration number 600 loss: 3.34332275390625\n",
      "Iteration number 700 loss: 2.608689546585083\n",
      "Iteration number 800 loss: 2.8122963905334473\n",
      "Iteration number 900 loss: 2.547499656677246\n",
      "Iteration number 1000 loss: 2.5099611282348633\n",
      "Iteration number 1100 loss: 2.686544895172119\n",
      "Iteration number 1200 loss: 2.1353578567504883\n",
      "Iteration number 1300 loss: 2.3552193641662598\n",
      "Iteration number 1400 loss: 2.6615400314331055\n",
      "Iteration number 1500 loss: 2.5681674480438232\n",
      "Iteration number 1600 loss: 2.818471908569336\n",
      "Iteration number 1700 loss: 2.3966355323791504\n",
      "Iteration number 1800 loss: 2.528099775314331\n",
      "Iteration number 1900 loss: 2.7999520301818848\n",
      "Iteration number 2000 loss: 2.3803353309631348\n",
      "Iteration number 2100 loss: 3.63777232170105\n",
      "Iteration number 2200 loss: 2.665705442428589\n",
      "Iteration number 2300 loss: 2.5876619815826416\n",
      "Iteration number 2400 loss: 2.7103328704833984\n",
      "Iteration number 2500 loss: 3.5081801414489746\n",
      "Iteration number 2600 loss: 2.2770938873291016\n",
      "Iteration number 2700 loss: 2.763434886932373\n",
      "Iteration number 2800 loss: 3.093182325363159\n",
      "Iteration number 2900 loss: 2.3467888832092285\n",
      "Iteration number 3000 loss: 2.972929000854492\n",
      "Iteration number 3100 loss: 2.4638543128967285\n",
      "Iteration number 3200 loss: 2.7321596145629883\n",
      "Iteration number 3300 loss: 3.0525999069213867\n",
      "Iteration number 3400 loss: 2.2693371772766113\n",
      "Iteration number 3500 loss: 3.3116941452026367\n",
      "Iteration number 3600 loss: 2.7223291397094727\n",
      "Iteration number 3700 loss: 2.8699076175689697\n",
      "Iteration number 3800 loss: 2.3725833892822266\n",
      "Iteration number 3900 loss: 2.5566396713256836\n",
      "Iteration number 4000 loss: 2.8683364391326904\n",
      "Iteration number 4100 loss: 2.2249197959899902\n",
      "Iteration number 4200 loss: 2.7152438163757324\n",
      "Iteration number 4300 loss: 2.248483896255493\n",
      "Iteration number 4400 loss: 1.9487078189849854\n",
      "Iteration number 4500 loss: 2.791687488555908\n",
      "Iteration number 4600 loss: 2.6895346641540527\n",
      "Iteration number 4700 loss: 2.656095504760742\n",
      "Iteration number 4800 loss: 2.5823025703430176\n",
      "Iteration number 4900 loss: 3.2565155029296875\n",
      "Iteration number 5000 loss: 2.2779083251953125\n",
      "Iteration number 5100 loss: 2.8434979915618896\n",
      "Iteration number 5200 loss: 3.173787832260132\n",
      "Iteration number 5300 loss: 2.77144718170166\n",
      "Iteration number 5400 loss: 3.484727621078491\n",
      "Iteration number 5500 loss: 2.1868224143981934\n",
      "Iteration number 5600 loss: 2.0239529609680176\n",
      "Iteration number 5700 loss: 2.938232421875\n",
      "Iteration number 5800 loss: 2.413109302520752\n",
      "Iteration number 5900 loss: 3.110365390777588\n",
      "Iteration number 6000 loss: 2.2420907020568848\n",
      "Iteration number 6100 loss: 2.6194441318511963\n",
      "Iteration number 6200 loss: 2.3380138874053955\n",
      "Iteration number 6300 loss: 2.54390811920166\n",
      "Iteration number 6400 loss: 2.6793272495269775\n",
      "Iteration number 6500 loss: 2.6137821674346924\n",
      "Iteration number 6600 loss: 1.9964728355407715\n",
      "Iteration number 6700 loss: 2.2106964588165283\n",
      "Iteration number 6800 loss: 2.1822431087493896\n",
      "Iteration number 6900 loss: 2.2627034187316895\n",
      "Iteration number 7000 loss: 3.1715450286865234\n",
      "Iteration number 7100 loss: 3.5732309818267822\n",
      "Iteration number 7200 loss: 2.2773189544677734\n",
      "Iteration number 7300 loss: 2.028174877166748\n",
      "Iteration number 7400 loss: 2.652179718017578\n",
      "Iteration number 7500 loss: 3.4020965099334717\n",
      "Iteration number 7600 loss: 2.8614115715026855\n",
      "Iteration number 7700 loss: 2.3182449340820312\n",
      "Iteration number 7800 loss: 2.394963264465332\n",
      "Iteration number 7900 loss: 2.0394487380981445\n",
      "Iteration number 8000 loss: 2.295316457748413\n",
      "Iteration number 8100 loss: 2.185248613357544\n",
      "Iteration number 8200 loss: 2.6001346111297607\n",
      "Iteration number 8300 loss: 1.7877819538116455\n",
      "Iteration number 8400 loss: 1.6615006923675537\n",
      "Iteration number 8500 loss: 1.928853988647461\n",
      "Iteration number 8600 loss: 1.840834379196167\n",
      "Iteration number 8700 loss: 1.825378179550171\n",
      "Iteration number 8800 loss: 1.7454502582550049\n",
      "Iteration number 8900 loss: 1.682623028755188\n",
      "Iteration number 9000 loss: 1.6830112934112549\n",
      "Iteration number 9100 loss: 1.6713365316390991\n",
      "Iteration number 9200 loss: 1.8965309858322144\n",
      "Iteration number 9300 loss: 1.869060754776001\n",
      "Iteration number 9400 loss: 1.9593472480773926\n",
      "Iteration number 9500 loss: 1.859722375869751\n",
      "Iteration number 9600 loss: 1.9227566719055176\n",
      "Iteration number 9700 loss: 1.956789255142212\n",
      "Iteration number 9800 loss: 2.465040922164917\n",
      "Iteration number 9900 loss: 1.9613397121429443\n",
      "Iteration number 10000 loss: 1.9260916709899902\n",
      "Iteration number 10100 loss: 1.942347526550293\n",
      "Iteration number 10200 loss: 2.161655902862549\n",
      "Iteration number 10300 loss: 1.9321482181549072\n",
      "Iteration number 10400 loss: 2.039726734161377\n",
      "Iteration number 10500 loss: 2.0108609199523926\n",
      "Iteration number 10600 loss: 1.9673492908477783\n",
      "Iteration number 10700 loss: 2.1120338439941406\n",
      "Iteration number 10800 loss: 1.982985019683838\n",
      "Iteration number 10900 loss: 1.89609694480896\n",
      "Iteration number 11000 loss: 1.8962254524230957\n",
      "Iteration number 11100 loss: 1.8729915618896484\n",
      "Iteration number 11200 loss: 2.1621921062469482\n",
      "Iteration number 11300 loss: 1.8042794466018677\n",
      "Iteration number 11400 loss: 1.8557100296020508\n",
      "Iteration number 11500 loss: 2.0271658897399902\n",
      "Iteration number 11600 loss: 1.9144079685211182\n",
      "Iteration number 11700 loss: 1.8841954469680786\n",
      "Iteration number 11800 loss: 1.895331621170044\n",
      "Iteration number 11900 loss: 1.843624472618103\n",
      "Iteration number 12000 loss: 1.9757161140441895\n",
      "Iteration number 12100 loss: 1.9794163703918457\n",
      "Iteration number 12200 loss: 2.023238182067871\n",
      "Iteration number 12300 loss: 2.0057387351989746\n",
      "Iteration number 12400 loss: 1.9447389841079712\n",
      "Iteration number 12500 loss: 1.8735271692276\n",
      "Iteration number 12600 loss: 2.0189290046691895\n",
      "Iteration number 12700 loss: 1.9224247932434082\n",
      "Iteration number 12800 loss: 1.7644543647766113\n",
      "Iteration number 12900 loss: 1.65545654296875\n",
      "Iteration number 13000 loss: 1.9568634033203125\n",
      "Iteration number 13100 loss: 1.91983962059021\n",
      "Iteration number 13200 loss: 1.9870474338531494\n",
      "Iteration number 13300 loss: 1.971386432647705\n",
      "Iteration number 13400 loss: 2.154012680053711\n",
      "Iteration number 13500 loss: 1.807042121887207\n",
      "Iteration number 13600 loss: 1.951130986213684\n",
      "Iteration number 13700 loss: 2.0407333374023438\n",
      "Iteration number 13800 loss: 1.9893813133239746\n",
      "Iteration number 13900 loss: 1.9221514463424683\n",
      "Iteration number 14000 loss: 2.0120198726654053\n",
      "Iteration number 14100 loss: 1.991504430770874\n",
      "Iteration number 14200 loss: 1.9717249870300293\n",
      "Iteration number 14300 loss: 1.9653899669647217\n",
      "Iteration number 14400 loss: 2.0212888717651367\n",
      "Iteration number 14500 loss: 1.9115679264068604\n",
      "Iteration number 14600 loss: 1.8764793872833252\n",
      "Iteration number 14700 loss: 2.0064189434051514\n",
      "Iteration number 14800 loss: 2.0567002296447754\n",
      "Iteration number 14900 loss: 1.90985906124115\n",
      "Iteration number 15000 loss: 1.957632303237915\n",
      "Iteration number 15100 loss: 2.0673375129699707\n",
      "Iteration number 15200 loss: 1.9990272521972656\n",
      "Iteration number 15300 loss: 1.9652698040008545\n",
      "Iteration number 15400 loss: 1.9015898704528809\n",
      "Iteration number 15500 loss: 1.9150896072387695\n",
      "Iteration number 15600 loss: 2.1324195861816406\n",
      "Iteration number 15700 loss: 2.006683826446533\n",
      "Iteration number 15800 loss: 2.058840751647949\n",
      "Iteration number 15900 loss: 2.0022330284118652\n",
      "Iteration number 16000 loss: 1.9405192136764526\n",
      "Iteration number 16100 loss: 1.9504461288452148\n",
      "Iteration number 16200 loss: 2.069707155227661\n",
      "Iteration number 16300 loss: 2.0425586700439453\n",
      "Iteration number 16400 loss: 2.0675926208496094\n",
      "Iteration number 16500 loss: 2.044125556945801\n",
      "Iteration number 16600 loss: 2.0942673683166504\n",
      "Iteration number 16700 loss: 1.9341917037963867\n",
      "Iteration number 16800 loss: 2.0882599353790283\n",
      "Iteration number 16900 loss: 2.102569103240967\n",
      "Iteration number 17000 loss: 2.298677682876587\n",
      "Iteration number 17100 loss: 2.2967474460601807\n",
      "Iteration number 17200 loss: 2.014691114425659\n",
      "Iteration number 17300 loss: 2.0653131008148193\n",
      "Iteration number 17400 loss: 1.8191041946411133\n",
      "Iteration number 17500 loss: 2.1753196716308594\n",
      "Iteration number 17600 loss: 2.07102108001709\n",
      "Iteration number 17700 loss: 2.0050487518310547\n",
      "Iteration number 17800 loss: 1.9285898208618164\n",
      "Iteration number 17900 loss: 1.843497395515442\n",
      "Iteration number 18000 loss: 1.971097707748413\n",
      "Iteration number 18100 loss: 1.9390010833740234\n",
      "Iteration number 18200 loss: 1.9290786981582642\n",
      "Iteration number 18300 loss: 2.0311548709869385\n",
      "Iteration number 18400 loss: 2.0157270431518555\n",
      "Iteration number 18500 loss: 1.9469311237335205\n",
      "Iteration number 18600 loss: 1.9398467540740967\n",
      "Iteration number 18700 loss: 2.0434513092041016\n",
      "Iteration number 18800 loss: 2.2551751136779785\n",
      "Iteration number 18900 loss: 1.984859824180603\n",
      "Iteration number 19000 loss: 2.0694117546081543\n",
      "Iteration number 19100 loss: 2.2287747859954834\n",
      "Iteration number 19200 loss: 1.6896917819976807\n",
      "Iteration number 19300 loss: 1.9344686269760132\n",
      "Iteration number 19400 loss: 2.1378791332244873\n",
      "Iteration number 19500 loss: 1.8996026515960693\n",
      "Iteration number 19600 loss: 1.9901118278503418\n",
      "Iteration number 19700 loss: 1.9300994873046875\n",
      "Iteration number 19800 loss: 2.0311906337738037\n",
      "Iteration number 19900 loss: 2.087472677230835\n",
      "Iteration number 20000 loss: 2.0709080696105957\n",
      "Iteration number 20100 loss: 1.9017937183380127\n",
      "Iteration number 20200 loss: 1.995780348777771\n",
      "Iteration number 20300 loss: 2.171762704849243\n",
      "Iteration number 20400 loss: 2.0214757919311523\n",
      "Iteration number 20500 loss: 1.9171056747436523\n",
      "Iteration number 20600 loss: 1.9980462789535522\n",
      "Iteration number 20700 loss: 1.8464360237121582\n",
      "Iteration number 20800 loss: 2.0674662590026855\n",
      "Iteration number 20900 loss: 1.9285069704055786\n",
      "Iteration number 21000 loss: 2.064964532852173\n",
      "Iteration number 21100 loss: 2.0506203174591064\n",
      "Iteration number 21200 loss: 1.995572566986084\n",
      "Iteration number 21300 loss: 1.8518362045288086\n",
      "Iteration number 21400 loss: 1.984734058380127\n",
      "Iteration number 21500 loss: 1.9749587774276733\n",
      "Iteration number 21600 loss: 1.856095790863037\n",
      "Iteration number 21700 loss: 1.8732428550720215\n",
      "Iteration number 21800 loss: 1.8427200317382812\n",
      "Iteration number 21900 loss: 1.828678846359253\n",
      "Iteration number 22000 loss: 2.0900497436523438\n",
      "Iteration number 22100 loss: 1.9598286151885986\n",
      "Iteration number 22200 loss: 1.7974648475646973\n",
      "Iteration number 22300 loss: 1.908052682876587\n",
      "Iteration number 22400 loss: 1.876969337463379\n",
      "Iteration number 22500 loss: 2.128145456314087\n",
      "Iteration number 22600 loss: 1.919205904006958\n",
      "Iteration number 22700 loss: 2.219876289367676\n",
      "Iteration number 22800 loss: 2.197643756866455\n",
      "Iteration number 22900 loss: 1.7635736465454102\n",
      "Iteration number 23000 loss: 1.9452300071716309\n",
      "Iteration number 23100 loss: 2.097991943359375\n",
      "Iteration number 23200 loss: 1.860563039779663\n",
      "Iteration number 23300 loss: 1.8362587690353394\n",
      "Iteration number 23400 loss: 1.8994650840759277\n",
      "Iteration number 23500 loss: 2.1243162155151367\n",
      "Iteration number 23600 loss: 2.030205726623535\n",
      "Iteration number 23700 loss: 1.8148012161254883\n",
      "Iteration number 23800 loss: 1.6871988773345947\n",
      "Iteration number 23900 loss: 1.9613676071166992\n",
      "Iteration number 24000 loss: 1.942870020866394\n",
      "Iteration number 24100 loss: 1.678312063217163\n",
      "Iteration number 24200 loss: 1.8921115398406982\n",
      "Iteration number 24300 loss: 1.9189653396606445\n",
      "Iteration number 24400 loss: 1.778083324432373\n",
      "Iteration number 24500 loss: 1.7847416400909424\n",
      "Iteration number 24600 loss: 2.1782779693603516\n",
      "Iteration number 24700 loss: 1.9878450632095337\n",
      "Iteration number 24800 loss: 1.8030849695205688\n",
      "Iteration number 24900 loss: 2.044701099395752\n",
      "Iteration number 25000 loss: 1.9570577144622803\n",
      "Iteration number 25100 loss: 2.08054780960083\n",
      "Iteration number 25200 loss: 1.7361161708831787\n",
      "Iteration number 25300 loss: 2.019111394882202\n",
      "Iteration number 25400 loss: 2.0214245319366455\n",
      "Iteration number 25500 loss: 2.066004991531372\n",
      "Iteration number 25600 loss: 1.8845351934432983\n",
      "Iteration number 25700 loss: 1.9066513776779175\n",
      "Iteration number 25800 loss: 2.101864814758301\n",
      "Iteration number 25900 loss: 2.1951804161071777\n",
      "Iteration number 26000 loss: 2.026522159576416\n",
      "Iteration number 26100 loss: 2.098040819168091\n",
      "Iteration number 26200 loss: 2.067753791809082\n",
      "Iteration number 26300 loss: 2.0985918045043945\n",
      "Iteration number 26400 loss: 2.1117844581604004\n",
      "Iteration number 26500 loss: 1.8724957704544067\n",
      "Iteration number 26600 loss: 2.2406301498413086\n",
      "Iteration number 26700 loss: 2.064005136489868\n",
      "Iteration number 26800 loss: 2.0617904663085938\n",
      "Episode Number: 17\n",
      "Iteration number 0 loss: 1.8666480779647827\n",
      "Iteration number 100 loss: 2.09041166305542\n",
      "Iteration number 200 loss: 2.178236961364746\n",
      "Iteration number 300 loss: 1.9650866985321045\n",
      "Iteration number 400 loss: 2.1264708042144775\n",
      "Iteration number 500 loss: 1.8852949142456055\n",
      "Iteration number 600 loss: 1.913743257522583\n",
      "Iteration number 700 loss: 1.932563066482544\n",
      "Iteration number 800 loss: 2.2476613521575928\n",
      "Iteration number 900 loss: 1.9021538496017456\n",
      "Iteration number 1000 loss: 2.2106285095214844\n",
      "Iteration number 1100 loss: 1.924642562866211\n",
      "Iteration number 1200 loss: 1.926154375076294\n",
      "Iteration number 1300 loss: 2.1023948192596436\n",
      "Iteration number 1400 loss: 1.995674729347229\n",
      "Iteration number 1500 loss: 1.7060346603393555\n",
      "Iteration number 1600 loss: 1.9812333583831787\n",
      "Iteration number 1700 loss: 1.9504226446151733\n",
      "Iteration number 1800 loss: 2.045642375946045\n",
      "Iteration number 1900 loss: 1.9711215496063232\n",
      "Iteration number 2000 loss: 2.1176512241363525\n",
      "Iteration number 2100 loss: 1.9039570093154907\n",
      "Iteration number 2200 loss: 1.9068478345870972\n",
      "Iteration number 2300 loss: 1.7621042728424072\n",
      "Iteration number 2400 loss: 2.0580010414123535\n",
      "Iteration number 2500 loss: 1.7108705043792725\n",
      "Iteration number 2600 loss: 1.961916208267212\n",
      "Iteration number 2700 loss: 2.0000672340393066\n",
      "Iteration number 2800 loss: 1.9685263633728027\n",
      "Iteration number 2900 loss: 1.9711673259735107\n",
      "Iteration number 3000 loss: 2.002617120742798\n",
      "Iteration number 3100 loss: 2.0619800090789795\n",
      "Iteration number 3200 loss: 2.0766875743865967\n",
      "Iteration number 3300 loss: 1.9414652585983276\n",
      "Iteration number 3400 loss: 2.0696301460266113\n",
      "Iteration number 3500 loss: 2.1028616428375244\n",
      "Iteration number 3600 loss: 1.9700310230255127\n",
      "Iteration number 3700 loss: 2.28098201751709\n",
      "Iteration number 3800 loss: 1.934196949005127\n",
      "Iteration number 3900 loss: 1.9421429634094238\n",
      "Iteration number 4000 loss: 2.0615270137786865\n",
      "Iteration number 4100 loss: 2.0632665157318115\n",
      "Iteration number 4200 loss: 1.9917241334915161\n",
      "Iteration number 4300 loss: 2.0548593997955322\n",
      "Iteration number 4400 loss: 1.957733154296875\n",
      "Iteration number 4500 loss: 1.845139980316162\n",
      "Iteration number 4600 loss: 1.9497476816177368\n",
      "Iteration number 4700 loss: 1.8827247619628906\n",
      "Iteration number 4800 loss: 2.159015655517578\n",
      "Iteration number 4900 loss: 2.1464686393737793\n",
      "Iteration number 5000 loss: 2.0153796672821045\n",
      "Iteration number 5100 loss: 1.9868309497833252\n",
      "Iteration number 5200 loss: 2.0411295890808105\n",
      "Iteration number 5300 loss: 2.036163806915283\n",
      "Iteration number 5400 loss: 2.078965663909912\n",
      "Iteration number 5500 loss: 1.9831032752990723\n",
      "Iteration number 5600 loss: 2.1927647590637207\n",
      "Iteration number 5700 loss: 1.866662859916687\n",
      "Iteration number 5800 loss: 1.8040075302124023\n",
      "Iteration number 5900 loss: 1.9076746702194214\n",
      "Iteration number 6000 loss: 1.8466320037841797\n",
      "Iteration number 6100 loss: 2.211066722869873\n",
      "Iteration number 6200 loss: 1.8750029802322388\n",
      "Iteration number 6300 loss: 2.061555862426758\n",
      "Iteration number 6400 loss: 2.0861382484436035\n",
      "Iteration number 6500 loss: 1.9396305084228516\n",
      "Iteration number 6600 loss: 1.9553287029266357\n",
      "Iteration number 6700 loss: 1.8685030937194824\n",
      "Iteration number 6800 loss: 1.996175765991211\n",
      "Iteration number 6900 loss: 1.8430793285369873\n",
      "Iteration number 7000 loss: 2.112152338027954\n",
      "Iteration number 7100 loss: 1.8059229850769043\n",
      "Iteration number 7200 loss: 1.9155769348144531\n",
      "Iteration number 7300 loss: 1.9127131700515747\n",
      "Iteration number 7400 loss: 2.0152339935302734\n",
      "Iteration number 7500 loss: 1.798285722732544\n",
      "Iteration number 7600 loss: 2.087188959121704\n",
      "Iteration number 7700 loss: 2.025132656097412\n",
      "Iteration number 7800 loss: 1.9033126831054688\n",
      "Iteration number 7900 loss: 1.9867513179779053\n",
      "Iteration number 8000 loss: 2.0625667572021484\n",
      "Iteration number 8100 loss: 2.0792856216430664\n",
      "Iteration number 8200 loss: 1.9983928203582764\n",
      "Iteration number 8300 loss: 1.8302063941955566\n",
      "Iteration number 8400 loss: 2.074045181274414\n",
      "Iteration number 8500 loss: 2.0929532051086426\n",
      "Iteration number 8600 loss: 2.1323933601379395\n",
      "Iteration number 8700 loss: 2.092061996459961\n",
      "Iteration number 8800 loss: 1.8415182828903198\n",
      "Iteration number 8900 loss: 1.8953542709350586\n",
      "Iteration number 9000 loss: 1.9414572715759277\n",
      "Iteration number 9100 loss: 1.9390438795089722\n",
      "Iteration number 9200 loss: 1.8773937225341797\n",
      "Iteration number 9300 loss: 1.8552360534667969\n",
      "Iteration number 9400 loss: 1.849137544631958\n",
      "Iteration number 9500 loss: 1.9541990756988525\n",
      "Iteration number 9600 loss: 2.0415732860565186\n",
      "Iteration number 9700 loss: 2.027329683303833\n",
      "Iteration number 9800 loss: 1.954530119895935\n",
      "Iteration number 9900 loss: 1.979981780052185\n",
      "Iteration number 10000 loss: 2.0627691745758057\n",
      "Iteration number 10100 loss: 1.9492347240447998\n",
      "Iteration number 10200 loss: 2.053086757659912\n",
      "Iteration number 10300 loss: 1.9068412780761719\n",
      "Iteration number 10400 loss: 1.8281910419464111\n",
      "Iteration number 10500 loss: 1.8866057395935059\n",
      "Iteration number 10600 loss: 1.8787835836410522\n",
      "Iteration number 10700 loss: 2.047194004058838\n",
      "Iteration number 10800 loss: 1.8345611095428467\n",
      "Iteration number 10900 loss: 1.875474214553833\n",
      "Iteration number 11000 loss: 2.1270408630371094\n",
      "Iteration number 11100 loss: 2.0572350025177\n",
      "Iteration number 11200 loss: 2.143113851547241\n",
      "Iteration number 11300 loss: 1.9634099006652832\n",
      "Iteration number 11400 loss: 1.9676275253295898\n",
      "Iteration number 11500 loss: 2.0313143730163574\n",
      "Iteration number 11600 loss: 2.101593494415283\n",
      "Iteration number 11700 loss: 2.3061134815216064\n",
      "Iteration number 11800 loss: 1.9275169372558594\n",
      "Iteration number 11900 loss: 1.899449348449707\n",
      "Iteration number 12000 loss: 1.9787119626998901\n",
      "Iteration number 12100 loss: 2.110013484954834\n",
      "Iteration number 12200 loss: 1.9593393802642822\n",
      "Iteration number 12300 loss: 1.9844036102294922\n",
      "Iteration number 12400 loss: 1.811739206314087\n",
      "Iteration number 12500 loss: 1.8667352199554443\n",
      "Iteration number 12600 loss: 1.7606310844421387\n",
      "Iteration number 12700 loss: 2.2441868782043457\n",
      "Iteration number 12800 loss: 1.8755395412445068\n",
      "Iteration number 12900 loss: 1.8584539890289307\n",
      "Iteration number 13000 loss: 2.0897364616394043\n",
      "Iteration number 13100 loss: 1.9229987859725952\n",
      "Iteration number 13200 loss: 2.048841714859009\n",
      "Iteration number 13300 loss: 1.904463768005371\n",
      "Iteration number 13400 loss: 1.9412142038345337\n",
      "Iteration number 13500 loss: 1.950101613998413\n",
      "Iteration number 13600 loss: 1.8754186630249023\n",
      "Iteration number 13700 loss: 1.903196096420288\n",
      "Iteration number 13800 loss: 1.8307719230651855\n",
      "Iteration number 13900 loss: 1.6525099277496338\n",
      "Iteration number 14000 loss: 1.8484653234481812\n",
      "Iteration number 14100 loss: 1.9561104774475098\n",
      "Iteration number 14200 loss: 1.8569209575653076\n",
      "Iteration number 14300 loss: 1.825179100036621\n",
      "Iteration number 14400 loss: 2.0115549564361572\n",
      "Iteration number 14500 loss: 1.7967053651809692\n",
      "Iteration number 14600 loss: 1.8039002418518066\n",
      "Iteration number 14700 loss: 1.8886544704437256\n",
      "Iteration number 14800 loss: 1.8030202388763428\n",
      "Iteration number 14900 loss: 1.8106210231781006\n",
      "Iteration number 15000 loss: 1.9087660312652588\n",
      "Iteration number 15100 loss: 1.8875887393951416\n",
      "Iteration number 15200 loss: 2.1080942153930664\n",
      "Iteration number 15300 loss: 2.065424919128418\n",
      "Iteration number 15400 loss: 1.8577030897140503\n",
      "Iteration number 15500 loss: 1.8795881271362305\n",
      "Iteration number 15600 loss: 1.9541423320770264\n",
      "Iteration number 15700 loss: 1.9381694793701172\n",
      "Iteration number 15800 loss: 1.7829148769378662\n",
      "Iteration number 15900 loss: 1.9356093406677246\n",
      "Iteration number 16000 loss: 2.021435499191284\n",
      "Iteration number 16100 loss: 2.0022459030151367\n",
      "Iteration number 16200 loss: 1.9914062023162842\n",
      "Iteration number 16300 loss: 1.956972360610962\n",
      "Iteration number 16400 loss: 2.093116283416748\n",
      "Iteration number 16500 loss: 2.1025280952453613\n",
      "Iteration number 16600 loss: 2.044428825378418\n",
      "Iteration number 16700 loss: 1.9754241704940796\n",
      "Iteration number 16800 loss: 1.860785722732544\n",
      "Iteration number 16900 loss: 1.859796166419983\n",
      "Iteration number 17000 loss: 1.9648691415786743\n",
      "Iteration number 17100 loss: 1.7382793426513672\n",
      "Iteration number 17200 loss: 1.993194580078125\n",
      "Iteration number 17300 loss: 1.9752755165100098\n",
      "Iteration number 17400 loss: 2.0925347805023193\n",
      "Iteration number 17500 loss: 1.9991567134857178\n",
      "Iteration number 17600 loss: 2.0012965202331543\n",
      "Iteration number 17700 loss: 1.8899091482162476\n",
      "Iteration number 17800 loss: 1.9980559349060059\n",
      "Iteration number 17900 loss: 1.866664171218872\n",
      "Iteration number 18000 loss: 1.9303139448165894\n",
      "Iteration number 18100 loss: 1.9278783798217773\n",
      "Iteration number 18200 loss: 1.9948149919509888\n",
      "Iteration number 18300 loss: 2.071443557739258\n",
      "Iteration number 18400 loss: 1.9933538436889648\n",
      "Iteration number 18500 loss: 1.8644671440124512\n",
      "Iteration number 18600 loss: 2.0849218368530273\n",
      "Iteration number 18700 loss: 1.9631860256195068\n",
      "Iteration number 18800 loss: 2.029822826385498\n",
      "Iteration number 18900 loss: 2.0118298530578613\n",
      "Iteration number 19000 loss: 2.0720536708831787\n",
      "Iteration number 19100 loss: 1.9977493286132812\n",
      "Iteration number 19200 loss: 1.9561901092529297\n",
      "Iteration number 19300 loss: 1.9047719240188599\n",
      "Iteration number 19400 loss: 1.9345316886901855\n",
      "Iteration number 19500 loss: 1.8545273542404175\n",
      "Iteration number 19600 loss: 1.6974890232086182\n",
      "Iteration number 19700 loss: 1.9135770797729492\n",
      "Iteration number 19800 loss: 1.924737811088562\n",
      "Iteration number 19900 loss: 1.8285133838653564\n",
      "Iteration number 20000 loss: 1.91305673122406\n",
      "Iteration number 20100 loss: 1.9388060569763184\n",
      "Iteration number 20200 loss: 1.8213841915130615\n",
      "Iteration number 20300 loss: 1.9767513275146484\n",
      "Iteration number 20400 loss: 1.9235661029815674\n",
      "Iteration number 20500 loss: 2.066120147705078\n",
      "Iteration number 20600 loss: 1.926159381866455\n",
      "Iteration number 20700 loss: 1.9735348224639893\n",
      "Iteration number 20800 loss: 1.964220643043518\n",
      "Iteration number 20900 loss: 1.9632114171981812\n",
      "Iteration number 21000 loss: 1.883840560913086\n",
      "Iteration number 21100 loss: 1.832265853881836\n",
      "Iteration number 21200 loss: 1.869218111038208\n",
      "Iteration number 21300 loss: 2.008009672164917\n",
      "Iteration number 21400 loss: 1.863119125366211\n",
      "Iteration number 21500 loss: 1.8959987163543701\n",
      "Iteration number 21600 loss: 1.8146178722381592\n",
      "Iteration number 21700 loss: 2.038926124572754\n",
      "Iteration number 21800 loss: 1.874470591545105\n",
      "Iteration number 21900 loss: 1.96547269821167\n",
      "Iteration number 22000 loss: 1.6975655555725098\n",
      "Iteration number 22100 loss: 1.8539899587631226\n",
      "Iteration number 22200 loss: 1.9090549945831299\n",
      "Iteration number 22300 loss: 1.9129559993743896\n",
      "Iteration number 22400 loss: 1.9005768299102783\n",
      "Iteration number 22500 loss: 2.0086863040924072\n",
      "Iteration number 22600 loss: 1.8402125835418701\n",
      "Iteration number 22700 loss: 1.9098321199417114\n",
      "Iteration number 22800 loss: 1.8336162567138672\n",
      "Iteration number 22900 loss: 1.9374122619628906\n",
      "Iteration number 23000 loss: 1.9794225692749023\n",
      "Iteration number 23100 loss: 1.969627857208252\n",
      "Iteration number 23200 loss: 1.8747550249099731\n",
      "Iteration number 23300 loss: 1.8983757495880127\n",
      "Iteration number 23400 loss: 1.969395399093628\n",
      "Iteration number 23500 loss: 1.8925988674163818\n",
      "Iteration number 23600 loss: 1.9661906957626343\n",
      "Iteration number 23700 loss: 1.961043357849121\n",
      "Iteration number 23800 loss: 1.8753130435943604\n",
      "Iteration number 23900 loss: 1.9584574699401855\n",
      "Iteration number 24000 loss: 1.8462953567504883\n",
      "Iteration number 24100 loss: 1.9408024549484253\n",
      "Iteration number 24200 loss: 1.8128104209899902\n",
      "Iteration number 24300 loss: 2.046006202697754\n",
      "Iteration number 24400 loss: 1.7500972747802734\n",
      "Iteration number 24500 loss: 2.0644891262054443\n",
      "Iteration number 24600 loss: 2.014273166656494\n",
      "Iteration number 24700 loss: 1.9637224674224854\n",
      "Iteration number 24800 loss: 1.8869708776474\n",
      "Iteration number 24900 loss: 2.017742872238159\n",
      "Iteration number 25000 loss: 1.9124929904937744\n",
      "Iteration number 25100 loss: 1.6704988479614258\n",
      "Iteration number 25200 loss: 1.8440345525741577\n",
      "Iteration number 25300 loss: 1.8937147855758667\n",
      "Iteration number 25400 loss: 2.001415491104126\n",
      "Iteration number 25500 loss: 1.9487535953521729\n",
      "Iteration number 25600 loss: 1.804947853088379\n",
      "Iteration number 25700 loss: 1.9067144393920898\n",
      "Iteration number 25800 loss: 1.9420883655548096\n",
      "Iteration number 25900 loss: 1.9312978982925415\n",
      "Iteration number 26000 loss: 1.8335368633270264\n",
      "Iteration number 26100 loss: 1.861605167388916\n",
      "Iteration number 26200 loss: 2.0074679851531982\n",
      "Iteration number 26300 loss: 1.9604804515838623\n",
      "Iteration number 26400 loss: 1.944019079208374\n",
      "Iteration number 26500 loss: 1.8315643072128296\n",
      "Iteration number 26600 loss: 1.868905782699585\n",
      "Iteration number 26700 loss: 2.0624876022338867\n",
      "Iteration number 26800 loss: 1.8506406545639038\n",
      "Iteration number 26900 loss: 2.0206236839294434\n",
      "Iteration number 27000 loss: 2.057568311691284\n",
      "Iteration number 27100 loss: 2.1256422996520996\n",
      "Iteration number 27200 loss: 2.011582136154175\n",
      "Iteration number 27300 loss: 1.9038501977920532\n",
      "Iteration number 27400 loss: 1.9467861652374268\n",
      "Iteration number 27500 loss: 1.8855934143066406\n",
      "Iteration number 27600 loss: 1.9722449779510498\n",
      "Iteration number 27700 loss: 1.8866095542907715\n",
      "Iteration number 27800 loss: 1.6729706525802612\n",
      "Iteration number 27900 loss: 1.9328114986419678\n",
      "Iteration number 28000 loss: 1.8933334350585938\n",
      "Iteration number 28100 loss: 1.8111639022827148\n",
      "Iteration number 28200 loss: 1.9850690364837646\n",
      "Iteration number 28300 loss: 2.035766363143921\n",
      "Iteration number 28400 loss: 1.9008444547653198\n",
      "Iteration number 28500 loss: 1.854418396949768\n",
      "Iteration number 28600 loss: 2.0094876289367676\n",
      "Iteration number 28700 loss: 2.01888370513916\n",
      "Iteration number 28800 loss: 2.0780937671661377\n",
      "Iteration number 28900 loss: 1.7598897218704224\n",
      "Iteration number 29000 loss: 1.7872248888015747\n",
      "Iteration number 29100 loss: 1.8999621868133545\n",
      "Iteration number 29200 loss: 1.9658019542694092\n",
      "Iteration number 29300 loss: 1.963281512260437\n",
      "Iteration number 29400 loss: 1.993262767791748\n",
      "Iteration number 29500 loss: 1.9911679029464722\n",
      "Iteration number 29600 loss: 2.039496660232544\n",
      "Iteration number 29700 loss: 1.937087893486023\n",
      "Iteration number 29800 loss: 1.8685115575790405\n",
      "Iteration number 29900 loss: 1.9892441034317017\n",
      "Iteration number 30000 loss: 2.0204405784606934\n",
      "Iteration number 30100 loss: 2.0218496322631836\n",
      "Iteration number 30200 loss: 2.032780647277832\n",
      "Iteration number 30300 loss: 1.8997061252593994\n",
      "Iteration number 30400 loss: 1.828127145767212\n",
      "Iteration number 30500 loss: 2.2195491790771484\n",
      "Iteration number 30600 loss: 1.7782421112060547\n",
      "Iteration number 30700 loss: 2.0412392616271973\n",
      "Iteration number 30800 loss: 1.798101782798767\n",
      "Iteration number 30900 loss: 2.1618828773498535\n",
      "Iteration number 31000 loss: 2.0694401264190674\n",
      "Iteration number 31100 loss: 2.1788017749786377\n",
      "Iteration number 31200 loss: 1.9008069038391113\n",
      "Iteration number 31300 loss: 1.9963088035583496\n",
      "Iteration number 31400 loss: 1.9881460666656494\n",
      "Iteration number 31500 loss: 2.118317127227783\n",
      "Iteration number 31600 loss: 2.0631256103515625\n",
      "Iteration number 31700 loss: 1.9930799007415771\n",
      "Iteration number 31800 loss: 1.7365703582763672\n",
      "Iteration number 31900 loss: 2.115814447402954\n",
      "Iteration number 32000 loss: 1.957618236541748\n",
      "Iteration number 32100 loss: 2.0353713035583496\n",
      "Iteration number 32200 loss: 2.0435094833374023\n",
      "Iteration number 32300 loss: 2.002601146697998\n",
      "Iteration number 32400 loss: 2.0430703163146973\n",
      "Iteration number 32500 loss: 1.9595465660095215\n",
      "Iteration number 32600 loss: 2.0327982902526855\n",
      "Iteration number 32700 loss: 1.8963907957077026\n",
      "Iteration number 32800 loss: 2.023054599761963\n",
      "Iteration number 32900 loss: 2.0741028785705566\n",
      "Iteration number 33000 loss: 1.7541449069976807\n",
      "Iteration number 33100 loss: 2.0003345012664795\n",
      "Iteration number 33200 loss: 1.94366455078125\n",
      "Iteration number 33300 loss: 1.9382416009902954\n",
      "Iteration number 33400 loss: 1.8901169300079346\n",
      "Iteration number 33500 loss: 1.8670824766159058\n",
      "Iteration number 33600 loss: 1.9146497249603271\n",
      "Iteration number 33700 loss: 1.7174086570739746\n",
      "Iteration number 33800 loss: 1.8828213214874268\n",
      "Iteration number 33900 loss: 1.9665031433105469\n",
      "Iteration number 34000 loss: 2.034857749938965\n",
      "Iteration number 34100 loss: 1.862372875213623\n",
      "Iteration number 34200 loss: 1.9136674404144287\n",
      "Iteration number 34300 loss: 1.7930736541748047\n",
      "Iteration number 34400 loss: 1.9480235576629639\n",
      "Iteration number 34500 loss: 1.8504886627197266\n",
      "Iteration number 34600 loss: 1.9149954319000244\n",
      "Iteration number 34700 loss: 1.8469938039779663\n",
      "Iteration number 34800 loss: 2.0627260208129883\n",
      "Iteration number 34900 loss: 1.953949213027954\n",
      "Iteration number 35000 loss: 1.8808685541152954\n",
      "Iteration number 35100 loss: 2.0628085136413574\n",
      "Iteration number 35200 loss: 1.8556385040283203\n",
      "Iteration number 35300 loss: 2.0741472244262695\n",
      "Iteration number 35400 loss: 1.7759058475494385\n",
      "Iteration number 35500 loss: 1.9226386547088623\n",
      "Iteration number 35600 loss: 1.9870202541351318\n",
      "Iteration number 35700 loss: 1.824622392654419\n",
      "Iteration number 35800 loss: 1.8532742261886597\n",
      "Iteration number 35900 loss: 1.857479453086853\n",
      "Iteration number 36000 loss: 2.0914580821990967\n",
      "Iteration number 36100 loss: 2.0815415382385254\n",
      "Iteration number 36200 loss: 1.822392225265503\n",
      "Iteration number 36300 loss: 2.056375026702881\n",
      "Iteration number 36400 loss: 1.918510913848877\n",
      "Iteration number 36500 loss: 1.8567512035369873\n",
      "Iteration number 36600 loss: 1.9263215065002441\n",
      "Iteration number 36700 loss: 1.6708266735076904\n",
      "Iteration number 36800 loss: 1.7622512578964233\n",
      "Iteration number 36900 loss: 2.037724018096924\n",
      "Iteration number 37000 loss: 1.9754624366760254\n",
      "Iteration number 37100 loss: 1.8085544109344482\n",
      "Iteration number 37200 loss: 1.9222594499588013\n",
      "Iteration number 37300 loss: 1.7904415130615234\n",
      "Iteration number 37400 loss: 1.9965555667877197\n",
      "Iteration number 37500 loss: 1.9002275466918945\n",
      "Iteration number 37600 loss: 1.9056055545806885\n",
      "Iteration number 37700 loss: 2.014014482498169\n",
      "Iteration number 37800 loss: 1.712623119354248\n",
      "Iteration number 37900 loss: 1.8145631551742554\n",
      "Iteration number 38000 loss: 1.958337664604187\n",
      "Iteration number 38100 loss: 1.877227544784546\n",
      "Iteration number 38200 loss: 1.780821442604065\n",
      "Iteration number 38300 loss: 1.9330949783325195\n",
      "Iteration number 38400 loss: 2.0251922607421875\n",
      "Iteration number 38500 loss: 1.9719634056091309\n",
      "Iteration number 38600 loss: 1.9150114059448242\n",
      "Iteration number 38700 loss: 1.8268060684204102\n",
      "Iteration number 38800 loss: 1.881717562675476\n",
      "Iteration number 38900 loss: 1.891880750656128\n",
      "Iteration number 39000 loss: 1.8867961168289185\n",
      "Iteration number 39100 loss: 1.9659411907196045\n",
      "Iteration number 39200 loss: 1.8570218086242676\n",
      "Iteration number 39300 loss: 1.994408130645752\n",
      "Iteration number 39400 loss: 1.7391995191574097\n",
      "Iteration number 39500 loss: 1.7927457094192505\n",
      "Iteration number 39600 loss: 1.9025120735168457\n",
      "Iteration number 39700 loss: 2.089132785797119\n",
      "Iteration number 39800 loss: 1.89780592918396\n",
      "Iteration number 39900 loss: 1.8216195106506348\n",
      "Iteration number 40000 loss: 1.9490364789962769\n",
      "Iteration number 40100 loss: 1.865225076675415\n",
      "Iteration number 40200 loss: 1.8126682043075562\n",
      "Iteration number 40300 loss: 1.8756482601165771\n",
      "Iteration number 40400 loss: 2.0698130130767822\n",
      "Iteration number 40500 loss: 1.84561026096344\n",
      "Iteration number 40600 loss: 1.9564862251281738\n",
      "Iteration number 40700 loss: 1.9481933116912842\n",
      "Iteration number 40800 loss: 1.9627888202667236\n",
      "Iteration number 40900 loss: 1.9570496082305908\n",
      "Iteration number 41000 loss: 1.886947512626648\n",
      "Iteration number 41100 loss: 1.772798776626587\n",
      "Iteration number 41200 loss: 1.9022636413574219\n",
      "Iteration number 41300 loss: 1.850629448890686\n",
      "Iteration number 41400 loss: 1.8000937700271606\n",
      "Iteration number 41500 loss: 1.7793223857879639\n",
      "Iteration number 41600 loss: 1.9005416631698608\n",
      "Iteration number 41700 loss: 2.1251213550567627\n",
      "Iteration number 41800 loss: 1.7696568965911865\n",
      "Iteration number 41900 loss: 1.8302152156829834\n",
      "Iteration number 42000 loss: 1.8226792812347412\n",
      "Iteration number 42100 loss: 1.8979101181030273\n",
      "Iteration number 42200 loss: 1.7585010528564453\n",
      "Iteration number 42300 loss: 1.823920726776123\n",
      "Iteration number 42400 loss: 1.859943151473999\n",
      "Iteration number 42500 loss: 2.050861358642578\n",
      "Iteration number 42600 loss: 1.90767502784729\n",
      "Iteration number 42700 loss: 1.8673336505889893\n",
      "Iteration number 42800 loss: 1.9041788578033447\n",
      "Iteration number 42900 loss: 1.8561731576919556\n",
      "Iteration number 43000 loss: 2.0151991844177246\n",
      "Iteration number 43100 loss: 1.8525446653366089\n",
      "Iteration number 43200 loss: 1.8263497352600098\n",
      "Iteration number 43300 loss: 1.929012656211853\n",
      "Iteration number 43400 loss: 2.0571200847625732\n",
      "Iteration number 43500 loss: 1.6503691673278809\n",
      "Iteration number 43600 loss: 1.869543433189392\n",
      "Iteration number 43700 loss: 1.882807731628418\n",
      "Iteration number 43800 loss: 1.8674094676971436\n",
      "Iteration number 43900 loss: 2.000485420227051\n",
      "Iteration number 44000 loss: 1.6366016864776611\n",
      "Iteration number 44100 loss: 1.6713401079177856\n",
      "Iteration number 44200 loss: 1.8388060331344604\n",
      "Iteration number 44300 loss: 1.8499305248260498\n",
      "Iteration number 44400 loss: 1.8255069255828857\n",
      "Iteration number 44500 loss: 1.8943721055984497\n",
      "Iteration number 44600 loss: 1.923919439315796\n",
      "Iteration number 44700 loss: 1.8364832401275635\n",
      "Iteration number 44800 loss: 2.0498666763305664\n",
      "Iteration number 44900 loss: 1.905266284942627\n",
      "Iteration number 45000 loss: 1.7900774478912354\n",
      "Iteration number 45100 loss: 1.720902442932129\n",
      "Iteration number 45200 loss: 1.906199336051941\n",
      "Iteration number 45300 loss: 1.7267212867736816\n",
      "Iteration number 45400 loss: 1.944556474685669\n",
      "Iteration number 45500 loss: 1.8060214519500732\n",
      "Iteration number 45600 loss: 1.8422136306762695\n",
      "Iteration number 45700 loss: 1.8999483585357666\n",
      "Iteration number 45800 loss: 2.0091958045959473\n",
      "Iteration number 45900 loss: 1.779341697692871\n",
      "Iteration number 46000 loss: 1.7529634237289429\n",
      "Iteration number 46100 loss: 1.792284369468689\n",
      "Iteration number 46200 loss: 1.8751200437545776\n",
      "Iteration number 46300 loss: 1.8810930252075195\n",
      "Iteration number 46400 loss: 1.8527631759643555\n",
      "Iteration number 46500 loss: 1.7317661046981812\n",
      "Iteration number 46600 loss: 1.9287059307098389\n",
      "Iteration number 46700 loss: 1.8193230628967285\n",
      "Iteration number 46800 loss: 1.8347992897033691\n",
      "Iteration number 46900 loss: 2.00931453704834\n",
      "Iteration number 47000 loss: 1.7056281566619873\n",
      "Iteration number 47100 loss: 1.9454939365386963\n",
      "Iteration number 47200 loss: 1.7808713912963867\n",
      "Iteration number 47300 loss: 2.004431962966919\n",
      "Iteration number 47400 loss: 2.0986855030059814\n",
      "Iteration number 47500 loss: 1.8859188556671143\n",
      "Iteration number 47600 loss: 2.0398969650268555\n",
      "Iteration number 47700 loss: 1.7557891607284546\n",
      "Iteration number 47800 loss: 1.9471508264541626\n",
      "Iteration number 47900 loss: 1.9335793256759644\n",
      "Iteration number 48000 loss: 1.9436612129211426\n",
      "Iteration number 48100 loss: 1.9478254318237305\n",
      "Iteration number 48200 loss: 1.8620052337646484\n",
      "Iteration number 48300 loss: 1.7914648056030273\n",
      "Iteration number 48400 loss: 1.774133563041687\n",
      "Iteration number 48500 loss: 1.8572804927825928\n",
      "Iteration number 48600 loss: 1.8637115955352783\n",
      "Iteration number 48700 loss: 1.702455997467041\n",
      "Iteration number 48800 loss: 1.7781181335449219\n",
      "Iteration number 48900 loss: 1.8428517580032349\n",
      "Iteration number 49000 loss: 1.6137797832489014\n",
      "Iteration number 49100 loss: 1.966970443725586\n",
      "Iteration number 49200 loss: 1.814953327178955\n",
      "Iteration number 49300 loss: 1.9553043842315674\n",
      "Iteration number 49400 loss: 1.833694577217102\n",
      "Iteration number 49500 loss: 1.6691924333572388\n",
      "Iteration number 49600 loss: 2.011176109313965\n",
      "Iteration number 49700 loss: 1.7379201650619507\n",
      "Iteration number 49800 loss: 1.7467734813690186\n",
      "Iteration number 49900 loss: 1.8557143211364746\n",
      "Iteration number 50000 loss: 1.8630836009979248\n",
      "Iteration number 50100 loss: 2.0135879516601562\n",
      "Iteration number 50200 loss: 1.9799529314041138\n",
      "Iteration number 50300 loss: 1.865525484085083\n",
      "Iteration number 50400 loss: 1.7405550479888916\n",
      "Iteration number 50500 loss: 1.7615290880203247\n",
      "Iteration number 50600 loss: 2.0009849071502686\n",
      "Iteration number 50700 loss: 1.9087687730789185\n",
      "Iteration number 50800 loss: 1.890358328819275\n",
      "Episode Number: 18\n",
      "Iteration number 0 loss: 1.9696106910705566\n",
      "Iteration number 100 loss: 1.8424022197723389\n",
      "Iteration number 200 loss: 1.6531705856323242\n",
      "Iteration number 300 loss: 1.711467981338501\n",
      "Iteration number 400 loss: 1.7952580451965332\n",
      "Iteration number 500 loss: 1.9528576135635376\n",
      "Iteration number 600 loss: 1.7111239433288574\n",
      "Iteration number 700 loss: 1.650180697441101\n",
      "Iteration number 800 loss: 1.7828388214111328\n",
      "Iteration number 900 loss: 1.73488187789917\n",
      "Iteration number 1000 loss: 1.6697006225585938\n",
      "Iteration number 1100 loss: 1.6680998802185059\n",
      "Iteration number 1200 loss: 1.8136146068572998\n",
      "Iteration number 1300 loss: 1.7651805877685547\n",
      "Iteration number 1400 loss: 1.6568593978881836\n",
      "Iteration number 1500 loss: 1.6048030853271484\n",
      "Iteration number 1600 loss: 1.6173772811889648\n",
      "Iteration number 1700 loss: 1.50642728805542\n",
      "Iteration number 1800 loss: 1.6357544660568237\n",
      "Iteration number 1900 loss: 1.9170308113098145\n",
      "Iteration number 2000 loss: 1.80439031124115\n",
      "Iteration number 2100 loss: 1.6144458055496216\n",
      "Iteration number 2200 loss: 1.4266164302825928\n",
      "Iteration number 2300 loss: 1.6212109327316284\n",
      "Iteration number 2400 loss: 1.6063650846481323\n",
      "Iteration number 2500 loss: 1.7551809549331665\n",
      "Iteration number 2600 loss: 1.7241058349609375\n",
      "Iteration number 2700 loss: 1.7855174541473389\n",
      "Iteration number 2800 loss: 1.6022071838378906\n",
      "Iteration number 2900 loss: 1.7090297937393188\n",
      "Iteration number 3000 loss: 1.8407821655273438\n",
      "Iteration number 3100 loss: 1.9367213249206543\n",
      "Iteration number 3200 loss: 1.793434739112854\n",
      "Iteration number 3300 loss: 1.707261562347412\n",
      "Iteration number 3400 loss: 1.842737078666687\n",
      "Iteration number 3500 loss: 2.1842286586761475\n",
      "Iteration number 3600 loss: 2.0234105587005615\n",
      "Iteration number 3700 loss: 1.8779619932174683\n",
      "Iteration number 3800 loss: 1.7534068822860718\n",
      "Iteration number 3900 loss: 1.657339096069336\n",
      "Iteration number 4000 loss: 1.9809974431991577\n",
      "Iteration number 4100 loss: 1.7751760482788086\n",
      "Iteration number 4200 loss: 1.6967121362686157\n",
      "Episode Number: 19\n",
      "Iteration number 0 loss: 1.7354810237884521\n",
      "Iteration number 100 loss: 1.697156310081482\n",
      "Iteration number 200 loss: 2.013744354248047\n",
      "Iteration number 300 loss: 2.0073747634887695\n",
      "Iteration number 400 loss: 1.8266503810882568\n",
      "Iteration number 500 loss: 1.7738474607467651\n",
      "Iteration number 600 loss: 1.8154807090759277\n",
      "Iteration number 700 loss: 1.9199683666229248\n",
      "Iteration number 800 loss: 1.8910763263702393\n",
      "Iteration number 900 loss: 1.8519669771194458\n",
      "Iteration number 1000 loss: 1.871752142906189\n",
      "Iteration number 1100 loss: 2.0539512634277344\n",
      "Iteration number 1200 loss: 1.7670801877975464\n",
      "Complete\n",
      "\n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m3\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m2\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m2\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m2\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m2\n",
      "\u001b[0;37m4\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mC\u001b[0;37ma\u001b[0;37mv\u001b[0;37m-\u001b[0;37mD\u001b[0;37mw\u001b[0;37ma\u001b[0;37m-\u001b[0;37mM\u001b[0;37ma\u001b[0;37ml\u001b[0;37m-\u001b[0;37mL\u001b[0;37ma\u001b[0;37mw\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m8\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m8\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m3\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m4\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mT\u001b[0;37mo\u001b[0;37mu\n",
      "\u001b[0;37m-\u001b[0;37mH\u001b[0;37mu\u001b[0;37mm\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mN\u001b[0;37me\u001b[0;37mu\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m0\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m0\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m7\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mV\u001b[0;37ma\u001b[0;37ml\u001b[0;37m-\u001b[0;37mD\u001b[0;37mw\u001b[0;37ma\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mL\u001b[0;37ma\u001b[0;37mw\n",
      "\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m8\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m8\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m8\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mR\u001b[0;37mo\u001b[0;37mg\u001b[0;37m-\u001b[0;37mO\u001b[0;37mr\u001b[0;37mc\u001b[0;37m-\u001b[0;37mF\u001b[0;37me\u001b[0;37mm\u001b[0;37m-\u001b[0;37mC\u001b[0;37mh\u001b[0;37ma\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\n",
      "\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m1\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m1\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m0\u001b[0;30m \u001b[0;30m \u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;37m-\u001b[0;37mH\u001b[0;37me\u001b[0;37ma\u001b[0;37m-\u001b[0;37mG\u001b[0;37mn\u001b[0;37mo\u001b[0;37m-\u001b[0;37mM\u001b[0;37ma\u001b[0;37ml\u001b[0;37m-\u001b[0;37mN\u001b[0;37me\u001b[0;37mu\u001b[0;30m \u001b[0;37mq\u001b[0;37mu\u001b[0;37mi\u001b[0;37mt\u001b[0;30m \u001b[0;37mi\u001b[0;37mn\u001b[0;30m \u001b[0;37mT\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mD\u001b[0;37mu\u001b[0;37mn\u001b[0;37mg\u001b[0;37me\u001b[0;37mo\u001b[0;37mn\u001b[0;37ms\u001b[0;30m \u001b[0;37mo\u001b[0;37mf\n",
      "\u001b[0;30m \u001b[0;37mD\u001b[0;37mo\u001b[0;37mo\u001b[0;37mm\u001b[0;30m \u001b[0;37mo\u001b[0;37mn\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37ml\u001b[0;37me\u001b[0;37mv\u001b[0;37me\u001b[0;37ml\u001b[0;30m \u001b[0;37m1\u001b[0;37m.\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37m1\u001b[0;37m2\u001b[0;30m \u001b[0;30m \u001b[0;37m[\u001b[0;37m1\u001b[0;37m2\u001b[0;37m]\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def concat_state(state):\n",
    "    state = np.stack((state['glyphs'], state['chars'], state['colors'], state['specials']))\n",
    "    state = torch.tensor(np.expand_dims(state, axis=0), device=device)\n",
    "    return state\n",
    "\n",
    "# EPISODES\n",
    "num_episodes = 20\n",
    "for i_episode in range(num_episodes):\n",
    "    print('Episode Number: ' + str(i_episode))\n",
    "    # Initialize the environment and state\n",
    "    obs = env.reset()\n",
    "    state = concat_state(obs)\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        obs, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        # Keep track of current state and previous states \n",
    "        last_state = state\n",
    "        state = concat_state(obs)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(StateTransition(last_state, action, state, reward))\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model(t)\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c4a8571-aacc-45e4-a0c5-bc8bbf358ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106754"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(episode_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8edfcdb5-8edd-4e3c-b6e3-b58add25ebe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = [x.reward for x in memory.memory]\n",
    "max(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dd39b-f1b4-437c-b1ae-67646435f955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
